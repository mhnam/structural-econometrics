{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9daf28f8ad1c2783",
   "metadata": {
    "id": "cell_000"
   },
   "source": [
    "# Tutorial 1: Hansen-Singleton (1982) GMM Estimation\n",
    "## STARTER FILE\n",
    "\n",
    "**ðŸ“ Student Instructions:**\n",
    "\n",
    "This is the starter file for Tutorial 1. You will implement key components of the GMM estimation procedure.\n",
    "\n",
    "### âœ… PROVIDED (Complete - No implementation needed):\n",
    "1. **Data preparation** - All data loading and transformation code\n",
    "2. **One-step GMM** - Fully implemented in `estimate_gmm()` function\n",
    "3. **Helper functions** - All utility functions (HAC covariance, numerical jacobian, etc.)\n",
    "4. **SpecificationRunner** class - Complete framework for running estimations\n",
    "5. **Question 1 example** - Full working example with specifications defined\n",
    "\n",
    "### ðŸ”¨ TO IMPLEMENT (Your tasks):\n",
    "\n",
    "#### **Task 1: Two-Step GMM** (in `estimate_gmm()` function)\n",
    "- Implement the two-step GMM estimator\n",
    "- Follow the TODO instructions in the code\n",
    "- Test by running with `gmm_method='two-step'`\n",
    "\n",
    "#### **Task 2: Iterated GMM** (in `estimate_gmm()` function)\n",
    "- Implement the iterated GMM estimator\n",
    "- Follow the TODO instructions in the code\n",
    "- Test by running with `gmm_method='iterated'`\n",
    "\n",
    "#### **Task 3: Question 2 Specifications** (Replicate Table 3)\n",
    "- **Panel A**: Define specifications for NDS consumption with EW+VW returns (NLAG=1,2,4)\n",
    "- **Panel B**: Define specifications for NDS consumption with VW+RF returns (NLAG=1,2,4)\n",
    "- Follow the pattern from Question 1 example\n",
    "\n",
    "#### **Task 4: Question 3** (Parameter Stability Test)\n",
    "- Implement Wald test for parameter stability across time periods\n",
    "- Follow the pseudocode structure provided\n",
    "- Test H0: parameters are equal across 3 periods\n",
    "\n",
    "#### **Task 5: Question 4** (CARA Utility)\n",
    "- Repeat Question 2 using CARA utility instead of CRRA\n",
    "- **Panel A**: CARA with EW+VW returns\n",
    "- **Panel B**: CARA with VW+RF returns\n",
    "\n",
    "### ðŸš¨ Important Notes:\n",
    "- **Assertions**: The code contains `assert False` statements where you need to implement. Remove them when done.\n",
    "- **Testing**: Run code frequently to catch errors early\n",
    "- **One-step GMM**: Use this as reference for implementing two-step and iterated\n",
    "- **Question 1**: Study the example carefully - it shows the complete pattern\n",
    "\n",
    "### ðŸ“š Resources:\n",
    "- Hansen-Singleton (1982) paper (provided)\n",
    "- Lecture slides on GMM estimation\n",
    "- One-step GMM implementation (use as template)\n",
    "\n",
    "---\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455a68bb1a900006",
   "metadata": {
    "id": "cell_001"
   },
   "source": [
    "## 0. Quick instructions\n",
    "1. If you have real data, set `DATA_PATH` and map your column names in the **Config** cell.\n",
    "2. Returns must be **gross** (e.g., `1 + R`), not net.\n",
    "3. Consumption should be **real per-capita**. For CRRA we use the **ratio** `c_{t+1}/c_t`; for CARA we use **levels** to form differences `c_{t+1}-c_t`.\n",
    "4. Instruments typically include a constant and lags of consumption growth and returns.\n",
    "5. The three regimes for HS-style comparisons are: pre-1959Q2, 1959Q2â€“1978Q4, post-1978Q4. You can change these.\n",
    "\n",
    "> **Tip:** If you see numerical issues, adjust starting values, tighten bounds, or reduce the instrument set."
   ]
  },
  {
   "cell_type": "code",
   "id": "6b56057845e15dad",
   "metadata": {
    "id": "cell_002"
   },
   "source": "!pip install numpy pandas scipy matplotlib statsmodels tabulate openpyxl --quiet",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6390c1bbdc09db98",
   "metadata": {
    "id": "cell_003"
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy.linalg as la\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Optional, Dict, Tuple\n",
    "import scipy.optimize as opt\n",
    "\n",
    "try:\n",
    "    from statsmodels.tsa.stattools import adfuller\n",
    "    HAS_SM = True\n",
    "except ImportError:\n",
    "    HAS_SM = False\n",
    "\n",
    "pd.set_option('display.float_format', lambda x: f\"{x:,.6f}\")\n",
    "from tabulate import tabulate"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "484b40b79126b15c",
   "metadata": {
    "id": "cell_004"
   },
   "source": [
    "## 1. Data preparation\n",
    "\n",
    "We construct quarterly real per-capita consumption and real equity returns from FRED and CRSP monthly data.\n",
    "\n",
    "**Data sources:**\n",
    "\n",
    "(1) FRED Monthly Data:\n",
    "- `PCEND`: Personal Consumption Expenditures: Nondurable Goods (billions of dollars, SAAR)\n",
    "- `DNDGRG3M086SBEA` (PPCEND): Chain-type price index for nondurable goods\n",
    "- `PCES`: Personal Consumption Expenditures: Services (billions of dollars, SAAR)\n",
    "- `DSERRG3M086SBEA` (PPCES): Chain-type price index for services\n",
    "- `POPTHM`: Population (thousands of persons)\n",
    "- `CNP16OV`: Civilian Noninstitutional Population (thousands)\n",
    "- `CPIAUCSL`: Consumer Price Index for All Urban Consumers\n",
    "- `A796RX0Q048SBEA`: Real Personal Consumption Expenditures per Capita: Nondurable Goods (chained 2017 dollars, SAAR)\n",
    "- `A797RX0Q048SBEA`: Real Personal Consumption Expenditures per Capita: Services (chained 2017 dollars, SAAR)\n",
    "`GS1`: 1-Year Treasury Constant Maturity Rate (percent per annum)\n",
    "\n",
    "(2) CRSP Monthly Data:\n",
    "- `vwretd`: Value-Weighted Return (includes dividends)\n",
    "- `ewretd`: Equal-Weighted Return (includes dividends)\n",
    "- `sprtn`: Return on the S&P 500 Index\n",
    "\n",
    "**Pipeline:**\n",
    "1. Load monthly FRED and CRSP data\n",
    "2. Transform to real per-capita consumption and deflate returns by CPI\n",
    "3. Aggregate to quarterly frequency\n",
    "4. Construct leads/lags for GMM estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b53f9835f89b825",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-22T01:59:46.776267Z",
     "start_time": "2025-10-22T01:59:46.772313Z"
    },
    "id": "cell_005"
   },
   "source": [
    "### 1.1. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "id": "9236e03345cb23ec",
   "metadata": {
    "id": "cell_006"
   },
   "source": [
    "# Data directory and column names\n",
    "DATA_DIR = Path('data')  # Relative to notebook location\n",
    "COL_DATE = 'date_q'\n",
    "COL_CONS_NDS, COL_CONS_NDS_SVC = 'cons_nds_pc', 'cons_nds_svc_pc'\n",
    "COL_RET_EW, COL_RET_VW, COL_RET_SP, COL_RET_RF, = 'ret_ew_gross', 'ret_vw_gross', 'ret_sp_gross', 'rf_gross'"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "e3fc41f995139e38",
   "metadata": {
    "id": "cell_007"
   },
   "source": "### 1.2 Load raw data"
  },
  {
   "cell_type": "code",
   "id": "9rqy7vn3s6b",
   "metadata": {
    "id": "cell_008"
   },
   "source": [
    "# Helper function to read FRED CSVs\n",
    "def read_fred(series: str) -> pd.DataFrame:\n",
    "    df = pd.read_csv(DATA_DIR / f\"{series}.csv\", parse_dates=['observation_date'])\n",
    "    return df.rename(columns={'observation_date': 'date', df.columns[1]: series})\n",
    "\n",
    "# Load all FRED series\n",
    "fred_specs = [\n",
    "    ('PCEND', 'PCEND'),                      # Consumption: Nondurable Goods (nominal)\n",
    "    ('DNDGRG3M086SBEA', 'PPCEND'),           # Price index: Nondurable Goods\n",
    "    ('PCES', 'PCES'),                        # Consumption: Services (nominal)\n",
    "    ('DSERRG3M086SBEA', 'PPCES'),            # Price index: Services\n",
    "    ('POPTHM', 'POPTHM'),                    # Population (thousands)\n",
    "    ('CNP16OV', 'CNP16OV'),                  # Civilian population (thousands)\n",
    "    ('CPIAUCSL', 'CPI'),                     # Consumer Price Index\n",
    "    ('GS1', 'GS1'),                          # 1-Year Treasury rate (%)\n",
    "    ('A796RX0Q048SBEA', 'CONS_ND_REAL_PC'),  # Real ND consumption per capita (quarterly)\n",
    "    ('A797RX0Q048SBEA', 'CONS_SVC_REAL_PC'), # Real services consumption per capita (quarterly)\n",
    "]\n",
    "\n",
    "fred = read_fred(fred_specs[0][0]).rename(columns={fred_specs[0][0]: fred_specs[0][1]})\n",
    "for key, alias in fred_specs[1:]:\n",
    "    try:\n",
    "        fred = fred.merge(read_fred(key).rename(columns={key: alias}), on='date', how='outer')\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Warning: {key}.csv not found, skipping...\")\n",
    "\n",
    "fred = fred.sort_values('date')\n",
    "fred[fred.columns[1:]] = fred[fred.columns[1:]].apply(pd.to_numeric, errors='coerce')\n",
    "fred['month'] = fred['date'].dt.to_period('M')\n",
    "\n",
    "# Load CRSP returns\n",
    "crsp = pd.read_csv(DATA_DIR / 'CRSP.csv', parse_dates=['MthCalDt'])\n",
    "crsp['month'] = crsp['MthCalDt'].dt.to_period('M')\n",
    "crsp[['vwretd', 'ewretd', 'sprtrn']] = crsp[['vwretd', 'ewretd', 'sprtrn']].apply(pd.to_numeric, errors='coerce')\n",
    "crsp_monthly = crsp.set_index('month')[['vwretd', 'ewretd', 'sprtrn']].sort_index()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "sshwno8cxuf",
   "metadata": {
    "id": "cell_009"
   },
   "source": [
    "### 1.3 Transform to real per-capita and deflate returns\n",
    "\n",
    "Real Personal Consumption Expenditure on Nondurables\n",
    "$$\n",
    "    c_t = \\frac{\\text{Nondurables Consumption}_t * 1\\text{e}9}{\\text{Nondurables CPI}_t/100}*\\frac{1}{\\text{Population}_t * 1\\text{e}3}\n",
    "$$\n",
    "Real Personal Consumption Expenditure on Nondurables and Services\n",
    "$$\n",
    "    c_t^* = \\left(\\frac{\\text{Nondurables Consumption}_t * 1\\text{e}9}{\\text{Nondurables CPI}_t/100}+\\frac{\\text{Services Consumption}_t * 1\\text{e}9}{\\text{Services CPI}_t/100}\\right)*\\frac{1}{\\text{Population}_t * 1\\text{e}3}\n",
    "$$\n",
    "Real Value-weighted Return (VWRETD)\n",
    "$$\n",
    "    r_t = \\text{Real Value-weighted Return}_t = \\frac{1+\\text{Value-weighted Return}_t}{\\text{CPI}_{t}/\\text{CPI}_{t-1}}\n",
    "$$\n",
    "Real Equal-weighted Return (EWRETD)\n",
    "$$\n",
    "    r_t^* = \\text{Real Equal-weighted Return}_t = \\frac{1+\\text{Equal-weighted Return}_t}{\\text{CPI}_t/\\text{CPI}_{t-1}}\n",
    "$$\n",
    "Real S&P Return (SPRTRN)\n",
    "$$\n",
    "    r_t^{**} = \\text{Real S\\&P Return}_t = \\frac{1+\\text{S\\&P Return}_t}{\\text{CPI}_t/\\text{CPI}_{t-1}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "id": "skieiss2pd",
   "metadata": {
    "id": "cell_010"
   },
   "source": [
    "# Compute real per-capita consumption (monthly)\n",
    "fred = fred.set_index('month')\n",
    "fred['cons_nds_pc'] = (fred['PCEND'] * 1e9 / (fred['PPCEND'] / 100)) / (fred['POPTHM'] * 1e3)\n",
    "fred['cons_nds_svc_pc'] = fred['cons_nds_pc'] + (fred['PCES'] * 1e9 / (fred['PPCES'] / 100)) / (fred['POPTHM'] * 1e3)\n",
    "\n",
    "# Merge FRED and CRSP, compute real returns\n",
    "monthly = fred[['cons_nds_pc', 'cons_nds_svc_pc', 'CPI', 'GS1']].join(crsp_monthly, how='left').sort_index()\n",
    "monthly = monthly.loc['1947-01':]\n",
    "monthly.index = monthly.index.to_timestamp(how='end')\n",
    "\n",
    "# Inflation and real returns\n",
    "monthly['inf'] = monthly['CPI'] / monthly['CPI'].shift(1)\n",
    "monthly['vwret_real_gross'] = (1.0 + monthly['vwretd']) / monthly['inf']\n",
    "monthly['ewret_real_gross'] = (1.0 + monthly['ewretd']) / monthly['inf']\n",
    "monthly['spret_real_gross'] = (1.0 + monthly['sprtrn']) / monthly['inf']\n",
    "\n",
    "# Risk-free rate: convert annual % to monthly gross return, then deflate\n",
    "# GS1 is annual rate, so monthly rate â‰ˆ GS1/12, gross monthly return = 1 + GS1/(100*12)\n",
    "monthly['rf_gross'] = (1.0 + monthly['GS1'] / (100 * 12)) / monthly['inf']"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "r8nh1g3dlg9",
   "metadata": {
    "id": "cell_011"
   },
   "source": [
    "### 1.4 Aggregate to quarterly frequency"
   ]
  },
  {
   "cell_type": "code",
   "id": "rkwubg8c4ij",
   "metadata": {
    "id": "cell_012"
   },
   "source": [
    "# Resample to quarterly: average consumption, compound returns\n",
    "quarterly = pd.DataFrame({\n",
    "    'cons_nds_pc': monthly['cons_nds_pc'].resample('QE').mean(),\n",
    "    'cons_nds_svc_pc': monthly['cons_nds_svc_pc'].resample('QE').mean(),\n",
    "    'ret_vw_gross': monthly['vwret_real_gross'].resample('QE').prod(),\n",
    "    'ret_ew_gross': monthly['ewret_real_gross'].resample('QE').prod(),\n",
    "    'ret_sp_gross': monthly['spret_real_gross'].resample('QE').prod(),  # Compound quarterly risk-free rate\n",
    "    'rf_gross': monthly['rf_gross'].resample('QE').prod(),  # Compound quarterly risk-free rate\n",
    "})\n",
    "\n",
    "# Add net returns and growth ratios\n",
    "quarterly['ret_vw'] = quarterly['ret_vw_gross'] - 1.0\n",
    "quarterly['ret_ew'] = quarterly['ret_ew_gross'] - 1.0\n",
    "quarterly['ret_sp'] = quarterly['ret_sp_gross'] - 1.0\n",
    "quarterly['rf'] = quarterly['rf_gross'] - 1.0\n",
    "\n",
    "# Create plotting dataframe\n",
    "plot_df = quarterly.loc['1947-03-31':].dropna(\n",
    "    subset=['cons_nds_pc', 'cons_nds_svc_pc', 'ret_vw_gross', 'ret_ew_gross']\n",
    ").copy()\n",
    "plot_df.index.name = 'date_q'\n",
    "\n",
    "# Create ratio variables for plotting\n",
    "for c in [COL_CONS_NDS, COL_CONS_NDS_SVC]:\n",
    "    plot_df[c + '_ratio'] = plot_df[c].shift(-1) / plot_df[c]\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "i6qp858cafe",
   "metadata": {
    "id": "cell_013"
   },
   "source": [
    "### 1.5 Prepare GMM estimation data with leads and lags"
   ]
  },
  {
   "cell_type": "code",
   "id": "9a9dd8bef3139ca5",
   "metadata": {
    "id": "cell_014"
   },
   "source": [
    "# Extract core variables and construct leads/lags for instruments\n",
    "data = plot_df[[COL_CONS_NDS, COL_CONS_NDS_SVC, COL_RET_EW, COL_RET_VW, COL_RET_SP, COL_RET_RF]].copy()\n",
    "data[COL_DATE] = plot_df.index.to_period('Q').astype(str)\n",
    "for c in [COL_CONS_NDS, COL_CONS_NDS_SVC]:\n",
    "    data[c + '_f1'] = data[c].shift(-1)\n",
    "    data[c + '_ratio'] = data[c + '_f1'] / data[c]\n",
    "\n",
    "# Create lagged instruments (including risk-free rate)\n",
    "for c in [COL_RET_EW, COL_RET_VW, COL_RET_SP, COL_RET_RF, COL_CONS_NDS + '_ratio', COL_CONS_NDS_SVC + '_ratio']:\n",
    "    for lag in range(1, 7):\n",
    "        data[c + f'_l{lag}'] = data[c].shift(lag)\n",
    "\n",
    "data = data.dropna().reset_index(drop=True)\n",
    "data['t_idx'] = pd.PeriodIndex(data[COL_DATE], freq='Q').to_timestamp()\n",
    "data['const'] = 1.0  # Add constant\n",
    "data.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "c5430a7dc571a7a2",
   "metadata": {
    "id": "cell_015"
   },
   "source": [
    "## 2. Plots and unit-root diagnostics\n",
    "Plot post-WWII (From 1960-) monthly series and compute ADF statistics for stationarity analysis.\n",
    "- Real consumption on expenditure on nondurables per capita $c_{t}$ and its ratio $c_{t+1} / c_{t}$\n",
    "- Real consumption on nondurables and services per capita $c_{t}^{*}$ and its ratio $c_{t+1}^{*} / c_{t}^{*}$\n",
    "- Value weighted aggregate stock returns $r_{t+1}$\n",
    "- Equally weighted aggregate stock returns $r_{t+1}^{*}$"
   ]
  },
  {
   "cell_type": "code",
   "id": "fe0abe1d5f5443b9",
   "metadata": {
    "id": "cell_016"
   },
   "source": [
    "# Plot 3x2 panel of time series\n",
    "fig, axes = plt.subplots(3, 2, figsize=(12, 9), sharex=True)\n",
    "plot_specs = [\n",
    "    ('cons_nds_pc', 'Real nondurables per capita $c_t$', 'Real dollars (per capita)', 'tab:blue'),\n",
    "    ('cons_nds_pc_ratio', r'Growth ratio $c_{t+1}/c_t$ (nondurables)', '', 'tab:orange'),\n",
    "    ('cons_nds_svc_pc', r'Real nondurables + services per capita $c_t^{*}$', 'Real dollars (per capita)', 'tab:green'),\n",
    "    ('cons_nds_svc_pc_ratio', r'Growth ratio $c_{t+1}^{*}/c_t^{*}$', '', 'tab:red'),\n",
    "    ('ret_vw', r'Value-weighted return $r_{t+1}$', 'Net return', 'tab:purple'),\n",
    "    ('ret_ew', r'Equal-weighted return $r_{t+1}^{*}$', '', 'tab:brown'),\n",
    "]\n",
    "\n",
    "for ax, (col, title, ylabel, color) in zip(axes.ravel(), plot_specs):\n",
    "    ax.plot(plot_df.index, plot_df[col], color=color)\n",
    "    ax.set_title(title)\n",
    "    if ylabel:\n",
    "        ax.set_ylabel(ylabel)\n",
    "    ax.grid(True, linestyle=':', linewidth=0.6, alpha=0.7)\n",
    "    ax.xaxis.set_major_locator(mdates.YearLocator(base=10))\n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n",
    "\n",
    "for ax in axes[2, :]:\n",
    "    ax.set_xlabel('Quarter')\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ADF unit-root tests\n",
    "if HAS_SM:\n",
    "    adf_results = []\n",
    "    for col, title, _, _ in plot_specs:\n",
    "        series = plot_df[col].dropna()\n",
    "        if len(series) >= 25:\n",
    "            stat, pvalue, lags, nobs, *_ = adfuller(series, autolag='AIC')\n",
    "            adf_results.append({'series': title, 'test_stat': stat, 'p_value': pvalue, 'lags': lags, 'nobs': nobs})\n",
    "    display(pd.DataFrame(adf_results))\n",
    "else:\n",
    "    print('statsmodels not installed; ADF tests skipped.')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a9ed1f78519baabf",
   "metadata": {
    "id": "cell_017"
   },
   "source": [
    "## 3. Generalized Method of Moments (GMM)\n",
    "\n",
    "GMM is a general estimation framework based on population moment conditions. Suppose we have a model with parameter vector $\\theta \\in \\mathbb{R}^p$ and moment conditions:\n",
    "\n",
    "$$\n",
    "\\mathbb{E}[g(y_t, \\theta_0)] = 0\n",
    "$$\n",
    "\n",
    "where $g: \\mathbb{R}^d \\times \\mathbb{R}^p \\to \\mathbb{R}^L$ is a vector of $L$ moment functions and $\\theta_0$ is the true parameter.\n",
    "\n",
    "### 3.1 GMM estimation procedure\n",
    "\n",
    "**Step 1: Sample moments**\n",
    "\n",
    "From observed data $\\{y_t\\}_{t=1}^T$, construct the sample moment average:\n",
    "$$\n",
    "\\bar{g}_T(\\theta) = \\frac{1}{T} \\sum_{t=1}^T g(y_t, \\theta)\n",
    "$$\n",
    "\n",
    "**Step 2: GMM criterion**\n",
    "\n",
    "Choose $\\theta$ to minimize the quadratic form:\n",
    "$$\n",
    "Q_T(\\theta) = \\bar{g}_T(\\theta)^\\top W \\bar{g}_T(\\theta)\n",
    "$$\n",
    "\n",
    "where $W$ is a positive semi-definite weighting matrix.\n",
    "\n",
    "**Step 3: Two-step efficient GMM**\n",
    "\n",
    "1. **First step**: Use $W = I$ (identity matrix) to get initial estimate $\\hat{\\theta}_1$\n",
    "2. **Second step**: Use optimal weighting matrix $W = \\hat{S}^{-1}$ where $\\hat{S}$ is the long-run covariance of moments:\n",
    "   $$\n",
    "   S = \\lim_{T \\to \\infty} \\text{Var}(\\sqrt{T} \\bar{g}_T(\\theta_0))\n",
    "   $$\n",
    "\n",
    "**Step 4: Asymptotic inference**\n",
    "\n",
    "Under regularity conditions, the efficient GMM estimator is asymptotically normal:\n",
    "$$\n",
    "\\sqrt{T}(\\hat{\\theta} - \\theta_0) \\xrightarrow{d} N(0, V)\n",
    "$$\n",
    "\n",
    "where $V = (D^\\top W D)^{-1}$ and $D = \\mathbb{E}[\\nabla_\\theta g(y_t, \\theta_0)]$ is the Jacobian of moments.\n",
    "\n",
    "**Step 5: Overidentification test (J-test)**\n",
    "\n",
    "When $L > p$ (more moments than parameters), we can test model specification:\n",
    "$$\n",
    "J = T \\bar{g}_T(\\hat{\\theta})^\\top \\hat{S}^{-1} \\bar{g}_T(\\hat{\\theta}) \\xrightarrow{d} \\chi^2_{L-p}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mqhzzllrsi",
   "metadata": {
    "id": "cell_018"
   },
   "source": [
    "### 3.2 General GMM implementation\n",
    "\n",
    "We implement a general-purpose GMM estimator that can be applied to any model with moment conditions."
   ]
  },
  {
   "cell_type": "code",
   "id": "hr3idg4mkmc",
   "metadata": {
    "id": "cell_019"
   },
   "source": [
    "def nw_lags(T: int) -> int:\n",
    "    \"\"\"Newey-West lag selection rule (Andrews 1991).\"\"\"\n",
    "    return max(0, int(4 * (T/100.0)**(2.0/9.0)))\n",
    "\n",
    "def hac_covariance(G: np.ndarray, L: Optional[int] = None) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Newey-West HAC estimator for long-run covariance.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    G : np.ndarray, shape (T, L)\n",
    "        Time series of moment conditions (T observations, L moments)\n",
    "    L : int, optional\n",
    "        Number of lags for Newey-West. If None, uses automatic selection.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    S : np.ndarray, shape (L, L)\n",
    "        HAC covariance matrix for sqrt(T) * gbar\n",
    "    \"\"\"\n",
    "    T, Lm = G.shape\n",
    "    if L is None:\n",
    "        L = nw_lags(T)\n",
    "    \n",
    "    # Center moments\n",
    "    Gc = G - G.mean(axis=0, keepdims=True)\n",
    "    \n",
    "    # Gamma_0 (contemporaneous covariance)\n",
    "    S = (Gc.T @ Gc) / T\n",
    "    \n",
    "    # Add weighted autocovariances\n",
    "    for ell in range(1, L+1):\n",
    "        w = 1.0 - ell / (L + 1.0)  # Bartlett kernel\n",
    "        Gamma_ell = (Gc[ell:].T @ Gc[:-ell]) / T\n",
    "        S = S + w * (Gamma_ell + Gamma_ell.T)\n",
    "    \n",
    "    return S\n",
    "\n",
    "def numerical_jacobian(moment_fn, theta, eps=1e-6):\n",
    "    \"\"\"\n",
    "    Compute numerical Jacobian of moment function.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    moment_fn : callable\n",
    "        Function that takes theta and returns gbar (L-vector)\n",
    "    theta : np.ndarray\n",
    "        Parameter vector (p-dimensional)\n",
    "    eps : float\n",
    "        Step size for numerical differentiation\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    D : np.ndarray, shape (L, p)\n",
    "        Jacobian matrix d(gbar)/d(theta)\n",
    "    \"\"\"\n",
    "    g0 = moment_fn(theta)\n",
    "    p = len(theta)\n",
    "    L = g0.size\n",
    "    D = np.zeros((L, p))\n",
    "    \n",
    "    for j in range(p):\n",
    "        theta_plus = np.array(theta, dtype=float)\n",
    "        theta_plus[j] += eps\n",
    "        gj = moment_fn(theta_plus)\n",
    "        D[:, j] = (gj - g0) / eps\n",
    "    \n",
    "    return D\n",
    "\n",
    "def gmm_criterion(theta, moment_fn, W):\n",
    "    \"\"\"GMM objective function Q_T(theta) = gbar' * W * gbar.\"\"\"\n",
    "    g = moment_fn(theta)\n",
    "    return float(g.T @ W @ g)\n",
    "\n",
    "def gmm_estimate(moment_fn, theta0, bounds=None, W=None, n_step=1, hac_lags=None):\n",
    "    \"\"\"\n",
    "    General two-step GMM estimator.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    moment_fn : callable\n",
    "        Function that takes theta and returns gbar (sample moments)\n",
    "    theta0 : array-like\n",
    "        Initial parameter guess\n",
    "    bounds : list of tuples, optional\n",
    "        Parameter bounds for optimization\n",
    "    W : np.ndarray, optional\n",
    "        Initial weighting matrix. If None, uses identity.\n",
    "    n_step : int\n",
    "        Number of steps: 1 (one-step), 2 (two-step), -1 (iterated)\n",
    "    hac_lags : int, optional\n",
    "        Lags for HAC covariance estimation\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    theta_hat : np.ndarray\n",
    "        GMM parameter estimate\n",
    "    V : np.ndarray\n",
    "        Asymptotic covariance matrix\n",
    "    W : np.ndarray\n",
    "        Final weighting matrix used\n",
    "    S : np.ndarray\n",
    "        HAC covariance of moments\n",
    "    \"\"\"\n",
    "    # First step: identity weighting\n",
    "    g0 = moment_fn(theta0)\n",
    "    L = g0.size\n",
    "    if W is None:\n",
    "        W = np.eye(L)\n",
    "    \n",
    "    res = opt.minimize(gmm_criterion, np.array(theta0, dtype=float), \n",
    "                      args=(moment_fn, W), method='L-BFGS-B', bounds=bounds)\n",
    "    theta1 = res.x\n",
    "    \n",
    "    if n_step == 1:\n",
    "        # Single-step GMM (not efficient)\n",
    "        D = numerical_jacobian(moment_fn, theta1)\n",
    "        M = D.T @ W @ D\n",
    "        Minv = la.pinv(M)\n",
    "        V = Minv  # Simplified, not accounting for S\n",
    "        return theta1, V, W, None\n",
    "\n",
    "    elif n_step == 2:\n",
    "        # Second step: efficient weighting with HAC\n",
    "        # Need moment time series to compute S - this requires moment_matrix_fn\n",
    "        # For now, return first-step estimate\n",
    "        # (Full implementation requires moment_matrix_fn returning G_t)\n",
    "        assert 0, \"Two-step GMM not implemented!\"\n",
    "\n",
    "    elif n_step == -1:\n",
    "        assert 0, \"Interated GMM not implemented!\"\n",
    "\n",
    "    else:\n",
    "        return theta1, None, W, None\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "2j8q326vuk",
   "metadata": {
    "id": "cell_020"
   },
   "source": [
    "### 3.3 Hansen-Singleton Euler equation model\n",
    "\n",
    "We now apply GMM to test consumption-based asset pricing. The representative agent's Euler equation implies:\n",
    "\n",
    "$$\n",
    "1 = \\mathbb{E}_t\\left[ M_{t+1} \\cdot R_{t+1,k} \\right]\n",
    "$$\n",
    "\n",
    "where $M_{t+1} = \\beta \\frac{u'(c_{t+1})}{u'(c_t)}$ is the stochastic discount factor (SDF) and $R_{t+1,k}$ is the gross return on asset $k$.\n",
    "\n",
    "**CRRA utility:** $u(c) = \\frac{c^{1+\\alpha}}{1+\\alpha}$\n",
    "\n",
    "The marginal utility is $u'(c) = c^\\alpha$, so:\n",
    "$$\n",
    "M_{t+1} = \\beta \\left(\\frac{c_{t+1}}{c_t}\\right)^\\alpha\n",
    "$$\n",
    "\n",
    "Parameters: $\\theta = (\\alpha, \\beta)$ where $\\alpha$ is relative risk aversion and $\\beta$ is the discount factor.\n",
    "\n",
    "**CARA utility:** $u(c) = -e^{-\\gamma c}$\n",
    "\n",
    "The marginal utility is $u'(c) = \\gamma e^{-\\gamma c}$, so:\n",
    "$$\n",
    "M_{t+1} = \\beta e^{-\\gamma(c_{t+1} - c_t)}\n",
    "$$\n",
    "\n",
    "Parameters: $\\theta = (\\gamma, \\beta)$ where $\\gamma$ is absolute risk aversion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qa7wzqp79m9",
   "metadata": {
    "id": "cell_021"
   },
   "source": [
    "**Moment conditions with instruments**\n",
    "\n",
    "Using instruments $x_t$ (information known at time $t$), the unconditional moment conditions are:\n",
    "$$\n",
    "\\mathbb{E}[x_t \\cdot (M_{t+1} R_{t+1,k} - 1)] = 0\n",
    "$$\n",
    "\n",
    "With $K$ assets and $L_x$ instruments, we have $L = K \\times L_x$ moment conditions.\n",
    "\n",
    "_e.g.,_ For instance, if we are using CRRA utility using NDS (Consumption with non-durables and services), EWR (Equally-weighted Gross Return) and one of their lagged terms as instruments, then our moment conditions becomes:\n",
    "$$\n",
    "\\mathbb{E}\\left[\\begin{pmatrix} 1\\\\ \\frac{c_t^{*}}{c_{t-1}^{*}}\\\\ r_{t}^{*} \\end{pmatrix}\n",
    "    \\cdot \\left(r_{t+1}^{*}\\beta\\left(\\frac{c_{t+1}^{*}}{c_t^{*}}\\right)^{\\alpha}-1\\right)\\right] = 0 \\\\\n",
    "$$\n",
    "\n",
    "**Sample moments**\n",
    "\n",
    "For each time $t$, the moment vector is:\n",
    "$$\n",
    "g_t(\\theta) = \\text{vec}(x_t \\otimes (M_{t+1}(\\theta) R_{t+1} - \\mathbf{1}_K)^\\top)\n",
    "$$\n",
    "\n",
    "The sample average is:\n",
    "$$\n",
    "\\bar{g}_T(\\theta) = \\frac{1}{T} \\sum_{t=1}^T g_t(\\theta)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783odxh3kde",
   "metadata": {
    "id": "cell_022"
   },
   "source": [
    "### 3.4 Implementation for Hansen-Singleton model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lb7tp0k6bim",
   "metadata": {
    "id": "cell_023"
   },
   "source": [
    "**Interpretation of estimates**\n",
    "\n",
    "- **CRRA** ($\\alpha$): Coefficient of relative risk aversion. If $\\alpha < 0$, the utility function is convex (risk-loving), which is economically implausible.\n",
    "- **CARA** ($\\gamma$): Coefficient of absolute risk aversion. Higher $\\gamma$ means more risk-averse.\n",
    "- **$\\beta$**: Subjective discount factor. Should be close to 1 (e.g., 0.96 corresponds to ~4% time preference).\n",
    "\n",
    "Hansen & Singleton (1982) found:\n",
    "- 10 out of 12 specifications rejected at 5% level\n",
    "- Remaining specifications with $\\alpha > 0$ (convex utility) are economically implausible\n",
    "- This is the \"equity premium puzzle\": consumption-based models struggle to match asset returns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34z6g85adm",
   "metadata": {
    "id": "cell_024"
   },
   "source": [
    "### 3.5 Unified configuration system\n",
    "\n",
    "We now create a comprehensive configuration system that allows specifying all aspects of GMM estimation through a single object."
   ]
  },
  {
   "cell_type": "code",
   "id": "tpl7fhcrtsk",
   "metadata": {
    "id": "cell_025"
   },
   "source": [
    "@dataclass\n",
    "class GMMConfig:\n",
    "    \"\"\"Configuration for Hansen-Singleton GMM estimation.\"\"\"\n",
    "    util: str  # 'CRRA' or 'CARA'\n",
    "    returns_cols: List[str]\n",
    "    instruments: List[str]\n",
    "    cons_col: str\n",
    "    cons_ratio_col: str\n",
    "    cons_f1_col: str\n",
    "    beta_bounds: tuple = (1e-5, 0.9999)\n",
    "    alpha_bounds: tuple = (-8.0, 4.0)    # CRRA\n",
    "    gamma_bounds: tuple = (1e-5, 50.0)   # CARA\n",
    "    hac_lags: Optional[int] = None\n",
    "\n",
    "@dataclass\n",
    "class EstimationSpec:\n",
    "    \"\"\"\n",
    "    Complete specification for a GMM estimation.\n",
    "    \n",
    "    This class encapsulates all aspects of what to estimate:\n",
    "    - Model choice (utility function)\n",
    "    - Data selection (consumption, returns)\n",
    "    - Instruments\n",
    "    - Sample period\n",
    "    - Parameter restrictions\n",
    "    - Estimation method\n",
    "    \"\"\"\n",
    "    \n",
    "    # Identification\n",
    "    name: str\n",
    "    \n",
    "    # Model specification\n",
    "    utility: str  # 'CRRA' or 'CARA'\n",
    "    \n",
    "    # Data selection\n",
    "    consumption_var: str  # Column name for consumption\n",
    "    returns: List[str]    # List of return column names\n",
    "    \n",
    "    # Instruments\n",
    "    instruments: List[str]  # List of instrument column names\n",
    "    \n",
    "    # Sample period\n",
    "    sample_start: Optional[str] = None  # YYYY-MM-DD or None for full sample\n",
    "    sample_end: Optional[str] = None\n",
    "    \n",
    "    # Parameter restrictions (e.g., {'beta': 0.96} to fix beta)\n",
    "    restrictions: Optional[Dict[str, float]] = None\n",
    "    \n",
    "    # Estimation options\n",
    "    gmm_method: str = 'one-step'  # 'one-step', 'two-step', or 'iterated'\n",
    "    max_iter: int = 10            # Maximum iterations for iterated GMM\n",
    "    iter_tol: float = 1e-6        # Convergence tolerance for iterated GMM\n",
    "    hac_lags: Optional[int] = None  # None for automatic selection\n",
    "    \n",
    "    # Optimization\n",
    "    initial_values: Optional[Dict[str, float]] = None\n",
    "    bounds: Optional[Dict[str, Tuple[float, float]]] = None\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        \"\"\"Set default bounds if not provided.\"\"\"\n",
    "        if self.bounds is None:\n",
    "            if self.utility.upper() == 'CRRA':\n",
    "                self.bounds = {'alpha': (-8.0, 4.0), 'beta': (0.01, 0.9999)}\n",
    "            else:  # CARA\n",
    "                self.bounds = {'gamma': (1e-5, 50.0), 'beta': (0.01, 0.9999)}\n",
    "        \n",
    "        # Set default initial values if not provided\n",
    "        if self.initial_values is None:\n",
    "            if self.utility.upper() == 'CRRA':\n",
    "                self.initial_values = {'alpha': -1.0, 'beta': 0.95}\n",
    "            else:  # CARA\n",
    "                self.initial_values = {'gamma': 1.0, 'beta': 0.95}\n",
    "        \n",
    "        # Initialize restrictions dict if None\n",
    "        if self.restrictions is None:\n",
    "            self.restrictions = {}\n",
    "    \n",
    "    def get_param_names(self) -> List[str]:\n",
    "        \"\"\"Get list of parameter names for this specification.\"\"\"\n",
    "        if self.utility.upper() == 'CRRA':\n",
    "            base = ['alpha', 'beta']\n",
    "        else:\n",
    "            base = ['gamma', 'beta']\n",
    "        \n",
    "        # Remove restricted parameters\n",
    "        return [p for p in base if p not in self.restrictions]\n",
    "    \n",
    "    def get_free_params(self) -> List[str]:\n",
    "        \"\"\"Get list of free (non-restricted) parameters.\"\"\"\n",
    "        return self.get_param_names()\n",
    "    \n",
    "    def specification_string(self) -> str:\n",
    "        \"\"\"Generate human-readable specification description.\"\"\"\n",
    "        lines = [\n",
    "            f\"Specification: {self.name}\",\n",
    "            f\"Utility: {self.utility}\",\n",
    "            f\"Consumption: {self.consumption_var}\",\n",
    "            f\"Returns: {', '.join(self.returns)}\",\n",
    "            f\"Instruments: {len(self.instruments)} ({', '.join(self.instruments[:3])}{'...' if len(self.instruments) > 3 else ''})\",\n",
    "            f\"Sample: {self.sample_start or 'start'} to {self.sample_end or 'end'}\",\n",
    "            f\"Method: {self.gmm_method}\",\n",
    "        ]\n",
    "        if self.restrictions:\n",
    "            lines.append(f\"Restrictions: {self.restrictions}\")\n",
    "        return '\\n'.join(lines)\n",
    "    \n",
    "    def to_dict(self) -> Dict:\n",
    "        \"\"\"Convert to dictionary for serialization.\"\"\"\n",
    "        return {\n",
    "            'name': self.name,\n",
    "            'utility': self.utility,\n",
    "            'consumption_var': self.consumption_var,\n",
    "            'returns': self.returns,\n",
    "            'instruments': self.instruments,\n",
    "            'sample_start': self.sample_start,\n",
    "            'sample_end': self.sample_end,\n",
    "            'restrictions': self.restrictions,\n",
    "            'gmm_method': self.gmm_method,\n",
    "            'max_iter': self.max_iter,\n",
    "            'iter_tol': self.iter_tol,\n",
    "            'hac_lags': self.hac_lags,\n",
    "        }"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1z5p8yluh5s",
   "metadata": {
    "id": "cell_026"
   },
   "source": [
    "@dataclass\n",
    "class EstimationResult:\n",
    "    \"\"\"\n",
    "    Results from GMM estimation.\n",
    "    \n",
    "    This class contains all estimation results and provides methods\n",
    "    for displaying and exporting them.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Original specification\n",
    "    spec: EstimationSpec\n",
    "    \n",
    "    # Parameter estimates\n",
    "    theta: np.ndarray          # Full parameter vector (including restricted)\n",
    "    theta_free: np.ndarray     # Free parameters only\n",
    "    se: np.ndarray             # Standard errors (free parameters)\n",
    "    t_stats: np.ndarray        # t-statistics (free parameters)\n",
    "    param_names: List[str]     # All parameter names\n",
    "    free_param_names: List[str]  # Free parameter names\n",
    "    \n",
    "    # Covariance matrices\n",
    "    V: np.ndarray              # Asymptotic variance of free parameters\n",
    "    S: np.ndarray              # HAC covariance of moments\n",
    "    W: np.ndarray              # Weighting matrix\n",
    "    \n",
    "    # Diagnostics\n",
    "    J_stat: float              # J-test statistic\n",
    "    J_pvalue: float            # J-test p-value\n",
    "    J_dof: int                 # Degrees of freedom\n",
    "    \n",
    "    # Sample information\n",
    "    n_obs: int                 # Number of observations\n",
    "    n_moments: int             # Number of moment conditions\n",
    "    n_params: int              # Number of free parameters\n",
    "    \n",
    "    # Convergence\n",
    "    converged: bool\n",
    "    \n",
    "    def get_param_dict(self) -> Dict[str, float]:\n",
    "        \"\"\"Get parameter estimates as dictionary.\"\"\"\n",
    "        return dict(zip(self.param_names, self.theta))\n",
    "    \n",
    "    def get_se_dict(self) -> Dict[str, float]:\n",
    "        \"\"\"Get standard errors as dictionary (free params only).\"\"\"\n",
    "        return dict(zip(self.free_param_names, self.se))\n",
    "    \n",
    "    def summary(self, decimals: int = 4) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Generate summary table of results.\n",
    "        \n",
    "        Returns DataFrame with columns: parameter, estimate, std_error, t_stat\n",
    "        \"\"\"\n",
    "        rows = []\n",
    "        param_dict = self.get_param_dict()\n",
    "        \n",
    "        for i, pname in enumerate(self.free_param_names):\n",
    "            rows.append({\n",
    "                'Parameter': pname,\n",
    "                'Estimate': round(self.theta_free[i], decimals),\n",
    "                'Std. Error': round(self.se[i], decimals),\n",
    "                't-stat': round(self.t_stats[i], decimals)\n",
    "            })\n",
    "        \n",
    "        # Add restricted parameters (no SE)\n",
    "        for pname in self.spec.restrictions:\n",
    "            rows.append({\n",
    "                'Parameter': pname,\n",
    "                'Estimate': round(self.spec.restrictions[pname], decimals),\n",
    "                'Std. Error': '--',\n",
    "                't-stat': '--'\n",
    "            })\n",
    "        \n",
    "        df = pd.DataFrame(rows)\n",
    "        return df\n",
    "    \n",
    "    def summary_string(self) -> str:\n",
    "        \"\"\"Generate formatted string summary using tabulate.\"\"\"\n",
    "        from tabulate import tabulate\n",
    "\n",
    "        lines = [\n",
    "            \"=\" * 70,\n",
    "            self.spec.specification_string(),\n",
    "            \"=\" * 70,\n",
    "            \"\\nParameter Estimates:\",\n",
    "        ]\n",
    "        \n",
    "        # Create table data\n",
    "        table_data = []\n",
    "        for i, pname in enumerate(self.free_param_names):\n",
    "            table_data.append([\n",
    "                pname,\n",
    "                f\"{self.theta_free[i]:.4f}\",\n",
    "                f\"{self.se[i]:.4f}\",\n",
    "                f\"{self.t_stats[i]:.4f}\"\n",
    "            ])\n",
    "        \n",
    "        # Add restricted parameters\n",
    "        for pname in self.spec.restrictions:\n",
    "            table_data.append([\n",
    "                pname,\n",
    "                f\"{self.spec.restrictions[pname]:.4f}\",\n",
    "                \"(fixed)\",\n",
    "                \"--\"\n",
    "            ])\n",
    "        \n",
    "        # Format with tabulate\n",
    "        headers = [\"Parameter\", \"Estimate\", \"Std. Error\", \"t-stat\"]\n",
    "        table_str = tabulate(table_data, headers=headers, tablefmt=\"grid\")\n",
    "        lines.append(table_str)\n",
    "        \n",
    "        # Add diagnostics\n",
    "        lines.extend([\n",
    "            \"\",\n",
    "            f\"Observations: {self.n_obs}\",\n",
    "            f\"Moments: {self.n_moments}\",\n",
    "            f\"Parameters: {self.n_params}\",\n",
    "            f\"\",\n",
    "            f\"J-statistic: {self.J_stat:.4f}\",\n",
    "            f\"J p-value: {self.J_pvalue:.4f}\",\n",
    "            f\"Degrees of freedom: {self.J_dof}\",\n",
    "            f\"Converged: {self.converged}\",\n",
    "            \"=\" * 70,\n",
    "        ])\n",
    "        \n",
    "        return '\\n'.join(lines)\n",
    "    \n",
    "    def to_latex(self, caption: str = None, label: str = None) -> str:\n",
    "        \"\"\"\n",
    "        Export results as LaTeX table.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        caption : str, optional\n",
    "            Table caption\n",
    "        label : str, optional\n",
    "            Table label for cross-referencing\n",
    "        \"\"\"\n",
    "        df = self.summary()\n",
    "        \n",
    "        # Format for LaTeX\n",
    "        latex_lines = [\n",
    "            \"\\\\begin{table}[htbp]\",\n",
    "            \"\\\\centering\",\n",
    "        ]\n",
    "        \n",
    "        if caption:\n",
    "            latex_lines.append(f\"\\\\caption{{{caption}}}\")\n",
    "        if label:\n",
    "            latex_lines.append(f\"\\\\label{{{label}}}\")\n",
    "        \n",
    "        # Convert DataFrame to latex\n",
    "        latex_table = df.to_latex(\n",
    "            index=False,\n",
    "            float_format=\"%.4f\",\n",
    "            na_rep=\"--\",\n",
    "            column_format=\"lrrr\"\n",
    "        )\n",
    "        \n",
    "        latex_lines.append(latex_table)\n",
    "        \n",
    "        # Add notes\n",
    "        latex_lines.extend([\n",
    "            f\"\\\\multicolumn{{4}}{{l}}{{\\\\textit{{Notes:}} $N={self.n_obs}$, \",\n",
    "            f\"$J={self.J_stat:.2f}$ (p={self.J_pvalue:.3f})}}\\\\\\\\\",\n",
    "            \"\\\\end{table}\",\n",
    "        ])\n",
    "        \n",
    "        return '\\n'.join(latex_lines)\n",
    "    \n",
    "    def __str__(self) -> str:\n",
    "        \"\"\"String representation.\"\"\"\n",
    "        return self.summary_string()\n",
    "    \n",
    "    def __repr__(self) -> str:\n",
    "        \"\"\"REPL representation.\"\"\"\n",
    "        return f\"EstimationResult('{self.spec.name}', n_obs={self.n_obs}, J={self.J_stat:.2f})\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "helper_run_all_methods",
   "metadata": {
    "id": "helper_run_all_methods"
   },
   "source": [
    "@dataclass\n",
    "class SpecificationRunner:\n",
    "    \"\"\"\n",
    "    Run multiple specifications and organize results.\n",
    "\n",
    "    Streamlined version that returns DataFrames for flexible display and export.\n",
    "    \"\"\"\n",
    "\n",
    "    results: List = None\n",
    "\n",
    "    def __post_init__(self):\n",
    "        if self.results is None:\n",
    "            self.results = []\n",
    "\n",
    "    def run_specs(self, specifications: List[EstimationSpec], data: pd.DataFrame,\n",
    "                  methods: List[str] = None, verbose: bool = True):\n",
    "        \"\"\"\n",
    "        Run list of specifications with multiple GMM methods.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        specifications : List[EstimationSpec]\n",
    "            List of manually defined specifications\n",
    "        data : pd.DataFrame\n",
    "            Data for estimation\n",
    "        methods : List[str], optional\n",
    "            GMM methods to run. Default: ['one-step', 'two-step', 'iterated']\n",
    "        verbose : bool\n",
    "            Show progress\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        self (for method chaining)\n",
    "        \"\"\"\n",
    "        import copy\n",
    "\n",
    "        if methods is None:\n",
    "            methods = ['one-step', 'two-step', 'iterated']\n",
    "\n",
    "        total = len(specifications) * len(methods)\n",
    "        count = 0\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Running {len(specifications)} specifications Ã— {len(methods)} methods = {total} estimations\\n\")\n",
    "\n",
    "        for spec in specifications:\n",
    "            for method in methods:\n",
    "                count += 1\n",
    "\n",
    "                # Create copy with specified method\n",
    "                spec_copy = copy.deepcopy(spec)\n",
    "                spec_copy.gmm_method = method\n",
    "\n",
    "                if verbose:\n",
    "                    print(f\"[{count}/{total}] {spec.name} ({method})...\", end=' ')\n",
    "\n",
    "                try:\n",
    "                    result = estimate_gmm(spec_copy, data)\n",
    "                    self.results.append(result)\n",
    "                    if verbose:\n",
    "                        print(\"âœ“\")\n",
    "                except Exception as e:\n",
    "                    if verbose:\n",
    "                        print(f\"âœ— Error: {e}\")\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"\\nâœ“ Completed {count} estimations\")\n",
    "\n",
    "        return self\n",
    "\n",
    "    def _extract_nlag(self, result) -> int:\n",
    "        \"\"\"Extract NLAG from instruments (count consumption lags).\"\"\"\n",
    "        cons_var = result.spec.consumption_var\n",
    "        nlag = sum(1 for inst in result.spec.instruments\n",
    "                   if f'{cons_var}_ratio_l' in inst)\n",
    "        return nlag if nlag > 0 else 1\n",
    "\n",
    "    def _format_returns(self, returns: List[str]) -> str:\n",
    "        \"\"\"Format return variable names.\"\"\"\n",
    "        return_map = {\n",
    "            'ret_ew_gross': 'EW',\n",
    "            'ret_vw_gross': 'VW',\n",
    "            'rf_gross': 'RF'\n",
    "        }\n",
    "        formatted = [return_map.get(r, r) for r in returns]\n",
    "        return '+'.join(formatted)\n",
    "\n",
    "    def _format_consumption(self, cons_var: str) -> str:\n",
    "        \"\"\"Format consumption variable name.\"\"\"\n",
    "        cons_map = {\n",
    "            'cons_nds_pc': 'NDS',\n",
    "            'cons_nds_svc_pc': 'NDS+SVC'\n",
    "        }\n",
    "        return cons_map.get(cons_var, cons_var)\n",
    "\n",
    "    def to_dataframe(self,\n",
    "                     by_method: bool = True,\n",
    "                     include_se: bool = True,\n",
    "                     diagnostics: List[str] = None,\n",
    "                     decimals: int = 4) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Convert results to DataFrame (replaces display_table).\n",
    "\n",
    "        Returns one row per model with columns for specification and estimates.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        by_method : bool, default True\n",
    "            If True, include 'Method' column\n",
    "            If False, assumes filtering by method happens externally\n",
    "        include_se : bool, default True\n",
    "            Include standard error columns\n",
    "        diagnostics : List[str], optional\n",
    "            Additional columns to include:\n",
    "            - 'N': Number of observations\n",
    "            - 'Moments': Number of moment conditions\n",
    "            - 'J_stat': J-statistic (Ï‡Â²)\n",
    "            - 'J_pval': J-test p-value\n",
    "            - 'DOF': Degrees of freedom\n",
    "            - 'Converged': Convergence status\n",
    "        decimals : int\n",
    "            Decimal places for rounding\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        pd.DataFrame with one row per model\n",
    "\n",
    "        Example:\n",
    "        --------\n",
    "        >>> df = runner.to_dataframe(diagnostics=['J_stat', 'J_pval', 'DOF'])\n",
    "        >>> print(df)\n",
    "        >>> df.to_excel('results.xlsx')\n",
    "        \"\"\"\n",
    "        if not self.results:\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        if diagnostics is None:\n",
    "            diagnostics = []\n",
    "\n",
    "        # Build rows\n",
    "        data_rows = []\n",
    "        for result in self.results:\n",
    "            # Determine parameter names based on utility\n",
    "            if result.spec.utility == 'CARA':\n",
    "                param1_name = 'gamma'\n",
    "            else:  # CRRA\n",
    "                param1_name = 'alpha'\n",
    "\n",
    "            theta = result.theta\n",
    "            se = result.se\n",
    "\n",
    "            # Base columns\n",
    "            row = {\n",
    "                'Consumption': self._format_consumption(result.spec.consumption_var),\n",
    "                'Returns': self._format_returns(result.spec.returns),\n",
    "                'NLAG': self._extract_nlag(result),\n",
    "                param1_name: round(theta[0], decimals),\n",
    "                'beta': round(theta[1], decimals)\n",
    "            }\n",
    "\n",
    "            # Add method column if requested\n",
    "            if by_method:\n",
    "                row = {'Method': result.spec.gmm_method, **row}\n",
    "\n",
    "            # Add standard errors\n",
    "            if include_se:\n",
    "                row[f'se_{param1_name}'] = round(se[0], decimals)\n",
    "                row['se_beta'] = round(se[1], decimals)\n",
    "\n",
    "            # Add optional diagnostics\n",
    "            if 'N' in diagnostics:\n",
    "                row['N'] = result.n_obs\n",
    "            if 'Moments' in diagnostics:\n",
    "                row['Moments'] = result.n_moments\n",
    "            if 'J_stat' in diagnostics:\n",
    "                row['J_stat'] = round(result.J_stat, decimals)\n",
    "            if 'J_pval' in diagnostics:\n",
    "                row['J_pval'] = round(result.J_pvalue, decimals)\n",
    "            if 'DOF' in diagnostics:\n",
    "                row['DOF'] = result.J_dof\n",
    "            if 'Converged' in diagnostics:\n",
    "                row['Converged'] = result.converged\n",
    "\n",
    "            data_rows.append(row)\n",
    "\n",
    "        return pd.DataFrame(data_rows)\n",
    "\n",
    "    def to_dataframe_by_method(self, method: str, **kwargs) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Get DataFrame for specific GMM method.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        method : str\n",
    "            GMM method: 'one-step', 'two-step', or 'iterated'\n",
    "        **kwargs : passed to to_dataframe()\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        pd.DataFrame filtered to specified method\n",
    "        \"\"\"\n",
    "        df = self.to_dataframe(by_method=True, **kwargs)\n",
    "        return df[df['Method'] == method].drop(columns=['Method']).reset_index(drop=True)\n",
    "\n",
    "    def to_excel(self, filepath: str,\n",
    "                 include_se: bool = True,\n",
    "                 diagnostics: List[str] = None,\n",
    "                 decimals: int = 4):\n",
    "        \"\"\"\n",
    "        Export results to Excel with separate sheets per GMM method.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        filepath : str\n",
    "            Output Excel file path\n",
    "        include_se : bool\n",
    "            Include standard error columns\n",
    "        diagnostics : List[str]\n",
    "            Optional diagnostic columns (see to_dataframe)\n",
    "        decimals : int\n",
    "            Decimal places\n",
    "        \"\"\"\n",
    "        if not self.results:\n",
    "            print(\"No results to export\")\n",
    "            return\n",
    "\n",
    "        with pd.ExcelWriter(filepath, engine='openpyxl') as writer:\n",
    "            # Sheet per method\n",
    "            for method in ['one-step', 'two-step', 'iterated']:\n",
    "                df = self.to_dataframe_by_method(\n",
    "                    method,\n",
    "                    include_se=include_se,\n",
    "                    diagnostics=diagnostics,\n",
    "                    decimals=decimals\n",
    "                )\n",
    "                if len(df) > 0:\n",
    "                    df.to_excel(writer, sheet_name=method, index=False)\n",
    "\n",
    "            # Combined sheet\n",
    "            df_all = self.to_dataframe(\n",
    "                by_method=True,\n",
    "                include_se=include_se,\n",
    "                diagnostics=diagnostics,\n",
    "                decimals=decimals\n",
    "            )\n",
    "            df_all.to_excel(writer, sheet_name='All_Methods', index=False)\n",
    "\n",
    "        print(f\"âœ“ Results exported to {filepath}\")\n",
    "\n",
    "    def display(self, by_method: bool = True, max_rows: int = None, **kwargs):\n",
    "        \"\"\"\n",
    "        Display results as formatted DataFrame.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        by_method : bool\n",
    "            If True, show separate tables per GMM method\n",
    "            If False, show single combined table\n",
    "        max_rows : int, optional\n",
    "            Maximum rows to display (None = all)\n",
    "        **kwargs : passed to to_dataframe()\n",
    "        \"\"\"\n",
    "        if by_method:\n",
    "            for method in ['one-step', 'two-step', 'iterated']:\n",
    "                df = self.to_dataframe_by_method(method, **kwargs)\n",
    "                if len(df) > 0:\n",
    "                    print(\"\\n\" + \"=\"*80)\n",
    "                    print(f\"{method.upper()} GMM\".center(80))\n",
    "                    print(\"=\"*80)\n",
    "                    if max_rows:\n",
    "                        print(df.head(max_rows).to_string(index=False))\n",
    "                    else:\n",
    "                        print(df.to_string(index=False))\n",
    "        else:\n",
    "            df = self.to_dataframe(by_method=True, **kwargs)\n",
    "            print(\"\\n\" + \"=\"*80)\n",
    "            print(\"ALL METHODS\".center(80))\n",
    "            print(\"=\"*80)\n",
    "            if max_rows:\n",
    "                print(df.head(max_rows).to_string(index=False))\n",
    "            else:\n",
    "                print(df.to_string(index=False))\n",
    "\n",
    "    def summary_stats(self):\n",
    "        \"\"\"Print summary statistics.\"\"\"\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"SUMMARY STATISTICS\")\n",
    "        print(\"=\"*80)\n",
    "\n",
    "        total = len(self.results)\n",
    "        rejected_05 = sum(1 for r in self.results if r.J_pvalue < 0.05)\n",
    "        rejected_10 = sum(1 for r in self.results if r.J_pvalue < 0.10)\n",
    "\n",
    "        print(f\"\\nTotal estimations: {total}\")\n",
    "        print(f\"Rejected at 5% (J-test): {rejected_05}/{total} ({100*rejected_05/total:.1f}%)\")\n",
    "        print(f\"Rejected at 10% (J-test): {rejected_10}/{total} ({100*rejected_10/total:.1f}%)\")\n",
    "        print(f\"Accepted at 5%: {total-rejected_05}/{total} ({100*(total-rejected_05)/total:.1f}%)\")\n",
    "\n",
    "        # By method\n",
    "        print(\"\\nBy GMM Method:\")\n",
    "        for method in ['one-step', 'two-step', 'iterated']:\n",
    "            method_results = [r for r in self.results if r.spec.gmm_method == method]\n",
    "            if method_results:\n",
    "                n = len(method_results)\n",
    "                rej = sum(1 for r in method_results if r.J_pvalue < 0.05)\n",
    "                print(f\"  {method}: {rej}/{n} rejected ({100*rej/n:.1f}%)\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.results)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"SpecificationRunner({len(self.results)} results)\"\n",
    ""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "7x6fee1hee",
   "metadata": {
    "id": "cell_029"
   },
   "source": [
    "### 3.6 Main estimation function\n",
    "\n",
    "The `estimate_gmm()` function is the unified interface for running GMM estimation with any specification."
   ]
  },
  {
   "metadata": {
    "id": "cell_030"
   },
   "cell_type": "code",
   "source": [
    "def build_moment_matrix(theta: np.ndarray, cfg: GMMConfig, df: pd.DataFrame) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Construct moment time series G_t for Hansen-Singleton model.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    theta : np.ndarray\n",
    "        Parameter vector (alpha/gamma, beta)\n",
    "    cfg : GMMConfig\n",
    "        Model configuration\n",
    "    df : pd.DataFrame\n",
    "        Data with returns, consumption, and instruments\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    G : np.ndarray, shape (T, L)\n",
    "        Moment matrix where L = (#instruments) * (#assets)\n",
    "        Each row is g_t = vec(x_t * (M_t*R_t - 1)')\n",
    "    \"\"\"\n",
    "    x = df[cfg.instruments].to_numpy()     # T x L_x\n",
    "    R = df[cfg.returns_cols].to_numpy()    # T x K (assets)\n",
    "    T, L_x = x.shape\n",
    "    K = R.shape[1]\n",
    "\n",
    "    # Compute stochastic discount factor\n",
    "    if cfg.util.upper() == 'CRRA':\n",
    "        alpha, beta = float(theta[0]), float(theta[1])\n",
    "        cr = df[cfg.cons_ratio_col].to_numpy()  # T vector\n",
    "        M = sdf_CRRA(cr.reshape(-1,1), alpha, beta)  # T x 1\n",
    "    else:\n",
    "        gamma, beta = float(theta[0]), float(theta[1])\n",
    "        c_next = df[cfg.cons_f1_col].to_numpy().reshape(-1,1)\n",
    "        c_now = df[cfg.cons_col].to_numpy().reshape(-1,1)\n",
    "        M = sdf_CARA(c_next, c_now, gamma, beta)  # T x 1\n",
    "\n",
    "    # Pricing errors: M * R - 1\n",
    "    resid = R * M - 1.0  # T x K\n",
    "\n",
    "    # Moments: x_t âŠ— resid_t, then vectorize\n",
    "    G = np.einsum('ti,tj->tij', x, resid)  # T x L_x x K\n",
    "    G = G.reshape(T, L_x * K)\n",
    "    return G\n",
    "\n",
    "def sdf_CRRA(cons_ratio, alpha, beta):\n",
    "    \"\"\"Stochastic discount factor for CRRA utility.\"\"\"\n",
    "    return beta * (cons_ratio ** alpha)\n",
    "\n",
    "def sdf_CARA(c_next, c_now, gamma, beta):\n",
    "    \"\"\"Stochastic discount factor for CARA utility.\"\"\"\n",
    "    return beta * np.exp(-gamma * (c_next - c_now))\n",
    "\n",
    "def gbar(theta, cfg, df):\n",
    "    \"\"\"Sample moment average.\"\"\"\n",
    "    G = build_moment_matrix(theta, cfg, df)\n",
    "    return G.mean(axis=0)"
   ],
   "id": "43edc7448eb5eb67",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ncbwhlhlbfh",
   "metadata": {
    "id": "cell_031"
   },
   "source": [
    "def estimate_gmm(spec: EstimationSpec, data: pd.DataFrame) -> EstimationResult:\n",
    "    \"\"\"\n",
    "    Run GMM estimation based on specification.\n",
    "    \n",
    "    Supports one-step, two-step, and iterated GMM.\n",
    "    \"\"\"\n",
    "    from scipy.stats import chi2\n",
    "    \n",
    "    # Step 1: Filter data by sample period\n",
    "    df = data.copy()\n",
    "    if spec.sample_start:\n",
    "        df = df[df['t_idx'] >= spec.sample_start]\n",
    "    if spec.sample_end:\n",
    "        df = df[df['t_idx'] <= spec.sample_end]\n",
    "    \n",
    "    # Verify all required columns exist\n",
    "    required_cols = [spec.consumption_var] + spec.returns + spec.instruments\n",
    "    missing_cols = [c for c in required_cols if c not in df.columns]\n",
    "    if missing_cols:\n",
    "        raise ValueError(f\"Missing columns in data: {missing_cols}\")\n",
    "    \n",
    "    df = df.dropna(subset=required_cols).reset_index(drop=True)\n",
    "    n_obs = len(df)\n",
    "    \n",
    "    if n_obs == 0:\n",
    "        raise ValueError(f\"No observations left after filtering for spec '{spec.name}'\")\n",
    "    \n",
    "    # Step 2: Set up parameter names and restrictions\n",
    "    if spec.utility.upper() == 'CRRA':\n",
    "        all_param_names = ['alpha', 'beta']\n",
    "    else:\n",
    "        all_param_names = ['gamma', 'beta']\n",
    "    \n",
    "    free_param_names = [p for p in all_param_names if p not in spec.restrictions]\n",
    "    n_params = len(free_param_names)\n",
    "    \n",
    "    # Step 3: Build configuration for GMM functions\n",
    "    cons_ratio_col = spec.consumption_var + '_ratio'\n",
    "    cons_f1_col = spec.consumption_var + '_f1'\n",
    "    \n",
    "    if cons_ratio_col not in df.columns:\n",
    "        if cons_f1_col not in df.columns:\n",
    "            df[cons_f1_col] = df[spec.consumption_var].shift(-1)\n",
    "        df[cons_ratio_col] = df[cons_f1_col] / df[spec.consumption_var]\n",
    "    \n",
    "    cfg = GMMConfig(\n",
    "        util=spec.utility,\n",
    "        returns_cols=spec.returns,\n",
    "        instruments=spec.instruments,\n",
    "        cons_col=spec.consumption_var,\n",
    "        cons_ratio_col=cons_ratio_col,\n",
    "        cons_f1_col=cons_f1_col,\n",
    "        hac_lags=spec.hac_lags\n",
    "    )\n",
    "    \n",
    "    # Step 4: Prepare initial values and bounds\n",
    "    theta0_dict = spec.initial_values.copy()\n",
    "    theta0_free = np.array([theta0_dict[p] for p in free_param_names])\n",
    "    bounds_free = [spec.bounds[p] for p in free_param_names]\n",
    "    \n",
    "    # Step 5: Create wrapper functions that handle restrictions\n",
    "    def expand_theta(theta_free):\n",
    "        theta_full = np.zeros(len(all_param_names))\n",
    "        free_idx = 0\n",
    "        for i, pname in enumerate(all_param_names):\n",
    "            if pname in spec.restrictions:\n",
    "                theta_full[i] = spec.restrictions[pname]\n",
    "            else:\n",
    "                theta_full[i] = theta_free[free_idx]\n",
    "                free_idx += 1\n",
    "        return theta_full\n",
    "    \n",
    "    def moment_fn_restricted(theta_free):\n",
    "        theta_full = expand_theta(theta_free)\n",
    "        return gbar(theta_full, cfg, df)\n",
    "\n",
    "    def build_G_restricted(theta_free):\n",
    "        theta_full = expand_theta(theta_free)\n",
    "        return build_moment_matrix(theta_full, cfg, df)\n",
    "    \n",
    "    # Step 6: Run GMM estimation\n",
    "    L = len(spec.instruments) * len(spec.returns)\n",
    "    \n",
    "    if spec.gmm_method == 'one-step':\n",
    "        # One-step GMM: single optimization with identity weighting\n",
    "        W = np.eye(L)\n",
    "        res = opt.minimize(\n",
    "            lambda th: gmm_criterion(th, moment_fn_restricted, W),\n",
    "            theta0_free, method='L-BFGS-B', bounds=bounds_free\n",
    "        )\n",
    "        theta_free_hat = res.x\n",
    "        converged = res.success\n",
    "        G = build_G_restricted(theta_free_hat)\n",
    "        S = hac_covariance(G, spec.hac_lags)\n",
    "        D = numerical_jacobian(moment_fn_restricted, theta_free_hat)\n",
    "        M = D.T @ W @ D\n",
    "        Minv = la.pinv(M)\n",
    "        V = Minv @ (D.T @ W @ S @ W @ D) @ Minv\n",
    "\n",
    "    elif spec.gmm_method == 'two-step':\n",
    "        # ============================================================\n",
    "        # TODO: IMPLEMENT TWO-STEP GMM\n",
    "        # ============================================================\n",
    "        # INSTRUCTIONS:\n",
    "        # 1. First step: Optimize with identity weighting matrix W0 = I\n",
    "        # 2. Compute HAC covariance S using first-step estimates\n",
    "        # 3. Compute optimal weighting W = S^(-1)\n",
    "        # 4. Second step: Re-optimize with optimal weighting W\n",
    "        # 5. Compute asymptotic variance using final estimates\n",
    "        #\n",
    "        # Hint: Follow the same structure as one-step GMM above\n",
    "        # Hint: Use res1 for first step, res2 for second step\n",
    "        assert False, \"TODO: Implement two-step GMM. Remove this assertion when implemented.\"\n",
    "\n",
    "    elif spec.gmm_method == 'iterated':\n",
    "        # ============================================================\n",
    "        # TODO: IMPLEMENT ITERATED GMM\n",
    "        # ============================================================\n",
    "        # INSTRUCTIONS:\n",
    "        # 1. Start with identity weighting matrix W = I\n",
    "        # 2. Iterate until convergence (max spec.max_iter iterations):\n",
    "        #    a. Optimize with current W\n",
    "        #    b. Compute HAC covariance S with new estimates\n",
    "        #    c. Update W = S^(-1)\n",
    "        #    d. Check convergence: ||theta_new - theta_old|| < spec.tol\n",
    "        # 3. Compute final asymptotic variance\n",
    "        #\n",
    "        # Hint: Use a for loop with early break on convergence\n",
    "        # Hint: Track theta_curr and theta_new for convergence check\n",
    "        assert False, \"TODO: Implement iterated GMM. Remove this assertion when implemented.\"\n",
    "\n",
    "        else:\n",
    "            # Max iterations reached\n",
    "            theta_free_hat = theta_curr\n",
    "            converged = False\n",
    "        \n",
    "        # Final variance\n",
    "        D = numerical_jacobian(moment_fn_restricted, theta_free_hat)\n",
    "        M = D.T @ W @ D\n",
    "        Minv = la.pinv(M)\n",
    "        V = Minv @ (D.T @ W @ S @ W @ D) @ Minv\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown GMM method: {spec.gmm_method}\")\n",
    "\n",
    "    # Step 7: Compute diagnostics\n",
    "    theta_full_hat = expand_theta(theta_free_hat)\n",
    "    g_hat = moment_fn_restricted(theta_free_hat)\n",
    "    J = n_obs * float(g_hat.T @ W @ g_hat)\n",
    "    J_dof = L - n_params\n",
    "    J_pvalue = 1 - chi2.cdf(J, J_dof) if J_dof > 0 else np.nan\n",
    "    \n",
    "    # Standard errors and t-statistics\n",
    "    se = np.sqrt(np.diag(V) / n_obs)\n",
    "    t_stats = theta_free_hat / se\n",
    "    \n",
    "    # Step 8: Package results\n",
    "    result = EstimationResult(\n",
    "        spec=spec,\n",
    "        theta=theta_full_hat,\n",
    "        theta_free=theta_free_hat,\n",
    "        se=se,\n",
    "        t_stats=t_stats,\n",
    "        param_names=all_param_names,\n",
    "        free_param_names=free_param_names,\n",
    "        V=V, S=S, W=W,\n",
    "        J_stat=J,\n",
    "        J_pvalue=J_pvalue,\n",
    "        J_dof=J_dof,\n",
    "        n_obs=n_obs,\n",
    "        n_moments=L,\n",
    "        n_params=n_params,\n",
    "        converged=converged\n",
    "    )\n",
    "    \n",
    "    return result"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "id": "cell_032"
   },
   "cell_type": "markdown",
   "source": [
    "## 4. Application Examples\n",
    "\n",
    "Now we demonstrate how to use the unified configuration system to answer the assignment questions."
   ],
   "id": "4c7978a8470ffed3"
  },
  {
   "metadata": {
    "id": "cell_033"
   },
   "cell_type": "markdown",
   "source": [
    "### 4.1 Example: Hansen-Singleton replication (Table 1)\n",
    "<img src=\"table1.png\">"
   ],
   "id": "d14332062a270f37"
  },
  {
   "metadata": {
    "id": "cell_034",
    "ExecuteTime": {
     "end_time": "2025-10-29T04:14:16.843396Z",
     "start_time": "2025-10-29T04:14:16.759440Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ============================================================================\n",
    "# PANEL A: EW + VW Returns\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"EXAMPLE: TABLE I REPLICATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Define Panel A specifications manually\n",
    "panel_specs = [\n",
    "\n",
    "    # Specification 1: NDS, NLAG=1\n",
    "    EstimationSpec(\n",
    "        name='Table1-NDS-NLAG1',\n",
    "        utility='CRRA',\n",
    "        consumption_var='cons_nds_pc',\n",
    "        returns=['ret_ew_gross'],\n",
    "        instruments=[\n",
    "            'const',\n",
    "            'cons_nds_pc_ratio_l1',   # 1 lag of consumption growth\n",
    "            'ret_ew_gross_l1',         # 1 lag of EW return\n",
    "        ],  # Total: 3 instruments Ã— 1 return = 3 moments, DOF = 3-2 = 1\n",
    "        sample_start='1959-04-01',\n",
    "        sample_end='1978-12-31'\n",
    "    ),\n",
    "\n",
    "    # Specification 2: NDS, NLAG=2\n",
    "    EstimationSpec(\n",
    "        name='Table1-NDS-NLAG2',\n",
    "        utility='CRRA',\n",
    "        consumption_var='cons_nds_pc',\n",
    "        returns=['ret_ew_gross'],\n",
    "        instruments=[\n",
    "            'const',\n",
    "            'cons_nds_pc_ratio_l1',   # 1 lag of consumption growth\n",
    "            'cons_nds_pc_ratio_l2',   # 2 lag of consumption growth\n",
    "            'ret_ew_gross_l1',         # 1 lag of EW return\n",
    "            'ret_ew_gross_l2',         # 2 lag of EW return\n",
    "        ],  # Total: 5 instruments Ã— 1 return = 5 moments, DOF = 5-2 = 3\n",
    "        sample_start='1959-04-01',\n",
    "        sample_end='1978-12-31'\n",
    "    ),\n",
    "\n",
    "    # Specification 3: NDS, NLAG=4\n",
    "    EstimationSpec(\n",
    "        name='Table1-NDS-NLAG4',\n",
    "        utility='CRRA',\n",
    "        consumption_var='cons_nds_pc',\n",
    "        returns=['ret_ew_gross'],\n",
    "        instruments=[\n",
    "            'const',\n",
    "            'cons_nds_pc_ratio_l1',   # 1 lag of consumption growth\n",
    "            'cons_nds_pc_ratio_l2',   # 2 lag of consumption growth\n",
    "            'cons_nds_pc_ratio_l3',   # 3 lag of consumption growth\n",
    "            'cons_nds_pc_ratio_l4',   # 4 lag of consumption growth\n",
    "            'ret_ew_gross_l1',         # 1 lag of EW return\n",
    "            'ret_ew_gross_l2',         # 2 lag of EW return\n",
    "            'ret_ew_gross_l3',         # 3 lag of EW return\n",
    "            'ret_ew_gross_l4',         # 4 lag of EW return\n",
    "        ],  # Total: 9 instruments Ã— 1 return = 9 moments, DOF = 9-2 = 7\n",
    "        sample_start='1959-04-01',\n",
    "        sample_end='1978-12-31'\n",
    "    ),\n",
    "        # Specification 3: NDS, NLAG=6\n",
    "    EstimationSpec(\n",
    "        name='Table1-NDS-NLAG6',\n",
    "        utility='CRRA',\n",
    "        consumption_var='cons_nds_pc',\n",
    "        returns=['ret_ew_gross'],\n",
    "        instruments=[\n",
    "            'const',\n",
    "            'cons_nds_pc_ratio_l1',   # 1 lag of consumption growth\n",
    "            'cons_nds_pc_ratio_l2',   # 2 lag of consumption growth\n",
    "            'cons_nds_pc_ratio_l3',   # 3 lag of consumption growth\n",
    "            'cons_nds_pc_ratio_l4',   # 4 lag of consumption growth\n",
    "            'cons_nds_pc_ratio_l5',   # 5 lag of consumption growth\n",
    "            'cons_nds_pc_ratio_l6',   # 6 lag of consumption growth\n",
    "            'ret_ew_gross_l1',         # 1 lag of EW return\n",
    "            'ret_ew_gross_l2',         # 2 lag of EW return\n",
    "            'ret_ew_gross_l3',         # 3 lag of EW return\n",
    "            'ret_ew_gross_l4',         # 4 lag of EW return\n",
    "            'ret_ew_gross_l5',         # 5 lag of EW return\n",
    "            'ret_ew_gross_l6',         # 6 lag of EW return\n",
    "        ],  # Total: 13 instruments Ã— 1 return =  13moments, DOF = 13-2 = 11\n",
    "        sample_start='1959-04-01',\n",
    "        sample_end='1978-12-31'\n",
    "    ),\n",
    "]\n",
    "\n",
    "print(f\"Defined {len(panel_specs)} specifications\")\n",
    "\n",
    "# Run all Panel specifications with all GMM methods\n",
    "runner_panel = SpecificationRunner()\n",
    "\n",
    "# Set verbose = True for detailed information\n",
    "runner_panel.run_specs(panel_specs, data, verbose=False, methods=['one-step', 'two-step', 'iterated'])\n",
    "\n",
    "# Display results organized by GMM method (Optional: May choose additional diagnostics)\n",
    "df = runner_panel.to_dataframe(\n",
    "    by_method=False,\n",
    "    decimals=4,\n",
    "    diagnostics=['N', 'Moments', 'J_stat', 'J_pval', 'DOF', 'Converged']\n",
    ")\n",
    "print(df)\n",
    "# df.to_excel('example_results.xlsx', index=False)\n",
    "\n",
    "# Optional: Export table format to Excel\n",
    "# runner_panel.to_excel('example_table_1.xlsx', decimals=4)"
   ],
   "id": "c6e57963ab0e69d5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "EXAMPLE: TABLE I REPLICATION\n",
      "================================================================================\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'EstimationSpec' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 13\u001B[39m\n\u001B[32m      7\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33m=\u001B[39m\u001B[33m\"\u001B[39m*\u001B[32m80\u001B[39m)\n\u001B[32m      9\u001B[39m \u001B[38;5;66;03m# Define Panel A specifications manually\u001B[39;00m\n\u001B[32m     10\u001B[39m panel_specs = [\n\u001B[32m     11\u001B[39m \n\u001B[32m     12\u001B[39m     \u001B[38;5;66;03m# Specification 1: NDS, NLAG=1\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m13\u001B[39m     \u001B[43mEstimationSpec\u001B[49m(\n\u001B[32m     14\u001B[39m         name=\u001B[33m'\u001B[39m\u001B[33mTable1-NDS-NLAG1\u001B[39m\u001B[33m'\u001B[39m,\n\u001B[32m     15\u001B[39m         utility=\u001B[33m'\u001B[39m\u001B[33mCRRA\u001B[39m\u001B[33m'\u001B[39m,\n\u001B[32m     16\u001B[39m         consumption_var=\u001B[33m'\u001B[39m\u001B[33mcons_nds_pc\u001B[39m\u001B[33m'\u001B[39m,\n\u001B[32m     17\u001B[39m         returns=[\u001B[33m'\u001B[39m\u001B[33mret_ew_gross\u001B[39m\u001B[33m'\u001B[39m],\n\u001B[32m     18\u001B[39m         instruments=[\n\u001B[32m     19\u001B[39m             \u001B[33m'\u001B[39m\u001B[33mconst\u001B[39m\u001B[33m'\u001B[39m,\n\u001B[32m     20\u001B[39m             \u001B[33m'\u001B[39m\u001B[33mcons_nds_pc_ratio_l1\u001B[39m\u001B[33m'\u001B[39m,   \u001B[38;5;66;03m# 1 lag of consumption growth\u001B[39;00m\n\u001B[32m     21\u001B[39m             \u001B[33m'\u001B[39m\u001B[33mret_ew_gross_l1\u001B[39m\u001B[33m'\u001B[39m,         \u001B[38;5;66;03m# 1 lag of EW return\u001B[39;00m\n\u001B[32m     22\u001B[39m         ],  \u001B[38;5;66;03m# Total: 3 instruments Ã— 1 return = 3 moments, DOF = 3-2 = 1\u001B[39;00m\n\u001B[32m     23\u001B[39m         sample_start=\u001B[33m'\u001B[39m\u001B[33m1959-04-01\u001B[39m\u001B[33m'\u001B[39m,\n\u001B[32m     24\u001B[39m         sample_end=\u001B[33m'\u001B[39m\u001B[33m1978-12-31\u001B[39m\u001B[33m'\u001B[39m\n\u001B[32m     25\u001B[39m     ),\n\u001B[32m     26\u001B[39m \n\u001B[32m     27\u001B[39m     \u001B[38;5;66;03m# Specification 2: NDS, NLAG=2\u001B[39;00m\n\u001B[32m     28\u001B[39m     EstimationSpec(\n\u001B[32m     29\u001B[39m         name=\u001B[33m'\u001B[39m\u001B[33mTable1-NDS-NLAG2\u001B[39m\u001B[33m'\u001B[39m,\n\u001B[32m     30\u001B[39m         utility=\u001B[33m'\u001B[39m\u001B[33mCRRA\u001B[39m\u001B[33m'\u001B[39m,\n\u001B[32m     31\u001B[39m         consumption_var=\u001B[33m'\u001B[39m\u001B[33mcons_nds_pc\u001B[39m\u001B[33m'\u001B[39m,\n\u001B[32m     32\u001B[39m         returns=[\u001B[33m'\u001B[39m\u001B[33mret_ew_gross\u001B[39m\u001B[33m'\u001B[39m],\n\u001B[32m     33\u001B[39m         instruments=[\n\u001B[32m     34\u001B[39m             \u001B[33m'\u001B[39m\u001B[33mconst\u001B[39m\u001B[33m'\u001B[39m,\n\u001B[32m     35\u001B[39m             \u001B[33m'\u001B[39m\u001B[33mcons_nds_pc_ratio_l1\u001B[39m\u001B[33m'\u001B[39m,   \u001B[38;5;66;03m# 1 lag of consumption growth\u001B[39;00m\n\u001B[32m     36\u001B[39m             \u001B[33m'\u001B[39m\u001B[33mcons_nds_pc_ratio_l2\u001B[39m\u001B[33m'\u001B[39m,   \u001B[38;5;66;03m# 2 lag of consumption growth\u001B[39;00m\n\u001B[32m     37\u001B[39m             \u001B[33m'\u001B[39m\u001B[33mret_ew_gross_l1\u001B[39m\u001B[33m'\u001B[39m,         \u001B[38;5;66;03m# 1 lag of EW return\u001B[39;00m\n\u001B[32m     38\u001B[39m             \u001B[33m'\u001B[39m\u001B[33mret_ew_gross_l2\u001B[39m\u001B[33m'\u001B[39m,         \u001B[38;5;66;03m# 2 lag of EW return\u001B[39;00m\n\u001B[32m     39\u001B[39m         ],  \u001B[38;5;66;03m# Total: 5 instruments Ã— 1 return = 5 moments, DOF = 5-2 = 3\u001B[39;00m\n\u001B[32m     40\u001B[39m         sample_start=\u001B[33m'\u001B[39m\u001B[33m1959-04-01\u001B[39m\u001B[33m'\u001B[39m,\n\u001B[32m     41\u001B[39m         sample_end=\u001B[33m'\u001B[39m\u001B[33m1978-12-31\u001B[39m\u001B[33m'\u001B[39m\n\u001B[32m     42\u001B[39m     ),\n\u001B[32m     43\u001B[39m \n\u001B[32m     44\u001B[39m     \u001B[38;5;66;03m# Specification 3: NDS, NLAG=4\u001B[39;00m\n\u001B[32m     45\u001B[39m     EstimationSpec(\n\u001B[32m     46\u001B[39m         name=\u001B[33m'\u001B[39m\u001B[33mTable1-NDS-NLAG4\u001B[39m\u001B[33m'\u001B[39m,\n\u001B[32m     47\u001B[39m         utility=\u001B[33m'\u001B[39m\u001B[33mCRRA\u001B[39m\u001B[33m'\u001B[39m,\n\u001B[32m     48\u001B[39m         consumption_var=\u001B[33m'\u001B[39m\u001B[33mcons_nds_pc\u001B[39m\u001B[33m'\u001B[39m,\n\u001B[32m     49\u001B[39m         returns=[\u001B[33m'\u001B[39m\u001B[33mret_ew_gross\u001B[39m\u001B[33m'\u001B[39m],\n\u001B[32m     50\u001B[39m         instruments=[\n\u001B[32m     51\u001B[39m             \u001B[33m'\u001B[39m\u001B[33mconst\u001B[39m\u001B[33m'\u001B[39m,\n\u001B[32m     52\u001B[39m             \u001B[33m'\u001B[39m\u001B[33mcons_nds_pc_ratio_l1\u001B[39m\u001B[33m'\u001B[39m,   \u001B[38;5;66;03m# 1 lag of consumption growth\u001B[39;00m\n\u001B[32m     53\u001B[39m             \u001B[33m'\u001B[39m\u001B[33mcons_nds_pc_ratio_l2\u001B[39m\u001B[33m'\u001B[39m,   \u001B[38;5;66;03m# 2 lag of consumption growth\u001B[39;00m\n\u001B[32m     54\u001B[39m             \u001B[33m'\u001B[39m\u001B[33mcons_nds_pc_ratio_l3\u001B[39m\u001B[33m'\u001B[39m,   \u001B[38;5;66;03m# 3 lag of consumption growth\u001B[39;00m\n\u001B[32m     55\u001B[39m             \u001B[33m'\u001B[39m\u001B[33mcons_nds_pc_ratio_l4\u001B[39m\u001B[33m'\u001B[39m,   \u001B[38;5;66;03m# 4 lag of consumption growth\u001B[39;00m\n\u001B[32m     56\u001B[39m             \u001B[33m'\u001B[39m\u001B[33mret_ew_gross_l1\u001B[39m\u001B[33m'\u001B[39m,         \u001B[38;5;66;03m# 1 lag of EW return\u001B[39;00m\n\u001B[32m     57\u001B[39m             \u001B[33m'\u001B[39m\u001B[33mret_ew_gross_l2\u001B[39m\u001B[33m'\u001B[39m,         \u001B[38;5;66;03m# 2 lag of EW return\u001B[39;00m\n\u001B[32m     58\u001B[39m             \u001B[33m'\u001B[39m\u001B[33mret_ew_gross_l3\u001B[39m\u001B[33m'\u001B[39m,         \u001B[38;5;66;03m# 3 lag of EW return\u001B[39;00m\n\u001B[32m     59\u001B[39m             \u001B[33m'\u001B[39m\u001B[33mret_ew_gross_l4\u001B[39m\u001B[33m'\u001B[39m,         \u001B[38;5;66;03m# 4 lag of EW return\u001B[39;00m\n\u001B[32m     60\u001B[39m         ],  \u001B[38;5;66;03m# Total: 9 instruments Ã— 1 return = 9 moments, DOF = 9-2 = 7\u001B[39;00m\n\u001B[32m     61\u001B[39m         sample_start=\u001B[33m'\u001B[39m\u001B[33m1959-04-01\u001B[39m\u001B[33m'\u001B[39m,\n\u001B[32m     62\u001B[39m         sample_end=\u001B[33m'\u001B[39m\u001B[33m1978-12-31\u001B[39m\u001B[33m'\u001B[39m\n\u001B[32m     63\u001B[39m     ),\n\u001B[32m     64\u001B[39m         \u001B[38;5;66;03m# Specification 3: NDS, NLAG=6\u001B[39;00m\n\u001B[32m     65\u001B[39m     EstimationSpec(\n\u001B[32m     66\u001B[39m         name=\u001B[33m'\u001B[39m\u001B[33mTable1-NDS-NLAG6\u001B[39m\u001B[33m'\u001B[39m,\n\u001B[32m     67\u001B[39m         utility=\u001B[33m'\u001B[39m\u001B[33mCRRA\u001B[39m\u001B[33m'\u001B[39m,\n\u001B[32m     68\u001B[39m         consumption_var=\u001B[33m'\u001B[39m\u001B[33mcons_nds_pc\u001B[39m\u001B[33m'\u001B[39m,\n\u001B[32m     69\u001B[39m         returns=[\u001B[33m'\u001B[39m\u001B[33mret_ew_gross\u001B[39m\u001B[33m'\u001B[39m],\n\u001B[32m     70\u001B[39m         instruments=[\n\u001B[32m     71\u001B[39m             \u001B[33m'\u001B[39m\u001B[33mconst\u001B[39m\u001B[33m'\u001B[39m,\n\u001B[32m     72\u001B[39m             \u001B[33m'\u001B[39m\u001B[33mcons_nds_pc_ratio_l1\u001B[39m\u001B[33m'\u001B[39m,   \u001B[38;5;66;03m# 1 lag of consumption growth\u001B[39;00m\n\u001B[32m     73\u001B[39m             \u001B[33m'\u001B[39m\u001B[33mcons_nds_pc_ratio_l2\u001B[39m\u001B[33m'\u001B[39m,   \u001B[38;5;66;03m# 2 lag of consumption growth\u001B[39;00m\n\u001B[32m     74\u001B[39m             \u001B[33m'\u001B[39m\u001B[33mcons_nds_pc_ratio_l3\u001B[39m\u001B[33m'\u001B[39m,   \u001B[38;5;66;03m# 3 lag of consumption growth\u001B[39;00m\n\u001B[32m     75\u001B[39m             \u001B[33m'\u001B[39m\u001B[33mcons_nds_pc_ratio_l4\u001B[39m\u001B[33m'\u001B[39m,   \u001B[38;5;66;03m# 4 lag of consumption growth\u001B[39;00m\n\u001B[32m     76\u001B[39m             \u001B[33m'\u001B[39m\u001B[33mcons_nds_pc_ratio_l5\u001B[39m\u001B[33m'\u001B[39m,   \u001B[38;5;66;03m# 5 lag of consumption growth\u001B[39;00m\n\u001B[32m     77\u001B[39m             \u001B[33m'\u001B[39m\u001B[33mcons_nds_pc_ratio_l6\u001B[39m\u001B[33m'\u001B[39m,   \u001B[38;5;66;03m# 6 lag of consumption growth\u001B[39;00m\n\u001B[32m     78\u001B[39m             \u001B[33m'\u001B[39m\u001B[33mret_ew_gross_l1\u001B[39m\u001B[33m'\u001B[39m,         \u001B[38;5;66;03m# 1 lag of EW return\u001B[39;00m\n\u001B[32m     79\u001B[39m             \u001B[33m'\u001B[39m\u001B[33mret_ew_gross_l2\u001B[39m\u001B[33m'\u001B[39m,         \u001B[38;5;66;03m# 2 lag of EW return\u001B[39;00m\n\u001B[32m     80\u001B[39m             \u001B[33m'\u001B[39m\u001B[33mret_ew_gross_l3\u001B[39m\u001B[33m'\u001B[39m,         \u001B[38;5;66;03m# 3 lag of EW return\u001B[39;00m\n\u001B[32m     81\u001B[39m             \u001B[33m'\u001B[39m\u001B[33mret_ew_gross_l4\u001B[39m\u001B[33m'\u001B[39m,         \u001B[38;5;66;03m# 4 lag of EW return\u001B[39;00m\n\u001B[32m     82\u001B[39m             \u001B[33m'\u001B[39m\u001B[33mret_ew_gross_l5\u001B[39m\u001B[33m'\u001B[39m,         \u001B[38;5;66;03m# 5 lag of EW return\u001B[39;00m\n\u001B[32m     83\u001B[39m             \u001B[33m'\u001B[39m\u001B[33mret_ew_gross_l6\u001B[39m\u001B[33m'\u001B[39m,         \u001B[38;5;66;03m# 6 lag of EW return\u001B[39;00m\n\u001B[32m     84\u001B[39m         ],  \u001B[38;5;66;03m# Total: 13 instruments Ã— 1 return =  13moments, DOF = 13-2 = 11\u001B[39;00m\n\u001B[32m     85\u001B[39m         sample_start=\u001B[33m'\u001B[39m\u001B[33m1959-04-01\u001B[39m\u001B[33m'\u001B[39m,\n\u001B[32m     86\u001B[39m         sample_end=\u001B[33m'\u001B[39m\u001B[33m1978-12-31\u001B[39m\u001B[33m'\u001B[39m\n\u001B[32m     87\u001B[39m     ),\n\u001B[32m     88\u001B[39m ]\n\u001B[32m     90\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mDefined \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(panel_specs)\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m specifications\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m     92\u001B[39m \u001B[38;5;66;03m# Run all Panel specifications with all GMM methods\u001B[39;00m\n",
      "\u001B[31mNameError\u001B[39m: name 'EstimationSpec' is not defined"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "id": "cell_035"
   },
   "cell_type": "markdown",
   "source": [
    "### 4.2 Question 2: Hansen-Singleton replication (Table 3)\n",
    "\n",
    "#### Panel A\n",
    "<img src=\"table3A.png\">\n",
    "\n",
    "There is one more complication here: we now have two sets of orthogonality conditions. The first line estimates of Table III uses equally- and value-weighted returns, with one lag for each of the consumption ration and equally- and value-weighted returns. This is a set of 8 population moment conditions in 2 parameters ($\\alpha,\\beta$).\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\mathbb{E}\\left[\\begin{pmatrix}\n",
    "1\\\\\n",
    "\\frac{c_t}{c_{t-1}}\\\\\n",
    "r_{t}^*\\\\\n",
    "r_{t}\n",
    "\\end{pmatrix} \\cdot \\left(r_{t+1}^*\\beta\\left(\\frac{c_{t+1}^*}{c_t^*}\\right)^{\\alpha}-1\\right)\\right] &= 0 \\\\\n",
    "\\mathbb{E}\\left[\\begin{pmatrix}\n",
    "1\\\\\n",
    "\\frac{c_t}{c_{t-1}}\\\\\n",
    "r_{t}^*\\\\\n",
    "r_{t}\n",
    "\\end{pmatrix} \\cdot \\left(r_{t+1}\\beta\\left(\\frac{c_{t+1}^*}{c_t^*}\\right)^{\\alpha}-1\\right)\\right] &= 0\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "The degree of freedom (DF) is 2*(1+(NLAG of consumption ratio)+(NLAG of EWR)+(NLAG of VWR))-2\n",
    "- NLAG=1: $2\\times(1+1+1+1)-2=6$\n",
    "- NLAG=2: $2\\times(1+2+2+2)-2=12$\n",
    "- NLAG=4: $2\\times(1+4+4+4)-2=24$"
   ],
   "id": "c49bb8d5c1830ed7"
  },
  {
   "metadata": {
    "id": "cell_036"
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\"\"\"\n",
    "Question 2: Table III Panel A Replication\n",
    "\"\"\"\n",
    "\n",
    "# ============================================================================\n",
    "# TODO: DEFINE PANEL A SPECIFICATIONS\n",
    "# ============================================================================\n",
    "# INSTRUCTIONS:\n",
    "# Replicate Table 3 Panel A from Hansen-Singleton (1982).\n",
    "#\n",
    "# Panel A uses:\n",
    "# - Consumption: cons_nds_pc (Nondurables)\n",
    "# - Returns: ret_ew_gross AND ret_vw_gross (both EW and VW)\n",
    "# - Utility: CRRA\n",
    "# - Sample period: '1959-04-01' to '1978-12-31'\n",
    "# - NLAG values: 1, 2, 4\n",
    "#\n",
    "# For each NLAG, you need to define:\n",
    "# 1. instruments = ['const', consumption lags, return lags]\n",
    "#    - Consumption lags: cons_nds_pc_ratio_l1, cons_nds_pc_ratio_l2, ..., cons_nds_pc_ratio_lN\n",
    "#    - Return lags: ret_ew_gross_l1, ret_vw_gross_l1, ret_ew_gross_l2, ret_vw_gross_l2, ..., ret_*_lN\n",
    "# 2. Create EstimationSpec with these parameters\n",
    "#\n",
    "# Example structure for NLAG=1:\n",
    "# panel_a_specs = [\n",
    "#     EstimationSpec(\n",
    "#         name='Table3A-NDS-NLAG1',\n",
    "#         utility='CRRA',\n",
    "#         consumption_var='cons_nds_pc',\n",
    "#         returns=['ret_ew_gross', 'ret_vw_gross'],\n",
    "#         instruments=['const', 'cons_nds_pc_ratio_l1', 'ret_ew_gross_l1', 'ret_vw_gross_l1'],\n",
    "#         sample_start='1959-04-01',\n",
    "#         sample_end='1978-12-31'\n",
    "#     ),\n",
    "#     # TODO: Add NLAG=2 specification\n",
    "#     # TODO: Add NLAG=4 specification\n",
    "# ]\n",
    "\n",
    "# TODO: Define panel_a_specs list here\n",
    "assert False, \"TODO: Define panel_a_specs for Question 2 Panel A. Remove this assertion when implemented.\"\n",
    "\n",
    "# ============================================================================\n",
    "# PANEL A: EW + VW Returns\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"Question 2: Panel A (Nondurables, EW+VW)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Run estimations\n",
    "runner_panel_a = SpecificationRunner()\n",
    "runner_panel_a.run_specs(panel_a_specs, data_quarterly)\n",
    "\n",
    "# Display results\n",
    "df = runner_panel_a.to_dataframe(\n",
    "    by_method=False,\n",
    "    decimals=4,\n",
    "    diagnostics=['N', 'Moments', 'J_stat', 'J_pval', 'DOF', 'Converged']\n",
    ")\n",
    "print(df)\n",
    "# df.to_excel('question2_panel_a.xlsx', index=False)\n",
    "\n",
    "# Summary statistics\n",
    "runner_panel_a.summary_stats()\n"
   ],
   "id": "question2_template"
  },
  {
   "metadata": {
    "id": "cell_037"
   },
   "cell_type": "markdown",
   "source": [
    "#### Panel B\n",
    "\n",
    "<img src=\"table3B.png\">\n",
    "\n",
    "In Hansen and Singleton (1984), they describe how they used the nominal risk-free returns:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\mathbb{E}\\left[\\begin{pmatrix}\n",
    "1\\\\\n",
    "\\frac{c_t}{c_{t-1}}\\\\\n",
    "r_{t}\\\\\n",
    "\\frac{R_{t+1}^f}{R_{t}^f}\\\\\n",
    "\\frac{R_{t}^f}{R_{t-1}^f}\n",
    "\\end{pmatrix} \\cdot \\left(r_{t+1}\\beta\\left(\\frac{c_{t+1}^*}{c_t^*}\\right)^{\\alpha}-1\\right)\\right] &= 0 \\\\\n",
    "\\mathbb{E}\\left[\\begin{pmatrix}\n",
    "1\\\\\n",
    "\\frac{c_t}{c_{t-1}}\\\\\n",
    "r_t \\\\\n",
    "\\frac{R_{t+1}^f}{R_{t}^f}\\\\\n",
    "\\frac{R_{t}^f}{R_{t-1}^f}\n",
    "\\end{pmatrix} \\cdot \\left(R_{t+1}^f \\beta\\left(\\frac{c_{t+1}}{c_t}\\right)^{\\alpha}-1\\right)\\right] &= 0\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Their claim is that the degree of freedom is 2* [constant + (risk-free ratio + NLAG for risk-free ratio) + (NLAG for consumption ratio) + (NLAG for VWR)]-2\n",
    "- NLAG=1: $2\\times(1+(1+1)+1+1)-2=8$\n",
    "- NLAG=2: $2\\times(1+(1+2)+2+2)-2=14$\n",
    "- NLAG=4: $2\\times(1+(1+4)+4+4)-2=26$\n",
    "\n",
    "(Credit to Christine Dabbs) However, it seems like Hansen and Singleton double-counted the number of risk-free ratios. They have df = 8, 16, 32. These numbers are replicable if we counted degree of freedoms as:\n",
    "\n",
    "2* [constant + 2*(NLAG for risk-free ratio) + (NLAG for consumption ratio) + (NLAG for VWR)]-2\n",
    "- NLAG=1: $2\\times(1+2*1+1+1)-2=8$\n",
    "- NLAG=2: $2\\times(1+2*2+2+2)-2=16$\n",
    "- NLAG=4: $2\\times(1+2*4+4+4)-2=32$\n"
   ],
   "id": "d63f5d4c93e215d8"
  },
  {
   "metadata": {
    "id": "cell_038"
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ============================================================================\n",
    "# TODO: DEFINE PANEL B SPECIFICATIONS\n",
    "# ============================================================================\n",
    "# INSTRUCTIONS:\n",
    "# Replicate Table 3 Panel B from Hansen-Singleton (1982).\n",
    "#\n",
    "# Panel B uses:\n",
    "# - Consumption: cons_nds_pc (Nondurables)\n",
    "# - Returns: ret_vw_gross AND rf_gross (VW and Risk-free)\n",
    "# - Utility: CRRA\n",
    "# - Sample period: '1959-04-01' to '1978-12-31'\n",
    "# - NLAG values: 1, 2, 4\n",
    "#\n",
    "# Follow the same pattern as Panel A, but change:\n",
    "# - returns to ['ret_vw_gross', 'rf_gross']\n",
    "# - return lags: ret_vw_gross_l*, rf_gross_l*\n",
    "#\n",
    "# TODO: Define panel_b_specs list here\n",
    "assert False, \"TODO: Define panel_b_specs for Question 2 Panel B. Remove this assertion when implemented.\"\n",
    "\n",
    "# ============================================================================\n",
    "# PANEL B: VW + RF Returns\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"Question 2: Panel B (Nondurables, VW+RF)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Run estimations\n",
    "runner_panel_b = SpecificationRunner()\n",
    "runner_panel_b.run_specs(panel_b_specs, data_quarterly)\n",
    "\n",
    "# Display results\n",
    "df = runner_panel_b.to_dataframe(\n",
    "    by_method=False,\n",
    "    decimals=4,\n",
    "    diagnostics=['N', 'Moments', 'J_stat', 'J_pval', 'DOF', 'Converged']\n",
    ")\n",
    "print(df)\n",
    "# df.to_excel('question2_panel_b.xlsx', index=False)\n",
    "\n",
    "# Summary statistics\n",
    "runner_panel_b.summary_stats()\n"
   ],
   "id": "217c5fd24d8cac9b"
  },
  {
   "metadata": {
    "id": "cell_039"
   },
   "cell_type": "markdown",
   "source": [
    "### 4.3 Question 3: Testing the over-identifying restrictions\n",
    "\n",
    "Here, you are now estimating 4 parameters, $(\\alpha_1,\\beta_1,\\alpha_2,\\beta_2)$. You may want to find $(\\alpha_1,\\beta_1)$ only with data from 1960.1 to 1978.12 and $(\\alpha_2,\\beta_2)$ with data from 1979.1 and onward. You can change `f_HS_TABLE3_EXAMPLE` to do this exercise. You can only use data from 1960.1 to 1978.12 for `m1` and use data from 1979.1 to 2020.12 for `m2`. You may also want to use $4\\times1$ vector $\\vec{\\gamma}$. This is your 'unconstrained' GMM.\n",
    "\n",
    "Now, you are asked to test $(\\alpha_1,\\beta_1)=(\\alpha_2,\\beta_2)$. The following theorem will be helpful:\n",
    "\n",
    "#### Theorem ([Professor Miller's Lecture Notes, slide 17](https://comlabgames.com/structuraleconometrics/3%20Asymptotic%20Theory%20for%20Nonlinear%20Models/13%20Testing%20Parametric%20Models/13%20Testing%20Parametric%20Models.pdf))\n",
    "Let $J_{un}$ be the unconstrained GMM criterion function with $l_1$ orthogonality conditions and $k_1$ parameters. Let $J_{con}$ be the constrained GMM criterion function with $l_2$ orthogonality conditions and $k_2$ parameters. Then,\n",
    "$$\n",
    "J_{con} - J_{un} \\overset{d}{\\longrightarrow} \\chi^2_{(l_2-k_2)-(l_1-k_1)}.\n",
    "$$\n",
    "\n",
    "Additionally, you might be able to test models with more parameters in more time frames, say, before/after the financial crisis in 2008 and before/after COVID-19. To do so, you may need more instruments using more lagged variables."
   ],
   "id": "360b23221cb9980"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\"\"\"\n",
    "Question 3: Parameter Stability Test Across Time Periods\n",
    "\"\"\"\n",
    "\n",
    "# ============================================================================\n",
    "# TODO: IMPLEMENT PARAMETER STABILITY TEST\n",
    "# ============================================================================\n",
    "# OBJECTIVE:\n",
    "# Test if parameters are stable across time by comparing:\n",
    "# - CONSTRAINED model: One (Î±, Î²) for all data â†’ 2 parameters\n",
    "# - UNCONSTRAINED model: Different (Î±â‚, Î²â‚), (Î±â‚‚, Î²â‚‚) per period â†’ 4 parameters\n",
    "#\n",
    "# If unconstrained fits significantly better â†’ parameters NOT stable\n",
    "# If constrained fits just as well â†’ parameters stable\n",
    "#\n",
    "# ============================================================================\n",
    "# PSEUDOCODE STRUCTURE:\n",
    "# ============================================================================\n",
    "#\n",
    "# PART A: CONSTRAINED MODEL (2 parameters)\n",
    "# ============================================================================\n",
    "# Estimate ONE set of parameters (Î±, Î²) using ALL data from both periods\n",
    "#\n",
    "# STEP A1: Create specification for full sample\n",
    "# --------------------------------\n",
    "# constrained_spec = EstimationSpec(\n",
    "#     name='Constrained_FullSample',\n",
    "#     utility='CRRA',\n",
    "#     consumption_var='cons_nds_pc',\n",
    "#     returns=['ret_ew_gross', 'ret_vw_gross'],\n",
    "#     instruments=[...],  # NLAG=1 instruments\n",
    "#     gmm_method='two-step',\n",
    "#     sample_start='1960-01-01',  # Start of Period 1\n",
    "#     sample_end='2020-12-31'      # End of Period 2\n",
    "# )\n",
    "#\n",
    "# STEP A2: Run constrained estimation\n",
    "# --------------------------------\n",
    "# runner_constrained = SpecificationRunner()\n",
    "# runner_constrained.run_specs([constrained_spec], data_quarterly)\n",
    "# result_constrained = runner_constrained.results[0]\n",
    "#\n",
    "# # Extract constrained estimates\n",
    "# theta_constrained = result_constrained.theta  # [Î±, Î²] - same for both periods\n",
    "# J_constrained = result_constrained.J_stat     # GMM objective value\n",
    "# n_constrained = result_constrained.n_obs      # Total sample size\n",
    "#\n",
    "# print(\"CONSTRAINED MODEL (2 parameters):\")\n",
    "# print(f\"Î± = {theta_constrained[0]:.4f}\")\n",
    "# print(f\"Î² = {theta_constrained[1]:.4f}\")\n",
    "# print(f\"J-statistic = {J_constrained:.4f}\")\n",
    "# print(f\"N = {n_constrained}\")\n",
    "#\n",
    "#\n",
    "# PART B: UNCONSTRAINED MODEL (4 parameters)\n",
    "# ============================================================================\n",
    "# Estimate SEPARATE parameters (Î±â‚, Î²â‚) and (Î±â‚‚, Î²â‚‚) for each period\n",
    "#\n",
    "# STEP B1: Estimate for Period 1\n",
    "# --------------------------------\n",
    "# import copy\n",
    "#\n",
    "# spec_period1 = copy.deepcopy(constrained_spec)\n",
    "# spec_period1.name = 'Unconstrained_Period1'\n",
    "# spec_period1.sample_start = '1960-01-01'\n",
    "# spec_period1.sample_end = '1978-12-31'\n",
    "#\n",
    "# runner_period1 = SpecificationRunner()\n",
    "# runner_period1.run_specs([spec_period1], data_quarterly)\n",
    "# result_period1 = runner_period1.results[0]\n",
    "#\n",
    "# theta1 = result_period1.theta  # [Î±â‚, Î²â‚]\n",
    "# V1 = result_period1.V          # Covariance matrix\n",
    "# n1 = result_period1.n_obs\n",
    "#\n",
    "# STEP B2: Estimate for Period 2\n",
    "# --------------------------------\n",
    "# spec_period2 = copy.deepcopy(constrained_spec)\n",
    "# spec_period2.name = 'Unconstrained_Period2'\n",
    "# spec_period2.sample_start = '1979-01-01'\n",
    "# spec_period2.sample_end = '2020-12-31'\n",
    "#\n",
    "# runner_period2 = SpecificationRunner()\n",
    "# runner_period2.run_specs([spec_period2], data_quarterly)\n",
    "# result_period2 = runner_period2.results[0]\n",
    "#\n",
    "# theta2 = result_period2.theta  # [Î±â‚‚, Î²â‚‚]\n",
    "# V2 = result_period2.V\n",
    "# n2 = result_period2.n_obs\n",
    "#\n",
    "# print(\"\\nUNCONSTRAINED MODEL (4 parameters):\")\n",
    "# print(f\"Period 1 (1960-1978): Î±â‚ = {theta1[0]:.4f}, Î²â‚ = {theta1[1]:.4f}, N = {n1}\")\n",
    "# print(f\"Period 2 (1979-2020): Î±â‚‚ = {theta2[0]:.4f}, Î²â‚‚ = {theta2[1]:.4f}, N = {n2}\")\n",
    "#\n",
    "#\n",
    "# PART C: WALD TEST\n",
    "# ============================================================================\n",
    "# Test H0: (Î±â‚, Î²â‚) = (Î±â‚‚, Î²â‚‚)\n",
    "# Equivalently: Is unconstrained model significantly better than constrained?\n",
    "#\n",
    "# STEP C1: Method 1 - Test parameter differences\n",
    "# --------------------------------\n",
    "# # Test if Î¸â‚ = Î¸â‚‚\n",
    "# # W = (Î¸â‚ - Î¸â‚‚)' Ã— Var(Î¸â‚ - Î¸â‚‚)^(-1) Ã— (Î¸â‚ - Î¸â‚‚)\n",
    "# # where Var(Î¸â‚ - Î¸â‚‚) = Vâ‚/nâ‚ + Vâ‚‚/nâ‚‚\n",
    "#\n",
    "# import numpy as np\n",
    "# from scipy.stats import chi2\n",
    "# import numpy.linalg as la\n",
    "#\n",
    "# theta_diff = theta1 - theta2\n",
    "# V_diff = V1/n1 + V2/n2\n",
    "#\n",
    "# try:\n",
    "#     V_diff_inv = la.inv(V_diff)\n",
    "# except:\n",
    "#     V_diff_inv = la.pinv(V_diff)\n",
    "#\n",
    "# wald_stat = theta_diff @ V_diff_inv @ theta_diff\n",
    "# dof = 2  # Testing 2 restrictions: Î±â‚=Î±â‚‚ and Î²â‚=Î²â‚‚\n",
    "#\n",
    "# # Alternative: Method 2 - Using J-statistics (if available)\n",
    "# # W = n_constrained * J_constrained - (n1 * J1 + n2 * J2)\n",
    "# # This works if you have the GMM objective values from each estimation\n",
    "#\n",
    "# STEP C2: Compute p-value\n",
    "# --------------------------------\n",
    "# pvalue = 1 - chi2.cdf(wald_stat, dof)\n",
    "#\n",
    "# STEP C3: Display results\n",
    "# --------------------------------\n",
    "# print(\"\\n\" + \"=\"*80)\n",
    "# print(\"WALD TEST: CONSTRAINED vs UNCONSTRAINED\")\n",
    "# print(\"=\"*80)\n",
    "# print(f\"H0: Parameters are STABLE â†’ (Î±â‚, Î²â‚) = (Î±â‚‚, Î²â‚‚)\")\n",
    "# print(f\"Ha: Parameters are NOT STABLE â†’ (Î±â‚, Î²â‚) â‰  (Î±â‚‚, Î²â‚‚)\")\n",
    "# print()\n",
    "# print(f\"Constrained model:   Î± = {theta_constrained[0]:.4f}, Î² = {theta_constrained[1]:.4f}\")\n",
    "# print(f\"Period 1:           Î±â‚ = {theta1[0]:.4f}, Î²â‚ = {theta1[1]:.4f}\")\n",
    "# print(f\"Period 2:           Î±â‚‚ = {theta2[0]:.4f}, Î²â‚‚ = {theta2[1]:.4f}\")\n",
    "# print()\n",
    "# print(f\"Wald statistic: {wald_stat:.4f}\")\n",
    "# print(f\"Degrees of freedom: {dof}\")\n",
    "# print(f\"P-value: {pvalue:.4f}\")\n",
    "# print()\n",
    "# if pvalue < 0.05:\n",
    "#     print(\"âœ“ REJECT H0 at 5% level\")\n",
    "#     print(\"  â†’ Unconstrained model fits significantly better\")\n",
    "#     print(\"  â†’ Parameters are NOT stable across time\")\n",
    "#     print(\"  â†’ The consumption-returns relationship has changed\")\n",
    "# else:\n",
    "#     print(\"âœ— FAIL TO REJECT H0 at 5% level\")\n",
    "#     print(\"  â†’ Constrained model fits just as well\")\n",
    "#     print(\"  â†’ Parameters appear stable across time\")\n",
    "#     print(\"  â†’ Can use one model for both periods\")\n",
    "# print(\"=\"*80)\n",
    "#\n",
    "#\n",
    "# ============================================================================\n",
    "# SUMMARY OF WHAT TO COMPARE:\n",
    "# ============================================================================\n",
    "#\n",
    "# Model                  Parameters        Uses Data From\n",
    "# --------------------   --------------    ------------------\n",
    "# CONSTRAINED            (Î±, Î²)            Both periods combined\n",
    "#                        2 params          â†’ Assumes stability\n",
    "#\n",
    "# UNCONSTRAINED          (Î±â‚, Î²â‚, Î±â‚‚, Î²â‚‚)  Each period separate\n",
    "#                        4 params          â†’ Allows instability\n",
    "#\n",
    "# WALD TEST: Is the extra flexibility of 4 params justified?\n",
    "# - If yes (reject H0) â†’ Parameters changed over time\n",
    "# - If no (fail to reject) â†’ Parameters stable, use constrained model\n",
    "#\n",
    "# ============================================================================\n",
    "# IMPLEMENTATION TIPS:\n",
    "# ============================================================================\n",
    "# 1. Use the SAME instruments for all three estimations\n",
    "# 2. Use the SAME GMM method (e.g., two-step) for all three\n",
    "# 3. Make sure period dates don't overlap\n",
    "# 4. The constrained model uses nâ‚ + nâ‚‚ observations\n",
    "# 5. Check that n_constrained â‰ˆ n1 + n2 (accounting for lag losses)\n",
    "#\n",
    "# ============================================================================\n",
    "\n",
    "# TODO: Implement Question 3 here following the pseudocode above\n",
    "# Remove the assertion below when you start implementing\n",
    "assert False, \"TODO: Implement Question 3 parameter stability test. Remove this assertion when implemented.\"\n",
    "\n",
    "# ============================================================================\n",
    "# EXAMPLE OUTPUT:\n",
    "# ============================================================================\n",
    "#\n",
    "# CONSTRAINED MODEL (2 parameters):\n",
    "# Î± = -1.045\n",
    "# Î² = 0.978\n",
    "# J-statistic = 12.45\n",
    "# N = 499\n",
    "#\n",
    "# UNCONSTRAINED MODEL (4 parameters):\n",
    "# Period 1 (1960-1978): Î±â‚ = -1.001, Î²â‚ = 0.981, N = 235\n",
    "# Period 2 (1979-2020): Î±â‚‚ = -1.125, Î²â‚‚ = 0.975, N = 264\n",
    "#\n",
    "# ================================================================================\n",
    "# WALD TEST: CONSTRAINED vs UNCONSTRAINED\n",
    "# ================================================================================\n",
    "# H0: Parameters are STABLE â†’ (Î±â‚, Î²â‚) = (Î±â‚‚, Î²â‚‚)\n",
    "# Ha: Parameters are NOT STABLE â†’ (Î±â‚, Î²â‚) â‰  (Î±â‚‚, Î²â‚‚)\n",
    "#\n",
    "# Constrained model:   Î± = -1.045, Î² = 0.978\n",
    "# Period 1:           Î±â‚ = -1.001, Î²â‚ = 0.981\n",
    "# Period 2:           Î±â‚‚ = -1.125, Î²â‚‚ = 0.975\n",
    "#\n",
    "# Wald statistic: 2.34\n",
    "# Degrees of freedom: 2\n",
    "# P-value: 0.3102\n",
    "#\n",
    "# âœ— FAIL TO REJECT H0 at 5% level\n",
    "#   â†’ Constrained model fits just as well\n",
    "#   â†’ Parameters appear stable across time\n",
    "#   â†’ Can use one model for both periods\n",
    "# ================================================================================\n",
    "#\n",
    "# INTERPRETATION:\n",
    "# - We compared two models: one assuming stability, one allowing change\n",
    "# - The Wald test asks: \"Is the unconstrained model significantly better?\"\n",
    "# - P-value > 0.05 means: No, the simple constrained model is sufficient\n",
    "# - Conclusion: Parameters haven't changed significantly over time\n",
    "# ============================================================================\n"
   ],
   "id": "7daab232fe8ea64f"
  },
  {
   "metadata": {
    "id": "cell_041"
   },
   "cell_type": "markdown",
   "source": [
    "### 4.4 Question 4: Hansen-Singleton replication (Table 3) using CARA\n",
    "Repeat the exercises entailed in Questions 2 and 3 under CARA utility. Compare the estimation results and over-identification test results under CRRA and CARA. Discuss any differences you observe."
   ],
   "id": "d1f0bbf28e668590"
  },
  {
   "metadata": {
    "id": "cell_042"
   },
   "cell_type": "markdown",
   "source": "### Panel A",
   "id": "61ac265586dee69e"
  },
  {
   "metadata": {
    "id": "cell_043"
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "Question 4: Table III Panel A & B Replication (CARA)\n",
    "\"\"\"\n",
    "\n",
    "# ============================================================================\n",
    "# TODO: DEFINE PANEL A SPECIFICATIONS (CARA UTILITY)\n",
    "# ============================================================================\n",
    "# INSTRUCTIONS:\n",
    "# Repeat Question 2, but using CARA utility instead of CRRA.\n",
    "# \n",
    "# Changes from Question 2:\n",
    "# - utility='CARA' (instead of 'CRRA')\n",
    "# - All other parameters remain the same\n",
    "#\n",
    "# Panel A uses:\n",
    "# - Consumption: cons_nds_pc (Nondurables)\n",
    "# - Returns: ret_ew_gross AND ret_vw_gross (both EW and VW)\n",
    "# - Utility: CARA  â† KEY CHANGE\n",
    "# - Sample period: '1959-04-01' to '1978-12-31'\n",
    "# - NLAG values: 1, 2, 4\n",
    "#\n",
    "# Example for NLAG=1:\n",
    "# panel_a_cara_specs = [\n",
    "#     EstimationSpec(\n",
    "#         name='Table3A-NDS-NLAG1-CARA',\n",
    "#         utility='CARA',  # â† Changed from CRRA\n",
    "#         consumption_var='cons_nds_pc',\n",
    "#         returns=['ret_ew_gross', 'ret_vw_gross'],\n",
    "#         instruments=['const', 'cons_nds_pc_ratio_l1', 'ret_ew_gross_l1', 'ret_vw_gross_l1'],\n",
    "#         sample_start='1959-04-01',\n",
    "#         sample_end='1978-12-31'\n",
    "#     ),\n",
    "#     # TODO: Add NLAG=2 specification\n",
    "#     # TODO: Add NLAG=4 specification\n",
    "# ]\n",
    "\n",
    "# TODO: Define panel_a_cara_specs list here\n",
    "assert False, \"TODO: Define panel_a_cara_specs for Question 4 Panel A. Remove this assertion when implemented.\"\n",
    "\n",
    "# ============================================================================\n",
    "# PANEL A: EW + VW Returns (CARA)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"Question 4: Panel A (Nondurables, EW+VW, CARA)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Run estimations\n",
    "runner_panel_a_cara = SpecificationRunner()\n",
    "runner_panel_a_cara.run_specs(panel_a_cara_specs, data_quarterly)\n",
    "\n",
    "# Display results\n",
    "df = runner_panel_a_cara.to_dataframe(\n",
    "    by_method=False, \n",
    "    decimals=4, \n",
    "    diagnostics=['N', 'Moments', 'J_stat', 'J_pval', 'DOF', 'Converged']\n",
    ")\n",
    "print(df)\n",
    "# df.to_excel('question4_panel_a_cara.xlsx', index=False)\n",
    "\n",
    "# Summary statistics\n",
    "runner_panel_a_cara.summary_stats()\n",
    ""
   ],
   "id": "e9f0a6c79969835d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "id": "cell_044"
   },
   "cell_type": "code",
   "source": [
    "# ============================================================================\n",
    "# TODO: DEFINE PANEL B SPECIFICATIONS (CARA UTILITY)\n",
    "# ============================================================================\n",
    "# INSTRUCTIONS:\n",
    "# Replicate Panel B with CARA utility.\n",
    "#\n",
    "# Panel B uses:\n",
    "# - Consumption: cons_nds_pc (Nondurables)\n",
    "# - Returns: ret_vw_gross AND rf_gross (VW and Risk-free)\n",
    "# - Utility: CARA  â† KEY CHANGE\n",
    "# - Sample period: '1959-04-01' to '1978-12-31'\n",
    "# - NLAG values: 1, 2, 4\n",
    "#\n",
    "# TODO: Define panel_b_cara_specs list here\n",
    "assert False, \"TODO: Define panel_b_cara_specs for Question 4 Panel B. Remove this assertion when implemented.\"\n",
    "\n",
    "# ============================================================================\n",
    "# PANEL B: VW + RF Returns (CARA)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"Question 4: Panel B (Nondurables, VW+RF, CARA)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Run estimations\n",
    "runner_panel_b_cara = SpecificationRunner()\n",
    "runner_panel_b_cara.run_specs(panel_b_cara_specs, data_quarterly)\n",
    "\n",
    "# Display results\n",
    "df = runner_panel_b_cara.to_dataframe(\n",
    "    by_method=False, \n",
    "    decimals=4, \n",
    "    diagnostics=['N', 'Moments', 'J_stat', 'J_pval', 'DOF', 'Converged']\n",
    ")\n",
    "print(df)\n",
    "# df.to_excel('question4_panel_b_cara.xlsx', index=False)\n",
    "\n",
    "# Summary statistics\n",
    "runner_panel_b_cara.summary_stats()\n",
    ""
   ],
   "id": "b5226a84ae37c982",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "id": "cell_045"
   },
   "cell_type": "markdown",
   "source": [
    "### 4.5 Question 5: Validation\n",
    "On the basis of the evidence from your work, which is the more palatable parameterization. Briefly explain the reasons for your choice.\n"
   ],
   "id": "f2edcbe044e4b31d"
  },
  {
   "metadata": {
    "id": "cell_046"
   },
   "cell_type": "code",
   "source": "",
   "id": "275c621d24f8554b",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
