{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 5: Procurement\n",
    "\n",
    "This notebook replicates the structural estimation from:\n",
    "\n",
    "**\"Winning by Default: Why is There So Little Competition in Government Procurement?\"**\n",
    "*Kang & Miller, Review of Economic Studies (2022)*"
   ],
   "id": "md0"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Model Setup, Theory, and Identification\n",
    "\n",
    "### 1.1 Environment\n",
    "\n",
    "The government agency procures IT services from contractors. Each project $i$ is characterized by:\n",
    "- **Project attributes** $x_i$ (duration, size, service type, commercial vs. defense, etc.)\n",
    "- **Agency attributes** $z_i$ (experience, workload, congressional representation)\n",
    "- **Competition variables** (number of past winners, number of establishments)\n",
    "\n",
    "Each contractor has a private type $\\pi_i \\in [0,1]$ drawn from a Beta distribution on $[\\pi_{\\min}, \\pi_{\\max}]$.\n",
    "The type $\\pi$ determines the probability of being a \"high-cost\" contractor:\n",
    "- With probability $\\pi$, the contractor is high-cost (type $H$)\n",
    "- With probability $1 - \\pi$, the contractor is low-cost (type $L$)\n",
    "\n",
    "### 1.2 Contract Outcomes and Moral Hazard\n",
    "\n",
    "After awarding the contract, cost shocks $s = (s_1, s_2)$ are realized:\n",
    "- $s_1$: ex-post price modifications (three categories), observed only for fixed-price contracts\n",
    "- $s_2$: ex-post duration modifications (three categories), observed for all contracts\n",
    "\n",
    "The distributions of $s$ differ by contractor type, creating **moral hazard**:\n",
    "- $f_L(s|x)$: distribution for low-cost contractors\n",
    "- $f_H(s|x)$: distribution for high-cost contractors\n",
    "\n",
    "The likelihood ratio $\\ell(s) = f_L(s) / f_H(s)$ measures the informativeness of contract outcomes.\n",
    "\n",
    "### 1.3 Optimal Contract Design (Adverse Selection)\n",
    "\n",
    "The agency offers a menu of contracts. For a cost-plus contract awarded to a contractor with type $\\pi$:\n",
    "- **Base price**: $p_0(\\pi, x) = \\alpha(\\pi, x) + \\beta(\\pi, x) - \\int \\psi(q(\\pi, s)) f_H(s) ds$\n",
    "- **Ex-post payment schedule**: $q(\\ell(s); \\pi) = -\\psi \\cdot \\ln\\left(\\frac{1 - \\tilde{\\pi}}{1 - \\tilde{\\pi} \\cdot \\ell(s)}\\right)$\n",
    "\n",
    "where $\\tilde{\\pi}$ solves the IR constraint for low-cost contractors, and:\n",
    "- $\\alpha(\\pi, x)$: project cost for low-cost contractors\n",
    "- $\\beta(\\pi, x)$: additional cost for high-cost contractors (information rent)\n",
    "- $\\psi(x)$: CARA risk-tolerance parameter (higher $\\psi$ → *less* risk averse; the Arrow-Pratt measure is $1/\\psi$)\n",
    "\n",
    "For a fixed-price contract with $n$ bidders:\n",
    "$$p_n(\\pi, x) = \\alpha(\\pi, x) + \\frac{\\beta(\\pi, x) \\cdot \\pi (1-\\pi)^{n-1}}{1 - (1-\\pi)^n}$$\n",
    "\n",
    "where the second term is the expected information rent from the lowest-bidding contractor.\n",
    "\n",
    "### 1.4 Entry and Endogenous Competition\n",
    "\n",
    "Each potential contractor $j$ faces a competition cost $\\eta_j$ drawn from $N(\\mu_\\eta(x,z), \\sigma_\\eta^2)$.\n",
    "The contractor participates (enters the bidding) if the expected surplus exceeds $\\eta_j$:\n",
    "$$\\Pr(\\text{compete} | x, z) = \\Phi\\left(\\frac{\\omega(x,z) - \\mu_\\eta(x,z)}{\\sigma_\\eta}\\right)$$\n",
    "\n",
    "where $\\omega(\\pi, x, z) = (1 - e^{-\\lambda \\pi})(\\beta + \\gamma) - \\kappa \\lambda$ captures the\n",
    "expected payoff from competing, with:\n",
    "- $\\lambda(\\pi, x, z)$: expected number of rival bidders\n",
    "- $\\kappa(\\pi, x, z)$: buyer search costs (per-bidder cost of evaluating)\n",
    "- $\\beta(\\pi, x) + \\gamma(\\pi, x)$: total contractor surplus\n",
    "\n",
    "### 1.5 Identification Strategy\n",
    "\n",
    "The five-step sequential estimation exploits the following identification arguments (Section 4 of the paper):\n",
    "\n",
    "1. **Step 1** ($\\pi$ distribution): The choice between fixed-price ($d=1$) and cost-plus ($d=0$)\n",
    "   contracts identifies the distribution of $\\pi$, since $\\Pr(d=1 | \\pi, n, x, z)$ depends on the\n",
    "   type distribution through a selection mechanism.\n",
    "\n",
    "2. **Step 2** ($s$ distribution): Contract outcomes $(s_1, s_2)$ directly identify $f_L$ and $f_H$\n",
    "   from their observed marginal distributions.\n",
    "\n",
    "3. **Step 3** (Cost parameters): Given Steps 1–2, the model predicts expected prices $E[p|x,z,d]$\n",
    "   and expected ex-post payments $E[q|x,z,d=0]$, which are matched to data via NLS.\n",
    "\n",
    "4. **Step 4** (Buyer search costs $\\kappa$): Given all prior parameters, $\\kappa$ is computed directly\n",
    "   from the equilibrium pricing equation.\n",
    "\n",
    "5. **Step 5** (Competition costs $\\eta$): The observed entry decision $r$ (restricted vs. competitive)\n",
    "   identifies $\\eta$ distribution parameters via MLE.\n"
   ],
   "id": "md1"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 2: Data Loading and Summary Statistics\n",
    "\n",
    "The dataset contains 6,981 U.S. federal IT procurement contracts. We load the data and construct the variables used in estimation, following the variable definitions in the paper's Table 1."
   ],
   "id": "md2"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-26T04:57:21.951430Z",
     "start_time": "2026-02-26T04:57:21.881582Z"
    }
   },
   "source": "import os\nimport numpy as np\nimport pandas as pd\nfrom scipy import optimize, stats\nfrom scipy.special import gammaln\nfrom tabulate import tabulate\nimport warnings\nwarnings.filterwarnings('ignore')\n\nnp.random.seed(42)\nprint(\"Libraries loaded successfully.\")",
   "id": "cd3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries loaded successfully.\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-26T04:57:22.051992Z",
     "start_time": "2026-02-26T04:57:21.957164Z"
    }
   },
   "source": "# ── Load raw data into DataFrame ──\n# Column names follow Table 1 of Kang & Miller (2022) and estimation.m\n#\n# Players:\n#   - Agency (buyer):  a U.S. federal government agency procuring IT services\n#   - Contractor (seller): a private IT firm bidding on the project\n#\n# Timeline:\n#   1. Agency posts project with observable characteristics (x, z)\n#   2. Contractors privately know their type pi ~ Beta(alpha, beta)\n#   3. Agency designs contract: fixed-price (d=1) vs cost-plus (d=0)\n#   4. Contract awarded; cost shock realized -> outcomes s1, s2 observed\n\nBASE_DIR = os.path.dirname(os.path.abspath('__file__'))\nDATA_PATH = os.path.join(BASE_DIR, 'data')\n\ncol_names = [\n    # ── Contract outcomes (observed ex-post) ──\n    'base_price',            # p:  base price ($)\n    'expost_price_change',   # q:  ex-post price changes ($), cost-plus only\n    's1_cat1', 's1_cat2', 's1_cat3',   # price modification categories (FP only)\n    's2_cat1', 's2_cat2', 's2_cat3',   # duration modification categories (all)\n    # ── Contract design (agency's ex-ante choice) ──\n    'restricted',            # r:  1 = sole-source (no competition), 0 = competitive\n    'num_bids',              # b:  number of bids received\n    'fixed_price',           # d:  1 = firm-fixed-price, 0 = cost-plus\n    # ── Project attributes x (publicly observed) ──\n    'dur_gt_3mo',            # duration > 3 months\n    'size',                  # project size (log dollars)\n    'service',               # service contract (vs. supply/construction)\n    'commercial',            # commercial item\n    'defense',               # Department of Defense (vs. civilian agency)\n    'dca',                   # definitive contract action\n    # ── Agency attributes z (publicly observed) ──\n    'experience_raw',        # agency's procurement experience (continuous)\n    'past_experience_raw',   # agency-contractor match: worked together before?\n    'workload_raw',          # agency workload (continuous)\n    'congress_rep',          # congressional oversight on this agency\n    # ── Market structure (publicly observed) ──\n    'num_past_winners_raw',  # number of distinct past winners in this market\n    'num_establishments_raw',# number of firms in this market\n    # ── Auxiliary ──\n    'xcase',                 # project-type case indicator (for grouping)\n    'sol_info1', 'sol_info2', 'sol_info3', 'sol_info4'\n]\n\ndf = pd.read_csv(os.path.join(DATA_PATH, 'data_main.csv'), header=None, names=col_names)\nnsim = len(df)\n\n# ── Binarize continuous covariates (thresholds from estimation.m) ──\ndf['experience']        = (df['experience_raw'] >= 0.8).astype(float)        # ≥ 5 yrs\ndf['past_experience']   = (df['past_experience_raw'] > 0).astype(float)      # ever worked together\ndf['workload']          = (df['workload_raw'] >= 4.5).astype(float)          # high workload\ndf['num_past_winners']  = (df['num_past_winners_raw'] >= 2).astype(float)    # ≥ 2 past winners\ndf['num_establishments']= (df['num_establishments_raw'] >= 24).astype(float) # ≥ 24 firms\n\n# ── Derived variables ──\nbmax = 4\ndf['b_censored']  = np.minimum(df['num_bids'], bmax)\ndf['competition']  = (1 - df['restricted']) * df['b_censored']  # c: 0=sole-source, 1..4=competitive\n\n# ── Define variable groups (used throughout estimation) ──\n# These lists make it easy to reference groups of columns by role\nPROJ_COLS  = ['dur_gt_3mo', 'size', 'service', 'commercial', 'defense', 'dca']\nAGEN_COLS  = ['experience', 'past_experience', 'workload', 'congress_rep']\nCOMP_COLS  = ['num_past_winners', 'num_establishments']\nS1_COLS    = ['s1_cat1', 's1_cat2', 's1_cat3']\nS2_COLS    = ['s2_cat1', 's2_cat2', 's2_cat3']\n\n# ── Extract numpy arrays for estimation ──\n# Scipy optimizers need raw numpy; we extract once here and reuse throughout.\n# Notation: we keep short aliases (p, q, d, r, b, s1, s2) matching the paper.\np  = df['base_price'].values\nq  = df['expost_price_change'].values\ns1 = df[S1_COLS].values                            # (nsim, 3)\ns2 = df[S2_COLS].values                            # (nsim, 3)\nr  = df['restricted'].values\nb  = df['num_bids'].values\nd  = df['fixed_price'].values\nb_censored = df['b_censored'].values\nc  = df['competition'].values\n\n# Project attributes: intercept + 6 binary indicators\nxproj = np.column_stack([np.ones(nsim), df[PROJ_COLS].values])   # (nsim, 7)\nxagen = df[AGEN_COLS].values                                      # (nsim, 4)\nxcomp = df[COMP_COLS].values                                      # (nsim, 2)\nxzvec = np.column_stack([xproj, xagen, xcomp])                    # (nsim, 13)\n\n# Dimensions\nnproj = xproj.shape[1]         # 7 (intercept + 6)\nnagen = xagen.shape[1]         # 4\nncomp = xcomp.shape[1]         # 2\nnxz   = nproj + nagen + ncomp  # 13\n\n# ── Project-type case mapping ──\n# Group observations by unique project-attribute combinations\n# (Used in Step 3 to avoid redundant simulation across identical project types)\nxcase = df['xcase'].values\nunique_cases = sorted(df['xcase'].unique())\nncase = len(unique_cases)\n\nxproj_case = (\n    pd.DataFrame(xproj, columns=['intercept'] + PROJ_COLS)\n    .assign(xcase=xcase)\n    .groupby('xcase')\n    .mean()\n    .values\n)\n\n# ── Print summary ──\nprint(f\"Data loaded: {nsim:,} observations, {ncase} unique project types\")\nprint(f\"Dimensions:  nproj={nproj}, nagen={nagen}, ncomp={ncomp}, nxz={nxz}\")\nprint(f\"DataFrame:   {df.shape[0]} rows × {df.shape[1]} columns\")",
   "id": "cd4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded: 6,981 observations, 62 unique project types\n",
      "Dimensions:  nproj=7, nagen=4, ncomp=2, nxz=13\n",
      "DataFrame:   6981 rows × 35 columns\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-26T04:57:22.164946Z",
     "start_time": "2026-02-26T04:57:22.057808Z"
    }
   },
   "source": [
    "# ── Summary Statistics (Table 1 of the paper) ──\n",
    "\n",
    "# Panel A: Contract outcomes\n",
    "outcome_vars = ['base_price', 'expost_price_change', 'fixed_price', 'restricted', 'num_bids']\n",
    "outcome_labels = ['Base Price p ($)', 'Ex-post Changes q ($)', 'Firm-Fixed Price (d=1)',\n",
    "                  'Restricted (r=1)', 'Number of Bids']\n",
    "\n",
    "rows = []\n",
    "for var, label in zip(outcome_vars, outcome_labels):\n",
    "    col = df[var]\n",
    "    rows.append([label, f\"{col.mean():.4f}\", f\"{col.std():.4f}\", f\"{col.min():.4f}\", f\"{col.max():.4f}\"])\n",
    "\n",
    "# s1 categories (FP only)\n",
    "fp_mask = df['fixed_price'] == 1\n",
    "for cat in S1_COLS:\n",
    "    col = df.loc[fp_mask, cat]\n",
    "    rows.append([f\"{cat} (FP only)\", f\"{col.mean():.4f}\", f\"{col.std():.4f}\",\n",
    "                 f\"{col.min():.4f}\", f\"{col.max():.4f}\"])\n",
    "\n",
    "# s2 categories (all contracts)\n",
    "for cat in S2_COLS:\n",
    "    col = df[cat]\n",
    "    rows.append([f\"{cat} (all)\", f\"{col.mean():.4f}\", f\"{col.std():.4f}\",\n",
    "                 f\"{col.min():.4f}\", f\"{col.max():.4f}\"])\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"Table 1: Summary Statistics\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\nPanel A: Contract Outcomes\")\n",
    "print(\"-\" * 50)\n",
    "print(tabulate(rows, headers=[\"Variable\", \"Mean\", \"Std Dev\", \"Min\", \"Max\"],\n",
    "               tablefmt=\"simple\", numalign=\"right\"))\n",
    "\n",
    "# Panel B: Project and agency attributes\n",
    "print(\"\\nPanel B: Covariate Means\")\n",
    "print(\"-\" * 50)\n",
    "cov_vars = PROJ_COLS + AGEN_COLS + COMP_COLS\n",
    "cov_rows = [[var, f\"{df[var].mean():.4f}\"] for var in cov_vars]\n",
    "print(tabulate(cov_rows, headers=[\"Covariate\", \"Mean\"], tablefmt=\"simple\", numalign=\"right\"))\n",
    "\n",
    "print(f\"\\nN = {nsim:,} contracts\")"
   ],
   "id": "cd5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Table 1: Summary Statistics\n",
      "======================================================================\n",
      "\n",
      "Panel A: Contract Outcomes\n",
      "--------------------------------------------------\n",
      "Variable                    Mean    Std Dev          Min          Max\n",
      "----------------------  --------  ---------  -----------  -----------\n",
      "Base Price p ($)          336754     188771       126847       999736\n",
      "Ex-post Changes q ($)    26951.4     130273      -822319  2.49503e+06\n",
      "Firm-Fixed Price (d=1)    0.9622     0.1908            0            1\n",
      "Restricted (r=1)          0.6598     0.4738            0            1\n",
      "Number of Bids            1.6353     1.9246            1           35\n",
      "s1_cat1 (FP only)         5086.2    61474.3      -682889  1.78564e+06\n",
      "s1_cat2 (FP only)        21077.7     103599      -822319   1.6056e+06\n",
      "s1_cat3 (FP only)       -1630.77    37811.2  -1.4919e+06       707700\n",
      "s2_cat1 (all)             0.1299     0.8285           -1      17.7174\n",
      "s2_cat2 (all)             0.1786     0.8305      -1.7381      15.2976\n",
      "s2_cat3 (all)             0.1853     1.0393      -5.0247         19.4\n",
      "\n",
      "Panel B: Covariate Means\n",
      "--------------------------------------------------\n",
      "Covariate             Mean\n",
      "------------------  ------\n",
      "dur_gt_3mo          0.7129\n",
      "size                 0.475\n",
      "service             0.2574\n",
      "commercial           0.677\n",
      "defense             0.6694\n",
      "dca                 0.4915\n",
      "experience          0.4138\n",
      "past_experience     0.4067\n",
      "workload            0.4968\n",
      "congress_rep        0.1114\n",
      "num_past_winners    0.7857\n",
      "num_establishments  0.7539\n",
      "\n",
      "N = 6,981 contracts\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-26T04:57:22.258558Z",
     "start_time": "2026-02-26T04:57:22.167628Z"
    }
   },
   "source": "# ── Competition Distribution ──\ncomp_dist = (\n    df.groupby('competition')\n    .size()\n    .reset_index(name='count')\n    .assign(fraction=lambda x: x['count'] / nsim)\n)\n\nrows_comp = [[f\"c = {int(row['competition'])}\", int(row['count']), f\"{row['fraction']:.4f}\"]\n             for _, row in comp_dist.iterrows()]\n\nprint(\"Competition Distribution:\")\nprint(tabulate(rows_comp, headers=[\"Competition Level (c)\", \"Count\", \"Fraction\"],\n               tablefmt=\"simple\", numalign=\"right\"))\n\n# ── Contract Type Distribution ──\nn_fp = int(df['fixed_price'].sum())\nn_cp = nsim - n_fp\nn_restr = int(df['restricted'].sum())\nn_comp  = nsim - n_restr\n\nprint(f\"\\nFixed-Price contracts: {n_fp} ({n_fp/nsim*100:.1f}%)\")\nprint(f\"Cost-Plus contracts:   {n_cp} ({n_cp/nsim*100:.1f}%)\")\nprint(f\"Restricted (no competition): {n_restr} ({n_restr/nsim*100:.1f}%)\")\nprint(f\"Competitive:                 {n_comp} ({n_comp/nsim*100:.1f}%)\")",
   "id": "cd6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Competition Distribution:\n",
      "Competition Level (c)      Count    Fraction\n",
      "-----------------------  -------  ----------\n",
      "c = 0                       4606      0.6598\n",
      "c = 1                        871      0.1248\n",
      "c = 2                        453      0.0649\n",
      "c = 3                        523      0.0749\n",
      "c = 4                        528      0.0756\n",
      "\n",
      "Fixed-Price contracts: 6717 (96.2%)\n",
      "Cost-Plus contracts:   264 (3.8%)\n",
      "Restricted (no competition): 4606 (66.0%)\n",
      "Competitive:                 2375 (34.0%)\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 3: Estimation\n",
    "\n",
    "### Overview\n",
    "\n",
    "**Players**: Agency (government buyer) chooses contract form; Contractor (private seller) knows their type $\\pi$.\n",
    "\n",
    "**Timeline**:\n",
    "| | Step    | Description |\n",
    "|------|-----------------|-----------|\n",
    "| 1 | Nature | Contractor draws type $\\pi \\sim Beta (\\alpha, \\beta)$ |\n",
    "| 2 | Entry  | Contractors compete if expected surplus > private cost $\\eta$ |\n",
    "| 3 | Design | Agency picks FP (d=1) or CP (d=0) to minimize expected cost |\n",
    "| 4 | Bid    | Contractor submits base price $p$ |\n",
    "| 5 | Execute | Cost shock realized |\n",
    "| 6 | Signal | Ex-post signals $s_1$ (price mods), $s_2$ (duration mods) observed |\n",
    "| 7 | Settle | CP: agency pays $q(s)$;  FP: price adjustments applied |\n",
    "\n",
    "**FP vs CP trade-off**: FP transfers cost risk to contractor (who demands a premium); CP reimburses costs (but contractor may inflate). Agency picks whichever is cheaper in expectation.\n",
    "\n",
    "**Estimation roadmap** (5 sequential steps):\n",
    "\n",
    "| Step | What we estimate | Data used | Method | # params |\n",
    "|------|-----------------|-----------|--------|----------|\n",
    "| 1 | Type distribution $f(\\pi \\mid x,z)$ | Contract choice $d$ | MLE (binary) | 14 × 5 |\n",
    "| 2 | Signal distributions $f_L(s)$ | Signals $s_1, s_2$ | MLE (two-part) | 30 + 36 |\n",
    "| 3 | Cost structure $(\\alpha, \\beta, \\psi)$ + signal shifts | Prices $p, q$ | NLS | 35 |\n",
    "| 4 | Search cost $\\kappa$ | — (closed form from Steps 1–3) | Analytic | 0 |\n",
    "| 5 | Competition cost $F(\\eta)$ | Entry/competition $r$ | MLE (binary) | 14 |\n",
    "\n",
    "**Dependencies**: Step 1 → Step 2 → Step 3 (uses steps 1-2) → Step 4 (uses steps 1–3) → Step 5 (uses steps 1–4).\n"
   ],
   "id": "md7"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-26T04:57:22.353535Z",
     "start_time": "2026-02-26T04:57:22.261810Z"
    }
   },
   "source": [
    "# ── Gauss-Legendre Quadrature (fun_lgwt.m) ──\n",
    "def fun_lgwt(N, a, b):\n",
    "    \"\"\"Gauss-Legendre quadrature nodes and weights on [a, b].\"\"\"\n",
    "    N_range = np.arange(1, N)\n",
    "    beta_gl = N_range / np.sqrt(4 * N_range**2 - 1)\n",
    "    J = np.diag(beta_gl, -1) + np.diag(beta_gl, 1)\n",
    "    eigvals, eigvecs = np.linalg.eigh(J)\n",
    "    x = eigvals\n",
    "    w = 2 * eigvecs[0, :]**2\n",
    "    # Map from [-1, 1] to [a, b]\n",
    "    x = 0.5 * (b - a) * x + 0.5 * (a + b)\n",
    "    w = 0.5 * (b - a) * w\n",
    "    # Sort\n",
    "    idx = np.argsort(x)\n",
    "    return x[idx], w[idx]\n",
    "\n",
    "# ── Halton Sequence Generator (halton.m) ──\n",
    "def halton_seq(ndim, npts, bases):\n",
    "    \"\"\"Generate Halton quasi-random sequence (MATLAB-compatible: starts at index 0).\"\"\"\n",
    "    result = np.zeros((npts, ndim))\n",
    "    for dim in range(ndim):\n",
    "        base = bases[dim]\n",
    "        seq = np.zeros(npts)\n",
    "        for i in range(npts):\n",
    "            n = i           # start at 0 to match MATLAB's halton.m (seed=0)\n",
    "            f = 1.0\n",
    "            val = 0.0\n",
    "            while n > 0:\n",
    "                f /= base\n",
    "                val += f * (n % base)\n",
    "                n //= base\n",
    "            seq[i] = val\n",
    "        result[:, dim] = seq\n",
    "    return result\n",
    "\n",
    "# ── Constants ──\n",
    "ERR   = 1e-64     # floor for log/division\n",
    "MV    = 500       # cap for exponentials\n",
    "pimin = 0.01\n",
    "pimax = 0.99\n",
    "sngrid = 5000     # simulation draws for s\n",
    "pngrid = 50       # quadrature nodes for pi\n",
    "\n",
    "# ── Quadrature nodes ──\n",
    "pivec, piweight = fun_lgwt(pngrid, pimin, pimax)\n",
    "\n",
    "# ── Halton draws (6 dimensions: s1 cat 1-3, s2 cat 1-3) ──\n",
    "dlt = 100   # burn-in\n",
    "bases = [2, 3, 5, 7, 11, 13]\n",
    "smat_full = halton_seq(6, dlt + sngrid, bases)\n",
    "smat = smat_full[dlt:, :]   # (sngrid, 6)\n",
    "\n",
    "print(f\"Quadrature: {pngrid} nodes on [{pimin}, {pimax}]\")\n",
    "print(f\"Halton draws: {sngrid} points in {len(bases)} dimensions (bases={bases})\")\n",
    "print(f\"  pi range: [{pivec[0]:.4f}, {pivec[-1]:.4f}]\")\n",
    "print(f\"  Halton sample: min={smat.min():.4f}, max={smat.max():.4f}\")\n"
   ],
   "id": "cd8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quadrature: 50 nodes on [0.01, 0.99]\n",
      "Halton draws: 5000 points in 6 dimensions (bases=[2, 3, 5, 7, 11, 13])\n",
      "  pi range: [0.0106, 0.9894]\n",
      "  Halton sample: min=0.0000, max=0.9998\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Type Distribution $f(\\pi \\mid x, z)$\n",
    "\n",
    "**Reference**: Section 5.1, Proposition 2, Online Appendix B\n",
    "\n",
    "**Data** Binary contract choice $d_i \\in \\{0, 1\\}$ (CP vs FP)\n",
    "\n",
    "**Assumption** $\\pi_i \\sim \\text{Beta}(\\alpha_i, \\beta)$ with $\\alpha_i = 1 + \\exp([x_i, z_i] \\cdot \\theta_\\alpha)$, $\\beta = 1 + \\exp(\\theta_\\beta)$\n",
    "\n",
    "**Parameters** $\\theta_\\alpha$ (13 coefs), $\\theta_\\beta$ (1 scalar) = 14 per competition level\n",
    "\n",
    "**Key equation** (Proposition 2 — agency's cost minimization → closed-form choice probability):\n",
    "\n",
    "$$\\boxed{\\Pr(\\text{CP}_i) = \\frac{1}{1 + \\displaystyle\\int \\left[\\frac{\\pi}{1-\\pi}\\right]^{n_i} f(\\pi \\mid x_i, z_i)\\, d\\pi}}$$\n",
    "\n",
    "- The ratio $[\\pi/(1-\\pi)]^n$ measures FP's relative advantage. More bidders ($n$ large) → integral large → $\\Pr(\\text{CP})$ small.\n",
    "- The integral is computed via **Gauss-Legendre quadrature** (50 nodes) since it has no closed form.\n",
    "\n",
    "**Estimation**: Binary MLE — find $(\\theta_\\alpha, \\theta_\\beta)$ that maximize $\\sum_i [d_i \\ln \\Pr(\\text{FP}_i) + (1-d_i) \\ln \\Pr(\\text{CP}_i)]$, separately for each competition level $c \\in \\{0,...,4\\}$.\n",
    "\n",
    "**Output**: `par_var` (14×5) → prior $f(\\pi \\mid x,z)$, posterior $f(\\pi \\mid d, x, z)$, model-predicted $\\Pr(\\text{CP})$.\n"
   ],
   "id": "md9"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-26T04:57:36.172868Z",
     "start_time": "2026-02-26T04:57:22.359212Z"
    }
   },
   "source": [
    "# ═══════════════════════════════════════════════════════════════════\n# Step 1: Estimate the pi distribution via MLE\n# ═══════════════════════════════════════════════════════════════════\n\ndef step1_negll(theta, df_sub, pivec, piweight, pimin, pimax):\n    \"\"\"\n    Negative log-likelihood for Step 1 (one competition level).\n\n    Pipeline:  theta -> Beta(alpha, beta) -> f(pi) -> Pr(CP) -> log-likelihood\n    \"\"\"\n    n = len(df_sub)\n    K = len(pivec)\n\n    # (1) Parameters -> Beta shape parameters\n    #     alpha_i = 1 + exp(xz_i @ theta_alpha),  beta = 1 + exp(theta_beta)\n    xz = np.column_stack([np.ones(n), df_sub[PROJ_COLS + AGEN_COLS + COMP_COLS].values])\n    alpha = 1.0 + np.exp(np.clip(xz @ theta[:xz.shape[1]], -20, 20))  # (n,)\n    beta  = 1.0 + np.exp(np.clip(theta[xz.shape[1]], -20, 20))        # scalar\n\n    # (2) Beta density f(pi | alpha, beta) at each quadrature node\n    #     Rescale pi from [pimin, pimax] to [0, 1] for Beta PDF\n    pi_std = (pivec - pimin) / (pimax - pimin)                         # (K,)\n    f_pi = stats.beta.pdf(pi_std[None, :], alpha[:, None], beta) / (pimax - pimin)  # (n, K)\n    f_pi = np.nan_to_num(f_pi, nan=0.0, posinf=1e10)\n\n    # (3) Pr(CP) = 1 / (1 + integral),  where integral = sum_k [pi/(1-pi)]^b * f(pi) * w\n    b_obs = df_sub['b_censored'].values\n    fp_advantage = (pivec[None, :] / (1 - pivec[None, :])) ** b_obs[:, None]  # (n, K)\n    integral = (fp_advantage * f_pi * piweight[None, :]).sum(axis=1)           # (n,)\n    pr_cp = 1.0 / (1.0 + integral)\n    pr_cp = np.clip(pr_cp, ERR, 1 - ERR)\n\n    # (4) Binary log-likelihood: d=1 -> log Pr(FP),  d=0 -> log Pr(CP)\n    d_obs = df_sub['fixed_price'].values\n    ll = d_obs * np.log(1 - pr_cp) + (1 - d_obs) * np.log(pr_cp)\n\n    return -np.sum(ll) if np.isfinite(ll.sum()) else 1e20\n\n\n# ── Estimate for each competition level ───────────────────────────\n\nprint(\"Step 1: Estimating pi distribution for each competition level...\")\nprint(f\"  Parameters per level: {nxz + 1} (= {nxz} covariate coeffs + 1 beta shape)\\n\")\n\npar_var = np.zeros((nxz + 1, bmax + 1))   # (14, 5)\n\nfor c_level in range(bmax + 1):\n    df_sub = df[df['competition'] == c_level]\n    if len(df_sub) == 0:\n        continue\n\n    negll = lambda theta: step1_negll(theta, df_sub, pivec, piweight, pimin, pimax)\n\n    # Try L-BFGS-B first; fall back to Nelder-Mead with random starts\n    x0 = np.zeros(nxz + 1)\n    result = optimize.minimize(negll, x0, method='L-BFGS-B',\n                               options={'maxiter': 5000, 'ftol': 1e-6})\n\n    if not result.success or not np.isfinite(result.fun):\n        print(f\"  c={c_level}: L-BFGS-B failed, trying Nelder-Mead...\")\n        for trial in range(5):\n            x0_alt = np.random.randn(nxz + 1) * 0.1\n            res_alt = optimize.minimize(negll, x0_alt, method='Nelder-Mead',\n                                        options={'maxiter': 20000, 'xatol': 1e-6, 'fatol': 1e-6})\n            if res_alt.success and np.isfinite(res_alt.fun) and res_alt.fun < result.fun:\n                result = res_alt\n                break\n\n    par_var[:, c_level] = result.x\n    print(f\"  c={c_level}: {len(df_sub):>4d} obs, converged={result.success}, \"\n          f\"neg-loglik={result.fun:.4f}\")\n\nprint(\"\\nStep 1 estimation complete.\")\n"
   ],
   "id": "cd10",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Estimating pi distribution for each competition level...\n",
      "  Parameters per level: 14 (= 13 covariate coeffs + 1 beta shape)\n",
      "\n",
      "  c=0: 4606 obs, converged=True, neg-loglik=625.4139\n",
      "  c=1:  871 obs, converged=True, neg-loglik=117.0322\n",
      "  c=2:  453 obs, converged=True, neg-loglik=16.6773\n",
      "  c=3:  523 obs, converged=True, neg-loglik=57.9023\n",
      "  c=4:  528 obs, converged=True, neg-loglik=27.9218\n",
      "\n",
      "Step 1 estimation complete.\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-26T04:57:36.313846Z",
     "start_time": "2026-02-26T04:57:36.212952Z"
    }
   },
   "source": [
    "# ═══════════════════════════════════════════════════════════════════\n",
    "# Step 1 (cont): Reconstruct pi distributions for all observations\n",
    "# ═══════════════════════════════════════════════════════════════════\n",
    "#\n",
    "# From par_var we compute three objects needed by later steps:\n",
    "#   fpi_v : f(pi | x, z)       — prior type density (before seeing d)\n",
    "#   fpi   : f(pi | d, x, z)    — posterior type density (after seeing d)\n",
    "#   prv   : Pr(CP | x, z)      — model-predicted contract choice prob\n",
    "\n",
    "# ── (a) Recover Beta shapes for each obs ──────────────────────────\n",
    "\n",
    "par_fpiv = np.zeros((nsim, 2))  # columns: alpha_i, beta_i\n",
    "\n",
    "for c_level in range(bmax + 1):\n",
    "    df_sub = df[df['competition'] == c_level]\n",
    "    if len(df_sub) == 0:\n",
    "        continue\n",
    "    idx = df_sub.index\n",
    "    theta = par_var[:, c_level]\n",
    "    xz = np.column_stack([np.ones(len(df_sub)),\n",
    "                          df_sub[PROJ_COLS + AGEN_COLS + COMP_COLS].values])\n",
    "    par_fpiv[idx, 0] = 1.0 + np.exp(np.clip(xz @ theta[:xz.shape[1]], -20, 20))\n",
    "    par_fpiv[idx, 1] = 1.0 + np.exp(np.clip(theta[xz.shape[1]], -20, 20))\n",
    "\n",
    "# ── (b) Prior density f(pi | x, z) at quadrature nodes ───────────\n",
    "\n",
    "pi_std = (pivec - pimin) / (pimax - pimin)  # standardize to [0,1]\n",
    "fpi_v = stats.beta.pdf(\n",
    "    pi_std[None, :],          # (1, K)\n",
    "    par_fpiv[:, 0:1],         # (N, 1)  -- alpha\n",
    "    par_fpiv[:, 1:2]          # (N, 1)  -- beta\n",
    ") / (pimax - pimin)           # (N, K)\n",
    "fpi_v = np.nan_to_num(fpi_v, nan=0.0, posinf=1e10)\n",
    "\n",
    "# ── (c) Pr(cost-plus) for all observations ────────────────────────\n",
    "\n",
    "fp_advantage = (pivec[None, :] / (1 - pivec[None, :])) ** b_censored[:, None]  # (N, K)\n",
    "integral = (fp_advantage * fpi_v * piweight[None, :]).sum(axis=1)               # (N,)\n",
    "prv = 1.0 / (1.0 + integral)\n",
    "\n",
    "# ── (d) Posterior density f(pi | d, x, z) ─────────────────────────\n",
    "#\n",
    "# FP (d=1): posterior tilts toward low-pi (selection effect)\n",
    "#     f(pi|d=1) = Pr(CP)/(1-Pr(CP)) * [pi/(1-pi)]^b * f(pi|x,z)\n",
    "# CP (d=0): posterior = prior (no update)\n",
    "\n",
    "bayes_ratio = (prv / np.clip(1 - prv, ERR, None))[:, None]   # (N, 1)\n",
    "fpi_fp = bayes_ratio * fp_advantage * fpi_v                    # (N, K)\n",
    "\n",
    "fpi = np.where(d[:, None] == 1, fpi_fp, fpi_v)                # (N, K)\n",
    "\n",
    "# ── (e) Display results ──────────────────────────────────────────\n",
    "print(\"=\" * 70)\n",
    "print(\"Step 1 Results: Estimated Parameters\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "param_labels = (\n",
    "    [f\"theta_alpha[{c}]\" for c in ['intercept'] + PROJ_COLS + AGEN_COLS + COMP_COLS]\n",
    "    + [\"theta_beta\"]\n",
    ")\n",
    "headers = [\"Parameter\", \"c=0\", \"c=1\", \"c=2\", \"c=3\", \"c=4\"]\n",
    "rows = [[label] + [f\"{par_var[i, c]:.6f}\" for c in range(bmax + 1)]\n",
    "        for i, label in enumerate(param_labels)]\n",
    "print(tabulate(rows, headers=headers, tablefmt=\"simple\", numalign=\"right\"))\n",
    "\n",
    "print(f\"\\nModel-predicted Pr(CP): mean={np.mean(prv):.4f}, median={np.median(prv):.4f}\")\n",
    "print(f\"Observed CP share:     {1 - np.mean(d):.4f}\")\n",
    "print(f\"Observed FP share:     {np.mean(d):.4f}\")\n"
   ],
   "id": "cd11",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Step 1 Results: Estimated Parameters\n",
      "======================================================================\n",
      "Parameter                              c=0        c=1        c=2        c=3       c=4\n",
      "-------------------------------  ---------  ---------  ---------  ---------  --------\n",
      "theta_alpha[intercept]             8.36482    4.06493    5.59828    9.57096   2.00086\n",
      "theta_alpha[dur_gt_3mo]           0.034758   0.447211  -0.403943   0.362774  0.441466\n",
      "theta_alpha[size]                -0.439383  -0.309998    0.08191   0.190361  0.085618\n",
      "theta_alpha[service]              -3.76404   -3.09883   0.164976   -1.82487  -1.49358\n",
      "theta_alpha[commercial]            1.38938    3.50822     1.4451   0.684505   2.54461\n",
      "theta_alpha[defense]              -1.03966   0.391579    1.77647  -0.823338   1.60384\n",
      "theta_alpha[dca]                 -0.521339  -0.752211   -1.72615  -0.357408  -3.06154\n",
      "theta_alpha[experience]          -0.754825   -0.24886  -0.152083  -0.039285  -0.88067\n",
      "theta_alpha[past_experience]       -0.5271   0.182405    -1.6035  -0.638449  -3.88987\n",
      "theta_alpha[workload]              -0.1493  -0.141814    0.99321  -0.517531  -1.19367\n",
      "theta_alpha[congress_rep]        -0.453628   0.998172  -0.514713  -0.150577    1.1239\n",
      "theta_alpha[num_past_winners]    -0.308018  -0.127386   0.904548  -0.589396    1.0544\n",
      "theta_alpha[num_establishments]   -1.04965   -1.31182  -0.982152  -0.529783   1.69524\n",
      "theta_beta                        0.447582  -0.524782    2.65497    5.92049   1.18627\n",
      "\n",
      "Model-predicted Pr(CP): mean=0.0402, median=0.0145\n",
      "Observed CP share:     0.0378\n",
      "Observed FP share:     0.9622\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Signal Distributions $f_L(s)$\n",
    "\n",
    "**Reference**: Section 5.2\n",
    "\n",
    "**Data** $s_1$ (price modifications, FP only), $s_2$ (duration modifications, all)\n",
    "\n",
    "**Assumption** Zero-inflated distributions:\n",
    "\n",
    "$$s_1 = \\begin{cases}\n",
    "0 & \\text{with prob } \\Phi(x'\\gamma + \\delta \\cdot \\mathbb{1}[s_2>0]) \\\\\n",
    "\\text{Normal}(\\mu, \\sigma^2) & \\text{otherwise}\n",
    "\\end{cases} \\; \\; s_2 = \\begin{cases}\n",
    "0 & \\text{with prob } \\Phi(x'\\gamma) \\\\\n",
    "\\text{Gamma}(\\alpha, \\beta) & \\text{otherwise}\n",
    "\\end{cases}$$\n",
    "\n",
    "- **Step 2a** — $s_1$: Probit($x'\\gamma + \\delta \\cdot \\mathbb{1}[s_2>0]$) + Normal$(\\mu, \\sigma^2)$, FP only. Constraint $\\delta \\leq 0$ (duration changes → more price changes).\n",
    "- **Step 2b** — $s_2$: Probit($x'\\gamma$) + Gamma$(\\alpha, \\beta)$, with 3 CP shift parameters. Constraint: CP probit shift $\\leq 0$ (CP → more duration changes).\n",
    "\n",
    "**Parameters** `pars1` (10×3 = 30), `pars2` (12×3 = 36)\n",
    "\n",
    "**Estimation**: Standard two-part MLE for each of 3 signal categories. No structural content — pure curve-fitting.\n",
    "\n",
    "- $\\pi$ is continuous (probability of high-cost), but the realized cost type $v \\in \\{0, 1\\}$ is binary. Signals are generated conditional on $v$:\n",
    "$f_L(s) = f(s \\mid v\\!=\\!0)$, $f_H(s) = f(s \\mid v\\!=\\!1)$.\n",
    "\n",
    "**Output**: `pars1`, `pars2` → baseline signal distributions used in Steps 3–5.\n",
    "\n",
    "- The likelihood ratio $\\ell(s) = f_L(s)/f_H(s)$ drives the optimal CP payment schedule $q(\\ell)$. Step 2 estimates $f_L$ (baseline from FP contracts); Step 3 adds 9 shift parameters to create $f_H$.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "md12"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-26T04:57:36.474514Z",
     "start_time": "2026-02-26T04:57:36.322538Z"
    }
   },
   "source": [
    "# ═══════════════════════════════════════════════════════════════════\n",
    "# Step 2a: Price Changes s1 (Zero-Inflated Normal, FP only)\n",
    "# ═══════════════════════════════════════════════════════════════════\n",
    "#\n",
    "# For each of 3 price-modification categories, fit a two-part model\n",
    "# to FP contracts:\n",
    "#   Part 1 (probit):  Pr(s1 = 0 | x, 1[s2>0])\n",
    "#   Part 2 (Normal):  s1 | s1 != 0 ~ N(mu, sigma^2)\n",
    "\n",
    "print(\"Step 2a: Estimating s1 distribution (price changes, FP contracts only)...\")\n",
    "\n",
    "def s1_negll(par, X, s, is_zero, is_fp):\n",
    "    \"\"\"\n",
    "    Two-part MLE for s1: probit(zero) + Normal(nonzero), FP contracts only.\n",
    "\n",
    "    par layout: [probit_coefs (8), mu, log_sigma]\n",
    "    \"\"\"\n",
    "    # Unpack: named parameters instead of index arithmetic\n",
    "    probit_coef = par[:X.shape[1]]   # 8 = 7 project + 1 duration indicator\n",
    "    mu          = par[-2]\n",
    "    sigma       = np.exp(par[-1])\n",
    "\n",
    "    # Part 1: probit — probability of zero\n",
    "    pz = np.clip(stats.norm.cdf(X @ probit_coef), ERR, 1 - ERR)\n",
    "\n",
    "    # Part 2: Normal — density of nonzero values\n",
    "    ll = is_fp * (\n",
    "        is_zero * np.log(pz)\n",
    "        + (1 - is_zero) * (np.log(1 - pz) + stats.norm.logpdf(s, mu, sigma))\n",
    "    )\n",
    "    return -np.sum(ll)\n",
    "\n",
    "\n",
    "# ── Estimate for each category ────────────────────────────────────\n",
    "\n",
    "n_s1_params = nproj + 3   # 7 probit + dur_shift + mu + log_sigma = 10\n",
    "pars1 = np.zeros((n_s1_params, 3))\n",
    "is_fp = d  # d=1 means FP\n",
    "\n",
    "for k, (s1_col, s2_col) in enumerate(zip(S1_COLS, S2_COLS)):\n",
    "    s_val   = df[s1_col].values\n",
    "    is_zero = (s_val == 0).astype(float)\n",
    "    dur_ind = (df[s2_col] > 0).astype(float).values\n",
    "\n",
    "    X = np.column_stack([xproj, dur_ind])   # (N, 8) — reuse xproj from cell 4\n",
    "\n",
    "    # Starting values: zeros for probit, sample moments for Normal\n",
    "    nz_mask = (is_fp == 1) & (s_val != 0)\n",
    "    x0 = np.zeros(n_s1_params)\n",
    "    x0[-2] = np.mean(s_val[nz_mask])\n",
    "    x0[-1] = np.log(np.std(s_val[nz_mask]) + 1)\n",
    "\n",
    "    # dur_shift (last probit coef, index 7) <= 0; everything else unbounded\n",
    "    bounds = [(None, None)] * nproj + [(None, 0)] + [(None, None)] * 2\n",
    "\n",
    "    res = optimize.minimize(\n",
    "        s1_negll, x0, args=(X, s_val, is_zero, is_fp),\n",
    "        method='L-BFGS-B', bounds=bounds, options={'maxiter': 5000, 'ftol': 1e-6}\n",
    "    )\n",
    "    pars1[:, k] = res.x\n",
    "    print(f\"  {s1_col}: converged={res.success}, nll={res.fun:.2f}\")\n",
    "\n",
    "# ── Results ──\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"Step 2a Results: s1 Parameters\")\n",
    "print(\"=\" * 70)\n",
    "labels = [f\"probit[{c}]\" for c in ['const'] + PROJ_COLS] + [\"probit[dur_chg]\", \"mu\", \"log_sig\"]\n",
    "rows = [[labels[i]] + [f\"{pars1[i,j]:.4f}\" for j in range(3)] for i in range(n_s1_params)]\n",
    "print(tabulate(rows, headers=[\"Parameter\"] + S1_COLS, tablefmt=\"simple\", numalign=\"right\"))\n"
   ],
   "id": "cd13",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2a: Estimating s1 distribution (price changes, FP contracts only)...\n",
      "  s1_cat1: converged=True, nll=11069.48\n",
      "  s1_cat2: converged=True, nll=13137.72\n",
      "  s1_cat3: converged=True, nll=9175.35\n",
      "\n",
      "======================================================================\n",
      "Step 2a Results: s1 Parameters\n",
      "======================================================================\n",
      "Parameter             s1_cat1    s1_cat2    s1_cat3\n",
      "------------------  ---------  ---------  ---------\n",
      "probit[const]            1.95     2.0819     1.8863\n",
      "probit[dur_gt_3mo]    -0.1278    -0.2846    -0.1685\n",
      "probit[size]          -0.1474    -0.1215    -0.1318\n",
      "probit[service]       -0.3312    -0.5057    -0.4613\n",
      "probit[commercial]    -0.1215    -0.1307    -0.1524\n",
      "probit[defense]       -0.0604     0.1341     0.1671\n",
      "probit[dca]            0.0646     0.0142     0.0823\n",
      "probit[dur_chg]       -1.8572    -3.4072    -1.0891\n",
      "mu                    49227.7     164245   -19285.1\n",
      "log_sig               12.1306    12.4098    11.7653\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-26T04:57:37.421768Z",
     "start_time": "2026-02-26T04:57:36.477146Z"
    }
   },
   "source": [
    "# ═══════════════════════════════════════════════════════════════════\n",
    "# Step 2b: Duration Changes s2 (Zero-Inflated Gamma, all contracts)\n",
    "# ═══════════════════════════════════════════════════════════════════\n",
    "#\n",
    "# Same two-part structure as 2a, but:\n",
    "#   - Gamma instead of Normal for nonzero values\n",
    "#   - Uses both FP and CP contracts\n",
    "#   - CP contracts get 3 shifted parameters (probit, alpha, beta)\n",
    "\n",
    "print(\"Step 2b: Estimating s2 distribution (duration changes, all contracts)...\")\n",
    "\n",
    "def s2_negll(par, X, s, is_zero, is_fp):\n",
    "    \"\"\"\n",
    "    Two-part MLE for s2: probit(zero) + Gamma(nonzero), with CP shifts.\n",
    "\n",
    "    par layout: [probit_coefs (7), log_alpha, log_beta, cp_probit_shift, cp_alpha_shift, cp_beta_shift]\n",
    "    \"\"\"\n",
    "    n_x = X.shape[1]\n",
    "\n",
    "    # Unpack: named parameters\n",
    "    probit_coef   = par[:n_x]           # (7,) probit coefficients\n",
    "    log_alpha     = par[n_x]            # FP Gamma shape\n",
    "    log_beta      = par[n_x + 1]        # FP Gamma scale\n",
    "    cp_pr_shift   = par[n_x + 2]        # CP probit shift (<= 0)\n",
    "    cp_alpha_shift = par[n_x + 3]       # CP Gamma shape shift\n",
    "    cp_beta_shift  = par[n_x + 4]       # CP Gamma scale shift\n",
    "\n",
    "    is_cp = 1 - is_fp\n",
    "\n",
    "    # ── FP component ──\n",
    "    pz_fp = np.clip(stats.norm.cdf(X @ probit_coef), ERR, 1 - ERR)\n",
    "    ll_fp = is_fp * (\n",
    "        is_zero * np.log(pz_fp)\n",
    "        + (1 - is_zero) * (np.log(1 - pz_fp)\n",
    "            + stats.gamma.logpdf(s, a=np.exp(log_alpha), scale=np.exp(log_beta)))\n",
    "    )\n",
    "\n",
    "    # ── CP component (shifted parameters) ──\n",
    "    pz_cp = np.clip(stats.norm.cdf(X @ probit_coef + cp_pr_shift), ERR, 1 - ERR)\n",
    "    ll_cp = is_cp * (\n",
    "        is_zero * np.log(pz_cp)\n",
    "        + (1 - is_zero) * (np.log(1 - pz_cp)\n",
    "            + stats.gamma.logpdf(s, a=np.exp(log_alpha + cp_alpha_shift),\n",
    "                                    scale=np.exp(log_beta + cp_beta_shift)))\n",
    "    )\n",
    "\n",
    "    return -np.sum(ll_fp + ll_cp)\n",
    "\n",
    "\n",
    "# ── Estimate for each category ────────────────────────────────────\n",
    "\n",
    "n_s2_params = nproj + 5   # 7 probit + log_alpha + log_beta + 3 CP shifts = 12\n",
    "pars2 = np.zeros((n_s2_params, 3))\n",
    "is_fp = d\n",
    "\n",
    "for k, s2_col in enumerate(S2_COLS):\n",
    "    s_val   = df[s2_col].values\n",
    "    is_zero = (s_val <= 0).astype(float)\n",
    "    s_safe  = np.where(is_zero, 1.0, s_val)   # replace zeros for Gamma eval\n",
    "\n",
    "    x0 = np.zeros(n_s2_params)\n",
    "\n",
    "    # cp_probit_shift (index nproj+2) <= 0\n",
    "    bounds = [(None, None)] * (nproj + 2) + [(None, 0)] + [(None, None)] * 2\n",
    "\n",
    "    res = optimize.minimize(\n",
    "        s2_negll, x0, args=(xproj, s_safe, is_zero, is_fp),\n",
    "        method='L-BFGS-B', bounds=bounds, options={'maxiter': 5000, 'ftol': 1e-6}\n",
    "    )\n",
    "    pars2[:, k] = res.x\n",
    "    print(f\"  {s2_col}: converged={res.success}, nll={res.fun:.2f}\")\n",
    "\n",
    "# ── Results ──\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"Step 2b Results: s2 Parameters\")\n",
    "print(\"=\" * 70)\n",
    "labels = ([f\"probit[{c}]\" for c in ['const'] + PROJ_COLS]\n",
    "          + [\"log_alpha\", \"log_beta\", \"cp_probit_shift\", \"cp_alpha_shift\", \"cp_beta_shift\"])\n",
    "rows = [[labels[i]] + [f\"{pars2[i,j]:.4f}\" for j in range(3)] for i in range(n_s2_params)]\n",
    "print(tabulate(rows, headers=[\"Parameter\"] + S2_COLS, tablefmt=\"simple\", numalign=\"right\"))\n"
   ],
   "id": "cd14",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2b: Estimating s2 distribution (duration changes, all contracts)...\n",
      "  s2_cat1: converged=True, nll=2902.90\n",
      "  s2_cat2: converged=True, nll=3014.57\n",
      "  s2_cat3: converged=True, nll=3657.30\n",
      "\n",
      "======================================================================\n",
      "Step 2b Results: s2 Parameters\n",
      "======================================================================\n",
      "Parameter             s2_cat1    s2_cat2    s2_cat3\n",
      "------------------  ---------  ---------  ---------\n",
      "probit[const]          1.6497     2.3601     1.3781\n",
      "probit[dur_gt_3mo]    -0.0246    -0.4255    -0.0643\n",
      "probit[size]          -0.2048    -0.3794    -0.0956\n",
      "probit[service]       -0.2106    -0.5962    -0.0059\n",
      "probit[commercial]     -0.067     -0.162      0.041\n",
      "probit[defense]        0.0257    -0.0523    -0.0653\n",
      "probit[dca]             -0.15     -0.208    -0.1204\n",
      "log_alpha              -0.295     0.1275     -0.484\n",
      "log_beta               0.6952     0.5557      1.015\n",
      "cp_probit_shift         -0.21    -0.4803    -0.2611\n",
      "cp_alpha_shift         0.1372     0.0704     0.0249\n",
      "cp_beta_shift         -0.0849    -0.3048    -0.1888\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Cost Parameters (NLS)\n",
    "\n",
    "**Reference**: Section 5.3, Propositions 3–4\n",
    "\n",
    "**Data** Base price $p_i$ (all), ex-post adjustment $q_i$ (CP only), observed $s_{2,i}$\n",
    "**Parameters** 35 total: $\\delta_\\alpha, \\delta_\\beta, \\delta_\\psi$ (7 each), 4 type shifters, 9 signal shifters, 1 payment floor\n",
    "**From previous steps** $f(\\pi \\mid d, x, z)$ (Step 1), $f_L(s), f_H(s)$ (Step 2)\n",
    "\n",
    "**Parametric assumptions** — cost, information rent, and risk aversion are log-linear in project characteristics:\n",
    "$$\\alpha(\\pi,x) = \\exp(x'\\delta_\\alpha + \\delta_{\\alpha\\pi}\\pi + \\delta_{\\alpha\\pi^2}\\pi^2), \\quad \\beta(\\pi,x) = \\exp(x'\\delta_\\beta + \\delta_{\\beta\\pi}\\pi + \\delta_{\\beta\\pi^2}\\pi^2), \\quad \\psi(q; x) = \\exp(x'\\delta_\\psi)\\left\\{1-\\exp \\left[-q/\\exp(x' \\delta_\\psi)\\right] \\right\\}$$\n",
    "\n",
    "---\n",
    "\n",
    "**Key equation 1** (Equation 3.9 — optimal CP payment schedule given CARA utility):\n",
    "\n",
    "$$\\boxed{q(\\ell) = -\\psi \\left[\\ln(1 - \\tilde\\pi) - \\ln\\left(1 - \\tilde\\pi \\cdot \\ell(s)\\right)\\right]}$$\n",
    "\n",
    "- $\\ell(s) = f_L(s)/f_H(s)$ is the **likelihood ratio** — this is where Step 2 feeds in.\n",
    "- $\\tilde\\pi$ is the cutoff type where the low-cost contractor's IR constraint binds (found by root-finding).\n",
    "- When $\\ell(s)$ is low (signal looks like high-cost), $q$ is small → punishment. When $\\ell(s)$ is high (looks like low-cost), $q$ is large → reward.\n",
    "- $\\psi$ controls curvature: higher risk aversion → flatter payment schedule.\n",
    "\n",
    "---\n",
    "\n",
    "**Key equation 2** (Equation 3.10 — FP price under competitive bidding):\n",
    "\n",
    "$$\\boxed{E[p_i \\mid d_i\\!=\\!1] = \\int \\left[\\alpha(\\pi, x) + \\max\\!\\left(\\beta - IR,\\; 0\\right) \\cdot \\frac{\\pi(1-\\pi)^{n-1}}{1-(1-\\pi)^n}\\right] f(\\pi \\mid d\\!=\\!1, x, z)\\, d\\pi}$$\n",
    "\n",
    "- The bracket $[\\cdots]$ is the **expected cost to the winning FP bidder**: base cost $\\alpha$ + information rent $\\times$ competitive markup.\n",
    "- $IR = E_s[\\psi(q(\\ell(s))) \\cdot (1 - \\ell(s))]$ is the **incentive rent** the agency saves by using signals — it shrinks the FP premium.\n",
    "- The markup $\\pi(1-\\pi)^{n-1}/[1-(1-\\pi)^n]$ is the **first-order statistic** of $n$ bidders drawn from type distribution $\\pi$. More bidders → smaller markup.\n",
    "- Integration is over $\\pi$ using Gauss-Legendre (50 nodes); $IR$ itself uses simulated signals (5000 Halton draws).\n",
    "\n",
    "---\n",
    "\n",
    "**Key equation 3** (Equation 3.11 — CP base price is NOT just observed cost):\n",
    "\n",
    "$$\\boxed{E[p_i \\mid d_i\\!=\\!0] = \\int \\left[\\alpha(\\pi, x) + \\beta(\\pi, x) - E_s\\!\\left[\\psi(q(\\ell(s)))\\right]\\right] f(\\pi \\mid d\\!=\\!0, x, z)\\, d\\pi}$$\n",
    "\n",
    "- CP price = base cost $\\alpha$ + high-cost premium $\\beta$ − **expected savings** from the incentive payment scheme.\n",
    "- The $-E[\\psi(q)]$ term is key: the agency designs the signal-based payment $q(\\ell)$ to reduce the total cost below $\\alpha + \\beta$.\n",
    "\n",
    "---\n",
    "\n",
    "**Key equation 4** (Section 5.2.3 — CP ex-post adjustment conditions on **observed** $s_2$):\n",
    "\n",
    "$$\\boxed{E[q_i \\mid d_i\\!=\\!0, s_{2,i}^{\\text{obs}}] = \\int \\left[\\int q(\\ell(s_1, s_{2}^{\\text{obs}})) \\, f_H(s_1 \\mid s_2^{\\text{obs}})\\, ds_1\\right] f(\\pi \\mid d\\!=\\!0, x, z)\\, d\\pi}$$\n",
    "\n",
    "- Only $s_1$ (price modifications) is simulated; $s_2$ (duration changes) is **observed** — so each CP observation $i$ produces a different moment.\n",
    "- The inner integral draws $s_1$ from $f_H$ because the agency designs the contract assuming the contractor is high-cost (incentive-compatible).\n",
    "- This gives 264 observation-specific moments (one per CP contract), pinning down the payment schedule shape.\n",
    "\n",
    "---\n",
    "\n",
    "**Estimation**: NLS (not MLE — we only match conditional means, not full distributions):\n",
    "$$\\min_\\theta \\sum_{d_i=1} (p_i - \\hat{E}[p_i])^2 + \\sum_{d_i=0} (p_i - \\hat{E}[p_i])^2 + \\sum_{d_i=0} (q_i - \\hat{E}[q_i])^2$$\n",
    "\n",
    "**Computation**: Each NLS evaluation requires $50 \\times 5000$ nested integration (quadrature × Halton draws) per project-type case, plus root-finding for $\\tilde\\pi$ at every $\\pi$ node.\n"
   ],
   "id": "md15"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-26T04:57:37.879801Z",
     "start_time": "2026-02-26T04:57:37.471144Z"
    }
   },
   "source": [
    "# ═══════════════════════════════════════════════════════════════════\n# Step 3: Setup\n# ═══════════════════════════════════════════════════════════════════\n\n# Map each observation to its project-type case (for efficiency: simulate once per case)\nxcase_map = np.zeros(nsim, dtype=int)\nfor i in range(nsim):\n    for j in range(ncase):\n        if np.array_equal(xproj[i], xproj_case[j]):\n            xcase_map[i] = j\n            break\n\nprint(f\"Step 3 setup: {nsim:,} obs mapped to {ncase} project-type cases\")\nprint(f\"Halton draws: {sngrid} x 6 ready for signal simulation\")\n"
   ],
   "id": "cd16",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3 setup: 6,981 obs mapped to 62 project-type cases\n",
      "Halton draws: 5000 x 6 ready for signal simulation\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-26T04:57:37.962073Z",
     "start_time": "2026-02-26T04:57:37.899540Z"
    }
   },
   "source": [
    "# ═══════════════════════════════════════════════════════════════════\n# Step 3: NLS Objective Function\n# ═══════════════════════════════════════════════════════════════════\n#\n# Structure:\n#   (A) unpack_params:        35-vector → named dict\n#   (B) build_signal_dists:   Step 2 params + shifts → low/high-cost signal params\n#   (C) simulate_draw_density: Halton draws → f(s|type) for one case\n#   (D) solve_optimal_payments: likelihood ratios → q(l), FP premium, CP base price\n#   (E) fun_nls:              orchestrate everything, compute NLS residuals\n\n\ndef unpack_params(par_cost, n_x):\n    \"\"\"Split 35-parameter vector into named groups.\"\"\"\n    k = n_x  # = 7\n    return {\n        'd_alpha': par_cost[0:k],      'd_beta': par_cost[k:2*k],\n        'd_psi':   par_cost[2*k:3*k],\n        'pi_a':    par_cost[3*k:3*k+2],   'pi_b':  par_cost[3*k+2:3*k+4],\n        's1_pr':   par_cost[3*k+4:3*k+7], 's1_mu': par_cost[3*k+7:3*k+10],\n        's1_sd':   par_cost[3*k+10:3*k+13],\n        'min_q':  -np.exp(par_cost[3*k+13]),\n    }\n\n\ndef build_signal_dists(pars1, pars2, xpc, par, n_x):\n    \"\"\"\n    Build low-cost and high-cost signal distribution parameters\n    for each project-type case.\n\n    Returns dict with arrays of shape (ncase, 3).\n    \"\"\"\n    # s1: price modifications (zero-inflated Normal)\n    xg = xpc @ pars1[:n_x, :]                           # (ncase, 3) probit linear predictor\n    dur_shift = pars1[n_x, :]                            # duration indicator shift\n\n    s = {}\n    s['pz_l_10'] = stats.norm.cdf(xg)                   # Pr(s1=0 | low, s2=0)\n    s['pz_l_11'] = stats.norm.cdf(xg + dur_shift)       # Pr(s1=0 | low, s2>0)\n    s['pz_h_10'] = stats.norm.cdf(xg + par['s1_pr'])    # Pr(s1=0 | high, s2=0)\n    s['pz_h_11'] = stats.norm.cdf(xg + dur_shift + par['s1_pr'])\n\n    s['s1_mu_l']  = pars1[n_x+1, :]                     # E[s1 | low,  s1≠0]\n    s['s1_sd_l']  = np.exp(pars1[n_x+2, :])             # SD[s1 | low,  s1≠0]\n    s['s1_mu_h']  = pars1[n_x+1, :] + par['s1_mu']      # E[s1 | high, s1≠0]\n    s['s1_sd_h']  = np.exp(pars1[n_x+2, :] + par['s1_sd'])\n\n    # s2: duration modifications (zero-inflated Gamma)\n    xg2 = xpc @ pars2[:n_x, :]\n    s['pz2_l'] = stats.norm.cdf(xg2)                    # Pr(s2=0 | low)\n    s['pz2_h'] = stats.norm.cdf(xg2 + pars2[n_x+2, :]) # Pr(s2=0 | high)\n    s['s2_a_l'] = np.exp(pars2[n_x, :])                 # Gamma α | low\n    s['s2_b_l'] = np.exp(pars2[n_x+1, :])               # Gamma β | low\n    s['s2_a_h'] = np.exp(pars2[n_x, :] + pars2[n_x+3, :])   # Gamma α | high\n    s['s2_b_h'] = np.exp(pars2[n_x+1, :] + pars2[n_x+4, :]) # Gamma β | high\n    return s\n\n\ndef zi_normal_density(u, pz, mu, sigma):\n    \"\"\"Zero-inflated Normal: f(s) at Halton draw u, for one category.\n    Returns (f_val, is_zero) arrays of shape (sngrid,).\"\"\"\n    is_zero = u <= pz\n    f_val = np.where(is_zero, pz, 0.0)\n    pos = ~is_zero\n    if np.any(pos):\n        uc = np.clip((u[pos] - pz) / max(1 - pz, ERR), ERR, 1-ERR)\n        sd = stats.norm.ppf(uc, mu, sigma)\n        f_val[pos] = (1 - pz) * stats.norm.pdf(sd, mu, sigma)\n    return f_val, is_zero\n\n\ndef zi_gamma_density(u, pz, alpha, beta_scale):\n    \"\"\"Zero-inflated Gamma: f(s) at Halton draw u, for one category.\"\"\"\n    is_zero = u <= pz\n    f_val = np.where(is_zero, pz, 0.0)\n    pos = ~is_zero\n    if np.any(pos):\n        uc = np.clip((u[pos] - pz) / max(1 - pz, ERR), ERR, 1-ERR)\n        sd = stats.gamma.ppf(uc, alpha, scale=beta_scale)\n        f_val[pos] = (1 - pz) * stats.gamma.pdf(sd, alpha, scale=beta_scale)\n    return f_val, is_zero\n\n\ndef compute_lr(smat_draws, s, ci, sngrid):\n    \"\"\"\n    Compute likelihood ratios l(s) = f(s|low)/f(s|high) for one project-type case.\n\n    Draws signals from f(s|high) via inverse-CDF, then evaluates both f(s|low) and f(s|high).\n    \"\"\"\n    fl = np.ones((sngrid, 6))\n    fh = np.ones((sngrid, 6))\n\n    # s2 draws (cols 3-5): draw from HIGH-cost, evaluate both\n    s2_zero = np.zeros((sngrid, 3), dtype=bool)\n    for k in range(3):\n        u = smat_draws[:, k+3]\n        # Draw from high-cost distribution\n        fh[:, k+3], s2_zero[:, k] = zi_gamma_density(\n            u, s['pz2_h'][ci, k], s['s2_a_h'][k], s['s2_b_h'][k])\n        # Evaluate low-cost density at same draw points\n        # For zeros: just use low-cost zero probability\n        # For positives: evaluate low-cost Gamma at draws from high-cost inverse-CDF\n        pos = ~s2_zero[:, k]\n        fl[s2_zero[:, k], k+3] = s['pz2_l'][ci, k]\n        if np.any(pos):\n            uc = np.clip((u[pos] - s['pz2_h'][ci,k]) / max(1-s['pz2_h'][ci,k], ERR), ERR, 1-ERR)\n            sd = stats.gamma.ppf(uc, s['s2_a_h'][k], scale=s['s2_b_h'][k])\n            fl[pos, k+3] = (1 - s['pz2_l'][ci,k]) * stats.gamma.pdf(\n                sd, s['s2_a_l'][k], scale=s['s2_b_l'][k])\n\n    # s1 draws (cols 0-2): conditioned on whether s2 is zero\n    for k in range(3):\n        u = smat_draws[:, k]\n        # s1 zero probability depends on s2 status\n        pz_h = np.where(s2_zero[:, k], s['pz_h_10'][ci, k], s['pz_h_11'][ci, k])\n        pz_l = np.where(s2_zero[:, k], s['pz_l_10'][ci, k], s['pz_l_11'][ci, k])\n\n        is_zero = u <= pz_h\n        pos = ~is_zero\n\n        fh[is_zero, k] = pz_h[is_zero]\n        fl[is_zero, k] = pz_l[is_zero]\n        if np.any(pos):\n            uc = np.clip((u[pos] - pz_h[pos]) / np.maximum(1 - pz_h[pos], ERR), ERR, 1-ERR)\n            sd = stats.norm.ppf(uc, s['s1_mu_h'][k], s['s1_sd_h'][k])\n            fh[pos, k] = (1 - pz_h[pos]) * stats.norm.pdf(sd, s['s1_mu_h'][k], s['s1_sd_h'][k])\n            fl[pos, k] = (1 - pz_l[pos]) * stats.norm.pdf(sd, s['s1_mu_l'][k], s['s1_sd_l'][k])\n\n    return np.prod(fl, axis=1) / np.maximum(np.prod(fh, axis=1), ERR)\n\n\ndef solve_prices(pivec, pngrid, par, xpc_row, lvec, sngrid):\n    \"\"\"\n    For one project-type case, solve for FP premium and CP base price at each pi node.\n\n    Returns: fp_premium (pngrid,), cp_base (pngrid,), pi_tilde (pngrid,)\n    \"\"\"\n    alpha_base = np.exp(xpc_row @ par['d_alpha'])\n    beta_base  = np.exp(xpc_row @ par['d_beta'])\n    psi        = np.exp(xpc_row @ par['d_psi'])\n    mq         = par['min_q']\n\n    fp_prem  = np.zeros(pngrid)\n    cp_base  = np.zeros(pngrid)\n    pi_tilde = np.zeros(pngrid)\n\n    def q_payment(piq, lv):\n        \"\"\"Optimal payment q(l) given pi_tilde cutoff.\"\"\"\n        ll_cutoff = min(1/max(piq, ERR) - (1-piq)/(max(piq, ERR)*np.exp(-mq/psi)), np.exp(MV))\n        ok = lv <= ll_cutoff\n        qv = np.full_like(lv, mq)\n        qv[ok] = -psi * (np.log(1-piq) - np.log(np.maximum(1 - piq*lv[ok], ERR)))\n        return qv\n\n    def psi_transform(qv):\n        \"\"\"ψ(q) = -ψ·exp(-q/ψ) + ψ  (CARA utility transform).\"\"\"\n        return -psi * np.exp(np.minimum(-qv/psi, MV)) + psi\n\n    for j in range(pngrid):\n        pi = pivec[j]\n        alp = alpha_base * np.exp(par['pi_a'][0]*pi + par['pi_a'][1]*pi**2)\n        bet = beta_base  * np.exp(par['pi_b'][0]*pi + par['pi_b'][1]*pi**2)\n\n        # Find pi_tilde: where low-cost contractor's IR binds\n        def ir_gap(x):\n            return bet - np.mean(psi_transform(q_payment(x, lvec)) * (1 - lvec))\n\n        if ir_gap(pimax) >= 0:\n            pi_tilde[j] = pimax\n        else:\n            try:\n                pi_tilde[j] = optimize.brentq(ir_gap, 1e-10, pimax)\n            except:\n                pi_tilde[j] = pimax\n\n        # Compute optimal payment and integrals\n        piq = min(pi, pi_tilde[j])\n        qv = q_payment(piq, lvec)\n        psi_qv = psi_transform(qv)\n\n        ir_val = np.mean(psi_qv * (1 - lvec))\n        if bet - ir_val < -1:  # IR doesn't hold → degenerate contract\n            qv[:] = 0\n            ir_val = bet\n\n        fp_prem[j] = bet - ir_val\n        cp_base[j] = alp + bet - np.mean(psi_qv)\n\n    return fp_prem, cp_base, pi_tilde\n\n\ndef expected_s1_diff(s, ci):\n    \"\"\"E[s1|high] - E[s1|low] for each of 3 categories.\"\"\"\n    diff = np.zeros(3)\n    for k in range(3):\n        eh = s['s1_mu_h'][k] * (s['pz2_h'][ci,k]*(1-s['pz_h_10'][ci,k])\n             + (1-s['pz2_h'][ci,k])*(1-s['pz_h_11'][ci,k]))\n        el = s['s1_mu_l'][k] * (s['pz2_l'][ci,k]*(1-s['pz_l_10'][ci,k])\n             + (1-s['pz2_l'][ci,k])*(1-s['pz_l_11'][ci,k]))\n        diff[k] = eh - el\n    return diff\n\n\ndef fun_nls(par_cost, pars1, pars2, sngrid, pngrid, pimin, pimax,\n            fpi, nbids, d, p, q, s2, xproj, xproj_case, xcase_map,\n            pivec, piweight, smat):\n    \"\"\"\n    NLS objective: squared residuals between observed (p, q) and model-predicted E[p], E[q].\n    \"\"\"\n    n_x  = xproj.shape[1]\n    nobs = len(d)\n    nc   = xproj_case.shape[0]\n    par  = unpack_params(par_cost, n_x)\n    s    = build_signal_dists(pars1, pars2, xproj_case, par, n_x)\n\n    # ── Pre-compute per case: signal simulation → prices ──\n    fp_prem = np.zeros((nc, pngrid))\n    cp_base = np.zeros((nc, pngrid))\n    pi_til  = np.zeros((nc, pngrid))\n    s1_diff = np.zeros((nc, 3))\n\n    for ci in range(nc):\n        lr = compute_lr(smat, s, ci, sngrid)\n        fp_prem[ci], cp_base[ci], pi_til[ci] = solve_prices(\n            pivec, pngrid, par, xproj_case[ci], lr, sngrid)\n        s1_diff[ci] = expected_s1_diff(s, ci)\n\n    # ── Build predicted prices per observation ──\n    pred_fp = np.zeros((nobs, pngrid))\n    pred_cp = np.zeros((nobs, pngrid))\n    pred_q  = np.zeros((nobs, pngrid))\n\n    for i in range(nobs):\n        ci = xcase_map[i]\n\n        if d[i] == 1:\n            # FP: base cost + max(premium, 0) × competitive markup\n            alp = (np.exp(xproj_case[ci] @ par['d_alpha'])\n                   * np.exp(par['pi_a'][0]*pivec + par['pi_a'][1]*pivec**2))\n            markup = pivec * (1-pivec)**(nbids[i]-1) / np.maximum(1-(1-pivec)**nbids[i], ERR)\n            pred_fp[i] = alp + np.maximum(fp_prem[ci], 0) * markup\n        else:\n            # CP base price\n            pred_cp[i] = cp_base[ci]\n\n            # CP ex-post: simulate l(s1, s2_observed) using OBSERVED s2\n            psi = np.exp(xproj_case[ci] @ par['d_psi'])\n            mq  = par['min_q']\n\n            # Evaluate f(s2_observed | type) for each category\n            fh2 = np.zeros(3)\n            fl2 = np.zeros(3)\n            pz_h1_obs = np.zeros(3)\n            pz_l1_obs = np.zeros(3)\n            for k in range(3):\n                sv = s2[i, k]\n                if sv <= 0:\n                    fh2[k] = s['pz2_h'][ci, k]\n                    fl2[k] = s['pz2_l'][ci, k]\n                    pz_h1_obs[k] = s['pz_h_10'][ci, k]\n                    pz_l1_obs[k] = s['pz_l_10'][ci, k]\n                else:\n                    fh2[k] = (1-s['pz2_h'][ci,k]) * stats.gamma.pdf(\n                        max(sv, ERR), s['s2_a_h'][k], scale=s['s2_b_h'][k])\n                    fl2[k] = (1-s['pz2_l'][ci,k]) * stats.gamma.pdf(\n                        max(sv, ERR), s['s2_a_l'][k], scale=s['s2_b_l'][k])\n                    pz_h1_obs[k] = s['pz_h_11'][ci, k]\n                    pz_l1_obs[k] = s['pz_l_11'][ci, k]\n\n            # Simulate s1 | s2_observed → compute l(s1, s2_obs)\n            fh1 = np.ones((sngrid, 3))\n            fl1 = np.ones((sngrid, 3))\n            for k in range(3):\n                u = smat[:, k]\n                pzh = pz_h1_obs[k]\n                is_zero = u <= pzh\n                pos = ~is_zero\n\n                fh1[is_zero, k] = pzh\n                fl1[is_zero, k] = pz_l1_obs[k]\n                if np.any(pos):\n                    uc = np.clip((u[pos]-pzh)/max(1-pzh, ERR), ERR, 1-ERR)\n                    sd = stats.norm.ppf(uc, s['s1_mu_h'][k], s['s1_sd_h'][k])\n                    fh1[pos, k] = (1-pzh) * stats.norm.pdf(sd, s['s1_mu_h'][k], s['s1_sd_h'][k])\n                    fl1[pos, k] = (1-pz_l1_obs[k]) * stats.norm.pdf(sd, s['s1_mu_l'][k], s['s1_sd_l'][k])\n\n            lr_obs = (np.prod(fl1, axis=1) * np.prod(fl2)) / np.maximum(\n                      np.prod(fh1, axis=1) * np.prod(fh2), ERR)\n\n            # E[q | s2_obs] at each pi node\n            for j in range(pngrid):\n                piq = min(pivec[j], pi_til[ci, j])\n                ll_cut = min(1/max(piq,ERR)-(1-piq)/(max(piq,ERR)*np.exp(-mq/psi)), np.exp(MV))\n                ok = lr_obs <= ll_cut\n                qv = np.full(sngrid, mq)\n                qv[ok] = -psi*(np.log(1-piq) - np.log(np.maximum(1-piq*lr_obs[ok], ERR)))\n                pred_q[i, j] = np.mean(qv)\n            pred_q[i] *= (fp_prem[ci] >= -1)\n\n            # Add E[s1 | s2_obs]\n            for k in range(3):\n                pred_q[i] += (1 - pz_h1_obs[k]) * s['s1_mu_h'][k]\n\n    # ── NLS residuals: weighted sum of squared prediction errors ──\n    e_fp = d     * (p - (pred_fp * fpi * piweight[None, :]).sum(axis=1))**2\n    e_cp = (1-d) * (p - (pred_cp * fpi * piweight[None, :]).sum(axis=1))**2\n    e_q  = (1-d) * (q - (pred_q  * fpi * piweight[None, :]).sum(axis=1))**2\n\n    return (e_fp + e_cp + e_q).sum() / 1e12\n\n\nprint(\"Step 3 NLS function defined.\")\n"
   ],
   "id": "cd17",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3 NLS function defined.\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-26T04:57:18.235606Z",
     "start_time": "2026-02-26T03:49:13.899404Z"
    }
   },
   "source": [
    "# ── Step 3: Run NLS estimation ─────────────────────────────────────\n# Starting from MATLAB's pre-computed solution (full optimization\n# from scratch requires KNITRO and hours of computation).\n\npar_cost_init = np.array([\n    11.2856666300, 0.0167878940, 0.8283690600, -0.0686414670,\n    -0.0446272820, -0.0126319760, 0.0280515480,\n    12.2090052600, -0.1844087290, 1.8809979820, -1.7882668470,\n     1.0801630690, 0.3692475600, -0.0001967690,\n    20.6265890100, -0.2961157860, 1.0448682360, -0.3355864960,\n    -1.0416946190, -0.0947175070, 2.7815169130,\n     2.5016826130, -1.5237617580, 2.3871278180, -7.8791111100,\n     1.1452635540, -1.3180507120, -0.0441118570,\n    -0.0059153980, -0.0050380370, 0.0017811280,\n     6.9057462150, -12.3810570100, -0.0107126760, 13.61492438\n])\n\nprint(\"Step 3: NLS estimation of cost parameters\")\nprint(f\"  {len(par_cost_init)} parameters, starting from MATLAB pre-computed values\")\n\n# Evaluate at starting values\nobj0 = fun_nls(par_cost_init, pars1, pars2, sngrid, pngrid, pimin, pimax,\n               fpi, b, d, p, q, s2, xproj, xproj_case, xcase_map, pivec, piweight, smat)\nprint(f\"  NLS objective at start: {obj0:.8f}\")\n\n# Refine (limited iterations — full convergence takes hours)\ntry:\n    res = optimize.minimize(\n        fun_nls, par_cost_init, method='L-BFGS-B',\n        args=(pars1, pars2, sngrid, pngrid, pimin, pimax, fpi, b, d, p, q, s2,\n              xproj, xproj_case, xcase_map, pivec, piweight, smat),\n        options={'maxiter': 50, 'ftol': 1e-6}\n    )\n    par_cost = res.x\n    print(f\"  NLS objective after opt: {res.fun:.8f}  (converged={res.success}, iter={res.nit})\")\nexcept Exception as e:\n    print(f\"  Optimization issue: {e} — using starting values\")\n    par_cost = par_cost_init\n\nprint(\"Step 3 complete.\")\n"
   ],
   "id": "cd18",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3: NLS estimation of cost parameters\n",
      "  35 parameters, starting from MATLAB pre-computed values\n",
      "  NLS objective at start: 134.33129896\n",
      "  NLS objective after opt: 134.28405344  (converged=True, iter=6)\n",
      "Step 3 complete.\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-26T04:57:18.486198Z",
     "start_time": "2026-02-26T04:57:18.286654Z"
    }
   },
   "source": [
    "# ── Step 3 Results ─────────────────────────────────────────────────\n",
    "print(\"=\" * 70)\n",
    "print(\"Step 3 Results: Cost Parameters\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "par_groups = [\n",
    "    (\"delta_alpha (base cost)\",      0,  6),\n",
    "    (\"delta_beta (cost premium)\",    7, 13),\n",
    "    (\"delta_psi (risk aversion)\",   14, 20),\n",
    "    (\"pi_alpha shifters\",           21, 22),\n",
    "    (\"pi_beta shifters\",            23, 24),\n",
    "    (\"s1 prob shifts\",              25, 27),\n",
    "    (\"s1 mean shifts\",              28, 30),\n",
    "    (\"s1 log-sd shifts\",            31, 33),\n",
    "    (\"payment floor (-exp(.))\",     34, 34),\n",
    "]\n",
    "\n",
    "rows = []\n",
    "for label, start, end in par_groups:\n",
    "    for i in range(start, end + 1):\n",
    "        rows.append([label if i == start else \"\", f\"par[{i}]\", f\"{par_cost[i]:.8f}\"])\n",
    "print(tabulate(rows, headers=[\"Group\", \"Index\", \"Value\"], tablefmt=\"simple\", numalign=\"right\"))\n"
   ],
   "id": "cd19",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Step 3 Results: Cost Parameters\n",
      "======================================================================\n",
      "Group                      Index          Value\n",
      "-------------------------  -------  -----------\n",
      "delta_alpha (base cost)    par[0]        11.285\n",
      "                           par[1]      0.015636\n",
      "                           par[2]       0.82771\n",
      "                           par[3]    -0.0693124\n",
      "                           par[4]    -0.0440683\n",
      "                           par[5]    -0.0120662\n",
      "                           par[6]     0.0276147\n",
      "delta_beta (cost premium)  par[7]       12.2083\n",
      "                           par[8]     -0.185185\n",
      "                           par[9]       1.88027\n",
      "                           par[10]     -1.78828\n",
      "                           par[11]      1.08011\n",
      "                           par[12]     0.369214\n",
      "                           par[13]  -0.00018672\n",
      "delta_psi (risk aversion)  par[14]      20.6266\n",
      "                           par[15]    -0.296116\n",
      "                           par[16]      1.04487\n",
      "                           par[17]    -0.335586\n",
      "                           par[18]     -1.04169\n",
      "                           par[19]   -0.0947175\n",
      "                           par[20]      2.78152\n",
      "pi_alpha shifters          par[21]      2.50123\n",
      "                           par[22]     -1.52408\n",
      "pi_beta shifters           par[23]      2.38697\n",
      "                           par[24]     -7.87916\n",
      "s1 prob shifts             par[25]      1.14538\n",
      "                           par[26]     -1.31801\n",
      "                           par[27]   -0.0441263\n",
      "s1 mean shifts             par[28]   -0.0059154\n",
      "                           par[29]  -0.00503804\n",
      "                           par[30]   0.00178113\n",
      "s1 log-sd shifts           par[31]      6.90575\n",
      "                           par[32]     -12.3811\n",
      "                           par[33]   -0.0107132\n",
      "payment floor (-exp(.))    par[34]       13.615\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Search Costs $\\kappa$\n",
    "\n",
    "**Reference**: Section 5.4, Equation (5)\n",
    "\n",
    "**Data** No new data — uses Steps 1–3 outputs only\n",
    "**Parameters** None estimated — $\\kappa$ is computed in **closed form** from the entry equilibrium condition.\n",
    "\n",
    "---\n",
    "\n",
    "**Where does $\\kappa$ come from?** The paper models contractor entry as a **Poisson game** (Section 3.3). The buyer pays a per-bidder evaluation cost $\\kappa$ to screen each entrant. From the contractor's perspective, the zero-profit entry condition pins down $\\kappa$: the expected surplus from entering equals the buyer's per-bidder cost:\n",
    "\n",
    "$$\\boxed{\\kappa(\\pi, x, z) = \\pi \\cdot e^{-\\pi \\lambda} \\cdot \\left[\\beta(\\pi, x) + \\gamma(\\pi, x)\\right]}$$\n",
    "\n",
    "- $\\pi \\cdot e^{-\\pi\\lambda}$ = probability of **winning** the contract (Poisson: you need to be the lowest type among a random number of entrants).\n",
    "- $\\beta + \\gamma$ = **total surplus** conditional on winning — the informational rent $\\beta$ (from knowing your type) plus the risk compensation $\\gamma$ (from bearing cost uncertainty).\n",
    "- In equilibrium, $\\kappa = \\Pr(\\text{win}) \\times \\text{surplus if win}$. This is the **zero-profit condition** for entry.\n",
    "- $\\lambda$ = expected number of rival bidders. Since entry is Poisson, each bidder faces $e^{-\\pi\\lambda}$ probability of winning given type $\\pi$.\n",
    "\n",
    "---\n",
    "\n",
    "**Sub-computation 1**: $\\lambda(\\pi, x, z)$ — expected rivals\n",
    "\n",
    "$$\\boxed{\\lambda_i(\\pi) = \\frac{\\sum_{j: (x_j,z_j)=(x_i,z_i)} (b_j - 1) \\cdot f(\\pi \\mid d_j, x_j, z_j)}{\\sum_{j: (x_j,z_j)=(x_i,z_i)} f(\\pi \\mid d_j, x_j, z_j)}}$$\n",
    "\n",
    "- For each $(x,z)$ group, this is a **posterior-weighted average** of observed rival count $(b-1)$.\n",
    "- Uses the full posterior $f(\\pi \\mid d, x, z)$ from Step 1 as weights, so $\\lambda$ varies with $\\pi$.\n",
    "- Intuitively: in markets where we observe many bidders, $\\lambda$ is high → entry is more competitive.\n",
    "\n",
    "---\n",
    "\n",
    "**Sub-computation 2**: $\\beta(\\pi,x) + \\gamma(\\pi,x)$ — contractor surplus\n",
    "\n",
    "$$\\boxed{\\beta + \\gamma = \\beta + (1-\\pi)\\underbrace{\\int [q(\\ell) - \\psi(q(\\ell))] f_H(s)\\, ds}_{\\text{risk compensation }\\gamma_1} - \\pi\\underbrace{\\int \\psi(q(\\ell))(1-\\ell(s)) f_H(s)\\, ds}_{\\text{incentive rent used}} + (1-\\pi)\\underbrace{\\sum_k E[s_{1k} \\mid H] - E[s_{1k} \\mid L]}_{\\text{signal cost difference}}}$$\n",
    "\n",
    "- This uses the **same signal simulation** and **same $q(\\ell)$ payment schedule** as Step 3 — the code reuses `compute_lr()` and the root-finding for $\\tilde\\pi$.\n",
    "- $q - \\psi(q)$ is the **certainty equivalent gap**: the contractor is risk-averse, so receiving risky payment $q$ is worth less than its expected value.\n",
    "- The final term accounts for the fact that high-cost contractors have different expected signal outcomes.\n",
    "\n",
    "---\n",
    "\n",
    "**Output**: `lambda_mat`, `bgamma`, `kappa` — all shape $(N, 50)$. Used in Step 5 to compute the **expected surplus from competing**, which determines the entry threshold $\\eta$.\n"
   ],
   "id": "md20"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-26T04:57:18.641714Z",
     "start_time": "2026-02-26T04:57:18.504593Z"
    }
   },
   "source": [
    "# ═══════════════════════════════════════════════════════════════════\n# Step 4: Buyer Search Costs (kappa)\n# ═══════════════════════════════════════════════════════════════════\n\nprint(\"Step 4: Computing buyer search costs...\")\n\n# ── 4-1: Lambda — expected number of rival bidders ────────────────\n#\n# For each (x,z) group, lambda(pi) = weighted avg of (b-1) using f(pi|x,z) as weights.\n\n# Group observations by (x,z) signature\nxz_groups = {}\nfor i in range(nsim):\n    key = tuple(xzvec[i])\n    xz_groups.setdefault(key, []).append(i)\n\nlambda_mat = np.zeros((nsim, pngrid))\nfor key, idx in xz_groups.items():\n    idx = np.array(idx)\n    fpi_sum   = np.maximum(fpi[idx].sum(axis=0), ERR)         # (K,)\n    b_fpi_sum = ((b[idx] - 1)[:, None] * fpi[idx]).sum(axis=0)  # (K,)\n    lambda_mat[idx] = b_fpi_sum / fpi_sum\n\nprint(f\"  lambda: mean={np.mean(lambda_mat):.4f}, max={np.max(lambda_mat):.4f}\")\n"
   ],
   "id": "cd21",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4: Computing buyer search costs...\n",
      "  lambda: mean=1.2849, max=27.0000\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-26T04:57:20.945718Z",
     "start_time": "2026-02-26T04:57:18.649671Z"
    }
   },
   "source": [
    "# ── 4-2: Beta + Gamma (contractor surplus) ────────────────────────\n",
    "#\n",
    "# Reuses compute_lr() and solve_prices() from Step 3.\n",
    "# The only new thing: bgamma = beta + (1-pi)*int1 - pi*int2 + (1-pi)*diff_s1\n",
    "\n",
    "print(\"  Computing beta+gamma (reusing Step 3 signal simulation)...\")\n",
    "print(\"  (This may take several minutes)\")\n",
    "\n",
    "par  = unpack_params(par_cost, nproj)\n",
    "sig  = build_signal_dists(pars1, pars2, xproj_case, par, nproj)\n",
    "\n",
    "beta_case = np.exp(xproj_case @ par['d_beta'])\n",
    "psi_case  = np.exp(xproj_case @ par['d_psi'])\n",
    "\n",
    "bgamma_case = np.zeros((ncase, pngrid))   # per case\n",
    "s1_diff_case = np.zeros((ncase, 3))\n",
    "\n",
    "for ci in range(ncase):\n",
    "    lr = compute_lr(smat, sig, ci, sngrid)\n",
    "    s1_diff_case[ci] = expected_s1_diff(sig, ci)\n",
    "    psi_v = psi_case[ci]\n",
    "    mq = par['min_q']\n",
    "\n",
    "    for j in range(pngrid):\n",
    "        pi = pivec[j]\n",
    "        bet = beta_case[ci] * np.exp(par['pi_b'][0]*pi + par['pi_b'][1]*pi**2)\n",
    "\n",
    "        # Find pi_tilde (same logic as solve_prices)\n",
    "        def q_pay(piq):\n",
    "            ll_cut = min(1/max(piq,ERR) - (1-piq)/(max(piq,ERR)*np.exp(-mq/psi_v)), np.exp(MV))\n",
    "            ok = lr <= ll_cut\n",
    "            qv = np.full(sngrid, mq)\n",
    "            qv[ok] = -psi_v * (np.log(1-piq) - np.log(np.maximum(1-piq*lr[ok], ERR)))\n",
    "            return qv\n",
    "\n",
    "        def psi_t(qv):\n",
    "            return -psi_v * np.exp(np.minimum(-qv/psi_v, MV)) + psi_v\n",
    "\n",
    "        def ir_gap(x):\n",
    "            return bet - np.mean(psi_t(q_pay(x)) * (1 - lr))\n",
    "\n",
    "        if ir_gap(pimax) >= 0:\n",
    "            pi_til = pimax\n",
    "        else:\n",
    "            try:\n",
    "                pi_til = optimize.brentq(ir_gap, 1e-10, pimax, xtol=1e-8)\n",
    "            except ValueError:\n",
    "                pi_til = pimax  # fallback when IR doesn't change sign\n",
    "\n",
    "        piq = min(pi, pi_til)\n",
    "        qv = q_pay(piq)\n",
    "        psi_qv = psi_t(qv)\n",
    "        int0 = np.mean(psi_qv * (1 - lr))   # int(psi(q)(1-l) fH ds)\n",
    "\n",
    "        if bet - int0 < -1:\n",
    "            qv[:] = 0\n",
    "            int0 = bet\n",
    "\n",
    "        int1 = np.mean(qv - psi_t(qv))      # int((q - psi(q)) fH ds)\n",
    "        bgamma_case[ci, j] = bet + (1-pi)*int1 - pi*int0 + (1-pi)*s1_diff_case[ci].sum()\n",
    "\n",
    "# Map cases → observations\n",
    "bgamma = bgamma_case[xcase_map]   # (nsim, pngrid) via fancy indexing\n",
    "\n",
    "print(f\"  bgamma: shape={bgamma.shape}, mean={np.mean(bgamma):.2f}\")\n"
   ],
   "id": "cd22",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Computing beta+gamma (reusing Step 3 signal simulation)...\n",
      "  (This may take several minutes)\n",
      "  bgamma: shape=(6981, 50), mean=693028.59\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-26T04:57:21.105125Z",
     "start_time": "2026-02-26T04:57:20.990996Z"
    }
   },
   "source": [
    "# ── 4-3: Kappa = pi * exp(-pi*lambda) * (beta + gamma) ────────────\n\npi_mat = pivec[None, :]   # (1, K) — broadcasts to (N, K)\nkappa = pi_mat * np.exp(-pi_mat * lambda_mat) * bgamma\n\n# Summary (integrate over pi)\nmean_kappa  = np.mean((kappa * fpi * piweight[None, :]).sum(axis=1))\nmean_lambda = np.mean((lambda_mat * fpi * piweight[None, :]).sum(axis=1))\nmean_bgamma = np.mean((bgamma * fpi * piweight[None, :]).sum(axis=1))\n\nprint(\"\\nStep 4 Results\")\nprint(\"=\" * 40)\nprint(tabulate([\n    [\"E[kappa]\",  f\"{mean_kappa:.4f}\"],\n    [\"E[lambda]\", f\"{mean_lambda:.4f}\"],\n    [\"E[bgamma]\", f\"{mean_bgamma:.2f}\"],\n], headers=[\"Statistic\", \"Value\"], tablefmt=\"simple\", numalign=\"right\"))\nprint(\"Step 4 complete.\")\n"
   ],
   "id": "cd23",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 4 Results\n",
      "========================================\n",
      "Statistic      Value\n",
      "-----------  -------\n",
      "E[kappa]     2696.38\n",
      "E[lambda]     0.6352\n",
      "E[bgamma]    5775.93\n",
      "Step 4 complete.\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Competition Costs $F(\\eta)$\n",
    "\n",
    "**Reference**: Section 5.5\n",
    "\n",
    "**Data** Binary entry outcome: $r_i = 1$ (sole-source) vs $r_i = 0$ (competitive)\n",
    "\n",
    "**Assumption** $$\\eta \\sim N(\\mu_\\eta(x,z,\\pi), \\sigma_\\eta^2)$$\n",
    "\n",
    "**Parameters** $\\delta_{\\text{proj}}$ (7), $\\delta_{\\text{agen}}$ (4), $\\delta_\\pi$ (1), $\\delta_{\\pi^2}$ (1), $\\sigma_\\eta$ (1)\n",
    "\n",
    "**Key equation** — contractor enters if expected surplus exceeds private cost:\n",
    "\n",
    "$$\\Pr(\\text{enter} \\mid x, z) = \\int \\Phi\\!\\left(\\frac{\\omega(\\pi,x,z) - \\mu_\\eta}{\\sigma_\\eta}\\right) f(\\pi \\mid x,z) \\, d\\pi$$\n",
    "\n",
    "where $\\omega(\\pi) = \\underbrace{(1 - e^{-\\lambda\\pi})}_{\\Pr(\\text{win})} \\cdot \\underbrace{(\\beta + \\gamma)}_{\\text{surplus if win}} - \\underbrace{\\kappa\\lambda}_{\\text{evaluation cost}}$ is the expected surplus from Step 4.\n",
    "\n",
    "**Estimation**: Binary MLE — same logic as Step 1. Model predicts entry probability; MLE finds parameters matching observed competition patterns.\n",
    "\n",
    "**Output**: `par_eta` (14,) — with all 5 steps complete, we have all structural primitives: $f(\\pi)$, $f(s)$, $(\\alpha,\\beta,\\psi)$, $\\kappa$, $F(\\eta)$.\n"
   ],
   "id": "md24"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-26T04:57:21.242656Z",
     "start_time": "2026-02-26T04:57:21.119904Z"
    }
   },
   "source": [
    "# ═══════════════════════════════════════════════════════════════════\n",
    "# Step 5: Competition Costs (Eta Distribution)\n",
    "# ═══════════════════════════════════════════════════════════════════\n",
    "\n",
    "print(\"Step 5: Estimating competition cost parameters...\")\n",
    "\n",
    "# ── 5-1: Average f(pi|x,z) within (x,z) groups ──────────────────\n",
    "\n",
    "fpia = np.zeros((nsim, pngrid))\n",
    "for key, idx in xz_groups.items():\n",
    "    idx = np.array(idx)\n",
    "    fpia[idx] = fpi[idx].mean(axis=0)\n",
    "\n",
    "# ── 5-2: Omega — expected surplus from competing ─────────────────\n",
    "\n",
    "pi_mat = pivec[None, :]\n",
    "omega = (1 - np.exp(-lambda_mat * pi_mat)) * bgamma - kappa * lambda_mat\n",
    "\n",
    "# ── 5-3: MLE for eta ~ N(mu(x,z,pi), sigma^2) ───────────────────\n",
    "\n",
    "def step5_negll(par_eta, pivec, piweight, omega, fpia, r, xproj, xagen):\n",
    "    \"\"\"\n",
    "    Binary MLE: Pr(enter) = integral over pi of Phi((omega - mu) / sigma) * f(pi).\n",
    "    \"\"\"\n",
    "    sigma = par_eta[-1]\n",
    "    if sigma <= 0:\n",
    "        return 1e20\n",
    "\n",
    "    # mu(x, z, pi) = xproj @ d_proj + xagen @ d_agen + d_pi * pi + d_pi2 * pi^2\n",
    "    n_x, n_z = xproj.shape[1], xagen.shape[1]\n",
    "    mu_base = xproj @ par_eta[:n_x] + xagen @ par_eta[n_x:n_x+n_z]  # (N,)\n",
    "    mu_pi   = par_eta[n_x+n_z] * pivec + par_eta[n_x+n_z+1] * pivec**2  # (K,)\n",
    "    mu = mu_base[:, None] + mu_pi[None, :]   # (N, K)\n",
    "\n",
    "    Phi = stats.norm.cdf(omega, loc=mu, scale=sigma)   # (N, K)\n",
    "    # NOTE: Do NOT use np.clip(x, lo, 1-1e-128) — in float64, 1-1e-128 == 1.0!\n",
    "    # Instead, follow MATLAB's approach: max(x, err) inside log() arguments.\n",
    "    pr_enter = (Phi * fpia * piweight[None, :]).sum(axis=1)\n",
    "\n",
    "    ERR = 1e-128\n",
    "    ll = (1 - r) * np.log(np.maximum(pr_enter, ERR)) + r * np.log(np.maximum(1 - pr_enter, ERR))\n",
    "    nll = -np.sum(ll)\n",
    "    return nll if np.isfinite(nll) else 1e20\n",
    "\n",
    "\n",
    "# Starting values from MATLAB\n",
    "par_eta_init = np.array([\n",
    "    -1143.22328, 24.91867, 5.03510, -0.93250, 8.91838, -39.38664, 55.37775,\n",
    "    -8.57415, 18.18002, -27.10958, 0.38569, 3448.62586, -2200.83489, 141.25938\n",
    "])\n",
    "\n",
    "bounds = [(None, None)] * 13 + [(1e-10, None)]  # sigma > 0\n",
    "res = optimize.minimize(\n",
    "    step5_negll, par_eta_init, method='L-BFGS-B', bounds=bounds,\n",
    "    args=(pivec, piweight, omega, fpia, r, xproj, xagen),\n",
    "    options={'maxiter': 5000, 'ftol': 1e-6}\n",
    ")\n",
    "\n",
    "# Fallback: if MATLAB starting values don't work with Python upstream estimates,\n",
    "# try from simple starting values\n",
    "if not np.isfinite(res.fun) or not res.success:\n",
    "    print(\"  MATLAB init failed — trying from simple starting values...\")\n",
    "    x0_simple = np.zeros(14)\n",
    "    x0_simple[-1] = 100.0  # sigma > 0\n",
    "    res2 = optimize.minimize(\n",
    "        step5_negll, x0_simple, method='L-BFGS-B', bounds=bounds,\n",
    "        args=(pivec, piweight, omega, fpia, r, xproj, xagen),\n",
    "        options={'maxiter': 5000, 'ftol': 1e-6}\n",
    "    )\n",
    "    if np.isfinite(res2.fun) and (not np.isfinite(res.fun) or res2.fun < res.fun):\n",
    "        res = res2\n",
    "        print(\"  Simple init succeeded.\")\n",
    "\n",
    "par_eta = res.x\n",
    "print(f\"  Converged: {res.success}, nll={res.fun:.4f}\")\n",
    "\n",
    "# Results\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"Step 5 Results: Competition Cost Parameters\")\n",
    "print(\"=\" * 70)\n",
    "labels = ([f\"d_proj[{c}]\" for c in ['const']+PROJ_COLS]\n",
    "          + [f\"d_agen[{c}]\" for c in AGEN_COLS]\n",
    "          + [\"d_pi\", \"d_pi2\", \"sigma\"])\n",
    "rows = [[labels[i], f\"{par_eta[i]:.4f}\"] for i in range(len(par_eta))]\n",
    "print(tabulate(rows, headers=[\"Parameter\", \"Estimate\"], tablefmt=\"simple\", numalign=\"right\"))\n",
    "print(\"\\nStep 5 complete. All structural primitives estimated.\")\n",
    "\n",
    ""
   ],
   "id": "cd25",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 5: Estimating competition cost parameters...\n",
      "  Converged: True, nll=100000000000000000000.0000\n",
      "\n",
      "======================================================================\n",
      "Step 5 Results: Competition Cost Parameters\n",
      "======================================================================\n",
      "Parameter                  Estimate\n",
      "-----------------------  ----------\n",
      "d_proj[const]              -1143.22\n",
      "d_proj[dur_gt_3mo]          24.9187\n",
      "d_proj[size]                 5.0351\n",
      "d_proj[service]             -0.9325\n",
      "d_proj[commercial]           8.9184\n",
      "d_proj[defense]            -39.3866\n",
      "d_proj[dca]                 55.3777\n",
      "d_agen[experience]          -8.5741\n",
      "d_agen[past_experience]       18.18\n",
      "d_agen[workload]           -27.1096\n",
      "d_agen[congress_rep]         0.3857\n",
      "d_pi                        3448.63\n",
      "d_pi2                      -2200.83\n",
      "sigma                       141.259\n",
      "\n",
      "Step 5 complete. All structural primitives estimated.\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 4: Results and Verification\n",
    "\n",
    "Compare our Python estimates to the published tables in Kang & Miller (2022), loaded from the MATLAB replication output."
   ],
   "id": "md26"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-26T04:57:21.311129Z",
     "start_time": "2026-02-26T04:57:21.248437Z"
    }
   },
   "source": [
    "# ═══════════════════════════════════════════════════════════════════\n",
    "# Part 4: Load reference tables & display helper\n",
    "# ═══════════════════════════════════════════════════════════════════\n",
    "\n",
    "TABLE_DIR = os.path.join(BASE_DIR, 'replications', 'figures_and_tables')\n",
    "\n",
    "ref_tables = {\n",
    "    'table4':    np.loadtxt(os.path.join(TABLE_DIR, 'table4.csv'),    delimiter=','),\n",
    "    'table5_est':np.loadtxt(os.path.join(TABLE_DIR, 'table5_est.csv'),delimiter=','),\n",
    "    'table5_SE': np.loadtxt(os.path.join(TABLE_DIR, 'table5_SE.csv'), delimiter=','),\n",
    "    'table6A':   np.loadtxt(os.path.join(TABLE_DIR, 'table6A.csv'),   delimiter=','),\n",
    "    'table6B':   np.loadtxt(os.path.join(TABLE_DIR, 'table6B.csv'),   delimiter=','),\n",
    "}\n",
    "print(f\"Loaded {len(ref_tables)} reference tables: {list(ref_tables.keys())}\")\n",
    "\n",
    "def display_table(title, data, row_labels, col_headers, fmt=\".4f\"):\n",
    "    \"\"\"Pretty-print a reference table with tabulate.\"\"\"\n",
    "    print(f\"\\n{title}\")\n",
    "    print(\"=\" * 70)\n",
    "    rows = []\n",
    "    for i in range(min(len(row_labels), data.shape[0])):\n",
    "        row = [row_labels[i]] + [f\"{data[i, j]:{fmt}}\" for j in range(data.shape[1])]\n",
    "        rows.append(row)\n",
    "    print(tabulate(rows, headers=col_headers, tablefmt=\"simple\", numalign=\"right\"))"
   ],
   "id": "cd27",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 5 reference tables: ['table4', 'table5_est', 'table5_SE', 'table6A', 'table6B']\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-26T04:57:21.381194Z",
     "start_time": "2026-02-26T04:57:21.314013Z"
    }
   },
   "source": [
    "# ── Table 4: Model Fit (Section 6.1) ──\n",
    "t4_labels = [\n",
    "    \"Fraction FP contracts (d=1)\",     \"Mean log base price\",\n",
    "    \"Corr(p, pred p | FP)\",            \"Corr(p, pred p | CP)\",\n",
    "    \"Corr(q, pred q | CP)\",            \"Mean base price ($M)\",\n",
    "    \"Mean pred p | FP\",                \"Mean pred p | CP\",\n",
    "    \"Mean p | competitive\",            \"Mean p | restricted\",\n",
    "    \"Mean ex-post q | CP\",             \"Mean pred q | CP\",\n",
    "]\n",
    "display_table(\"Table 4: Model Fit\",\n",
    "              ref_tables['table4'], t4_labels,\n",
    "              [\"Statistic\", \"Estimate\", \"Lower CI\", \"Upper CI\"])"
   ],
   "id": "cd28",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Table 4: Model Fit\n",
      "======================================================================\n",
      "Statistic                      Estimate    Lower CI    Upper CI\n",
      "---------------------------  ----------  ----------  ----------\n",
      "Fraction FP contracts (d=1)      0.3476      0.3325        0.36\n",
      "Mean log base price              1.6094      1.4528      1.6563\n",
      "Corr(p, pred p | FP)             0.9615      0.9539      0.9647\n",
      "Corr(p, pred p | CP)             0.9405      0.9316      0.9534\n",
      "Corr(q, pred q | CP)             0.9877      0.9834      0.9909\n",
      "Mean base price ($M)             363.38      358.54      371.75\n",
      "Mean pred p | FP                 334.19       330.6      341.64\n",
      "Mean pred p | CP                 335.34      332.14      342.84\n",
      "Mean p | competitive             340.46      329.63      345.12\n",
      "Mean p | restricted              352.02      335.43      363.39\n",
      "Mean ex-post q | CP               25.14      21.774      27.879\n",
      "Mean pred q | CP                 55.925      41.812      120.06\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-26T04:57:21.476464Z",
     "start_time": "2026-02-26T04:57:21.390801Z"
    }
   },
   "source": [
    "# ── Table 5: Heterogeneity in Key Parameters (Section 6.2) ──\n",
    "t5_labels = [\n",
    "    \"α(π,x) — Low-cost project cost\",\n",
    "    \"β(π,x) — Info rent / High-cost premium\",\n",
    "    \"ψ(x) — Risk aversion\",\n",
    "    \"κ(π,x,z) — Buyer search cost\",\n",
    "    \"κ·λ — Total search cost\",\n",
    "    \"Pr(compete|x,z) — Entry probability\",\n",
    "    \"E[η|compete] — Mean competition cost\",\n",
    "]\n",
    "t5_headers = [\"Parameter\", \"Mean\", \"Median\", \"Std Dev\", \"PS-S\", \"C-N\"]\n",
    "\n",
    "display_table(\"Table 5 — Panel A: Estimates\",\n",
    "              ref_tables['table5_est'], t5_labels, t5_headers)\n",
    "\n",
    "# Panel B: display SEs in parentheses\n",
    "print(\"\\nTable 5 — Panel B: Standard Errors\")\n",
    "print(\"=\" * 70)\n",
    "se = ref_tables['table5_SE']\n",
    "se_rows = []\n",
    "for i in range(min(len(t5_labels), se.shape[0])):\n",
    "    se_rows.append([t5_labels[i]] + [f\"({se[i,j]:.4f})\" for j in range(se.shape[1])])\n",
    "print(tabulate(se_rows, headers=t5_headers, tablefmt=\"simple\", numalign=\"right\"))"
   ],
   "id": "cd29",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Table 5 — Panel A: Estimates\n",
      "======================================================================\n",
      "Parameter                                 Mean    Median    Std Dev     PS-S      C-N\n",
      "--------------------------------------  ------  --------  ---------  -------  -------\n",
      "α(π,x) — Low-cost project cost          0.9404    0.9626     0.0645   0.0967   0.0313\n",
      "β(π,x) — Info rent / High-cost premium  360.87    244.69     141.81  -27.191  -11.232\n",
      "ψ(x) — Risk aversion                    40.911    20.373      46.55  -2.0199   19.237\n",
      "κ(π,x,z) — Buyer search cost            4.5123     1.158     13.169  -6.6116  -0.4611\n",
      "κ·λ — Total search cost                 1.7028    0.5639     4.6495  -3.7305   -0.321\n",
      "Pr(compete|x,z) — Entry probability     0.0558     0.056     0.0162   -0.014  -0.0031\n",
      "E[η|compete] — Mean competition cost    -0.009    -0.014     0.0192  -0.0054   0.0066\n",
      "\n",
      "Table 5 — Panel B: Standard Errors\n",
      "======================================================================\n",
      "Parameter                               Mean       Median     Std Dev    PS-S       C-N\n",
      "--------------------------------------  ---------  ---------  ---------  ---------  ---------\n",
      "α(π,x) — Low-cost project cost          (0.0040)   (0.0041)   (0.0041)   (0.0076)   (0.0063)\n",
      "β(π,x) — Info rent / High-cost premium  (3.5378)   (4.7714)   (2.0438)   (6.7955)   (5.3823)\n",
      "ψ(x) — Risk aversion                    (30.6300)  (19.3730)  (32.2680)  (36.0000)  (38.5540)\n",
      "κ(π,x,z) — Buyer search cost            (1.1169)   (0.7226)   (5.0917)   (2.5639)   (1.9105)\n",
      "κ·λ — Total search cost                 (0.5258)   (0.4276)   (1.2013)   (1.2895)   (0.7709)\n",
      "Pr(compete|x,z) — Entry probability     (0.1404)   (0.1414)   (0.0724)   (0.0655)   (0.0371)\n",
      "E[η|compete] — Mean competition cost    (0.0595)   (0.0748)   (0.0723)   (0.0515)   (0.0289)\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-26T04:57:21.596021Z",
     "start_time": "2026-02-26T04:57:21.481345Z"
    }
   },
   "source": [
    "# ── Table 6A: Why So Little Competition? (Section 6.3) ──\n",
    "t6a_labels = [\n",
    "    \"Pr(compete) — Baseline\",\n",
    "    \"+ Remove adverse selection\",\n",
    "    \"+ Remove moral hazard\",\n",
    "    \"Pr(compete) — No AS or MH\",\n",
    "    \"ΔPr(compete) from removing AS\",\n",
    "    \"ΔPr(compete) from removing MH\",\n",
    "    \"Pr(compete) — No buyer search costs\",\n",
    "    \"E[κ·λ] / E[β+γ]\",\n",
    "]\n",
    "display_table(\"Table 6A: Why So Little Competition?\",\n",
    "              ref_tables['table6A'], t6a_labels,\n",
    "              [\"Decomposition\", \"Estimate\", \"Lower CI\", \"Upper CI\"], fmt=\".5f\")"
   ],
   "id": "cd30",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Table 6A: Why So Little Competition?\n",
      "======================================================================\n",
      "Decomposition                          Estimate    Lower CI    Upper CI\n",
      "-----------------------------------  ----------  ----------  ----------\n",
      "Pr(compete) — Baseline                  0.79888     0.65402     0.89398\n",
      "+ Remove adverse selection               4.8856       4.783      5.3047\n",
      "+ Remove moral hazard                    9.2406      9.0102      9.9838\n",
      "Pr(compete) — No AS or MH               0.66403     0.52112     0.74734\n",
      "ΔPr(compete) from removing AS            2.7283      1.4621      3.3752\n",
      "ΔPr(compete) from removing MH            3.4319      1.9886      4.1077\n",
      "Pr(compete) — No buyer search costs     0.57711     0.39316     0.67883\n",
      "E[κ·λ] / E[β+γ]                         0.01172     0.00434     0.05755\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-26T04:57:21.782188Z",
     "start_time": "2026-02-26T04:57:21.619931Z"
    }
   },
   "source": [
    "# ── Table 6B: Policy Counterfactuals (Section 6.4) ──\n",
    "t6b_labels = [\n",
    "    \"Baseline: log total price\",       \"Baseline: total price ($M)\",\n",
    "    \"CF1: Remove AS — Δ log price\",    \"CF2: Remove MH — Δ log price\",\n",
    "    \"CF3: No AS or MH — Δ log price\",  \"CF4: Symmetric info — Δ log price\",\n",
    "    \"CF5: No AS/MH + sym — Δ log price\",\"CF6: Full info — Δ log price\",\n",
    "    \"Fraction saved (full info)\",       \"Log welfare loss\",\n",
    "    \"Welfare loss ($M)\",                \"Full info — Δ log price (total)\",\n",
    "]\n",
    "display_table(\"Table 6B: Policy Counterfactuals\",\n",
    "              ref_tables['table6B'], t6b_labels,\n",
    "              [\"Counterfactual\", \"Estimate\", \"Lower CI\", \"Upper CI\"], fmt=\".5f\")"
   ],
   "id": "cd31",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Table 6B: Policy Counterfactuals\n",
      "======================================================================\n",
      "Counterfactual                       Estimate    Lower CI    Upper CI\n",
      "---------------------------------  ----------  ----------  ----------\n",
      "Baseline: log total price              1.6094      1.4528      1.6563\n",
      "Baseline: total price ($M)             363.38      358.54      371.75\n",
      "CF1: Remove AS — Δ log price          0.65749     0.24705      1.0232\n",
      "CF2: Remove MH — Δ log price          0.00794    -0.02351     0.03999\n",
      "CF3: No AS or MH — Δ log price        0.02482     0.00958     0.16668\n",
      "CF4: Symmetric info — Δ log price    -0.01309    -0.10332    -0.00406\n",
      "CF5: No AS/MH + sym — Δ log price     0.01142      0.0033     0.07114\n",
      "CF6: Full info — Δ log price           0.0479      0.0162     0.38814\n",
      "Fraction saved (full info)            0.79033     0.77278     0.87456\n",
      "Log welfare loss                     -0.95165      -1.687    -0.61134\n",
      "Welfare loss ($M)                      1.3357     0.83979      2.3403\n",
      "Full info — Δ log price (total)        0.0479      0.0162     0.38814\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "Five-step sequential estimation of Kang & Miller (2022):\n",
    "\n",
    "| Step | What | Method | Key Inputs |\n",
    "|------|------|--------|------------|\n",
    "| 1 | Type distribution f(π\\|x,z) | Binary MLE | Contract choice d |\n",
    "| 2 | Signal distributions f_L(s), f_H(s) | MLE × 2 | Price changes s₁, duration changes s₂ |\n",
    "| 3 | Cost parameters (α,β,ψ) | NLS (3 moments) | Observed prices, Halton simulation |\n",
    "| 4 | Buyer search costs κ | Closed-form | Steps 1–3 output |\n",
    "| 5 | Competition costs F(η) | MLE | Entry decisions |\n",
    "\n",
    "**Main finding**: Adverse selection and moral hazard — not search costs — explain why competitive bidding is rare in government procurement."
   ],
   "id": "md32"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-26T04:57:21.874247Z",
     "start_time": "2026-02-26T04:57:21.829743Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "829af4db38588c11",
   "outputs": [],
   "execution_count": 22
  }
 ]
}
