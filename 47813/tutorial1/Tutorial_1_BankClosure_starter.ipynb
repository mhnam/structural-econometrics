{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 1: The Costs of Closing Failed Banks\n",
    "## Replication of Kang, Lowery & Wardlaw (Review of Financial Studies, 2015)\n",
    "---\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. [Economic Framework](#1-economic-framework)\n",
    "   - 1.1 The Research Question\n",
    "   - 1.2 The Dynamic Discrete Choice Model\n",
    "   - 1.3 The CCP Approach (Hotz-Miller 1993)\n",
    "2. [Data Overview](#2-data-overview)\n",
    "   - 2.1 Data Sources\n",
    "   - 2.2 Variable Definitions\n",
    "   - 2.3 Summary Statistics\n",
    "3. [First Stage: CCP Estimation](#3-first-stage-ccp-estimation)\n",
    "   - 3.1 Flexible Logit Specification\n",
    "   - 3.2 Estimation Results\n",
    "   - 3.3 Verification and Diagnostics\n",
    "4. [Second Stage: Forward Simulation](#4-second-stage-forward-simulation)\n",
    "   - 4.1 State Transition Model\n",
    "   - 4.2 Monte Carlo Integration\n",
    "   - 4.3 Verification\n",
    "5. [Third Stage: Structural GMM Estimation](#5-third-stage-structural-gmm-estimation)\n",
    "   - 5.1 The Moment Condition\n",
    "   - 5.2 Continuously-Updated GMM\n",
    "   - 5.3 Grid-Search Refinement Procedure\n",
    "   - 5.4 Estimation Results\n",
    "6. [Inference and Results](#6-inference-and-results)\n",
    "   - 6.1 Standard Error Computation\n",
    "   - 6.2 Pre-Estimation Variance Adjustments\n",
    "7. [Economic Interpretation](#7-economic-interpretation)\n",
    "   - 7.1 Parameter Interpretation\n",
    "   - 7.2 Net Monetary Cost Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 1. Economic Framework\n",
    "\n",
    "## 1.1 The Research Question\n",
    "\n",
    "**Economic Question**: What are the structural parameters governing bank regulators' decisions to close a bank?\n",
    "\n",
    "**Object of Interest**: \n",
    "- Discount factor ($\\beta$) - how much do regulators value future costs?\n",
    "- Scale parameter ($\\sigma$) - how much heterogeneity exists in unobserved closure costs?\n",
    "- Net monetary cost function parameters ($\\beta_{NMC}$) - how do bank characteristics affect operating costs?\n",
    "\n",
    "**Identification**: The CCP approach (Hotz-Miller 1993) identifies the value function difference from observed closure probabilities. The key identifying assumption is that unobserved shocks follow the Type-I Extreme Value distribution.\n",
    "\n",
    "**Sample**: 22,269 bank-quarter observations during the S&L Crisis era (1985Q4-1992Q4).\n",
    "\n",
    "## 1.2 The Dynamic Discrete Choice Model\n",
    "\n",
    "### State Variables\n",
    "\n",
    "At each period $t$, a bank is characterized by state vector $s_t$:\n",
    "- **Equity ratio** ($equity\\_a$): Capital buffer against losses\n",
    "- **Non-performing loans ratio** ($npf\\_a$): Measure of asset quality\n",
    "- **Log assets** ($\\log(assets)$): Bank size\n",
    "- **Real estate owned ratio** ($realest\\_a$): Foreclosed properties\n",
    "- **Return on assets** ($roa$): Profitability\n",
    "- **Political indices** ($House$, $Senate$): Regulatory environment\n",
    "\n",
    "### Value Functions\n",
    "\n",
    "The regulator's value function for keeping the bank **open**:\n",
    "\n",
    "$$V_{\\text{open}}(s_t) = MC(s_t) + \\beta \\cdot \\mathbb{E}_t[V(s_{t+1})]$$\n",
    "\n",
    "where:\n",
    "- $MC(s_t)$ = Net monetary cost of operating the bank (negative if bank is profitable)\n",
    "- $\\beta$ = Discount factor\n",
    "- $\\mathbb{E}_t[V(s_{t+1})]$ = Expected continuation value\n",
    "\n",
    "The value of **closing** the bank: $V_{\\text{close}}(s_t) = 0$ (normalized)\n",
    "\n",
    "### Choice Probabilities\n",
    "\n",
    "With Type-I Extreme Value (logit) errors, the probability of closing is:\n",
    "\n",
    "$$P(\\text{close} | s_t) = \\frac{1}{1 + \\exp\\left(\\frac{V_{\\text{open}}(s_t) - V_{\\text{close}}(s_t)}{\\sigma}\\right)}$$\n",
    "\n",
    "## 1.3 The CCP Approach (Hotz-Miller 1993)\n",
    "\n",
    "### The Inversion Formula\n",
    "\n",
    "From the logit formula:\n",
    "\n",
    "$$\\sigma \\cdot \\log\\left(\\frac{1 - P_t}{P_t}\\right) = V_{\\text{open}}(s_t) - V_{\\text{close}}(s_t)$$\n",
    "\n",
    "### The Euler Equation / Moment Condition\n",
    "\n",
    "Substituting the value function:\n",
    "\n",
    "$$g(\\theta) = \\sigma \\cdot \\log\\left(\\frac{1-P_t}{P_t}\\right) + \\beta\\sigma \\cdot \\mathbb{E}[\\ln P_{t+1}] - \\beta \\cdot \\mathbb{E}[MC_{t+1}] + MC_t$$\n",
    "\n",
    "### Structural Parameters (10 total)\n",
    "\n",
    "- $\\beta$: Discount factor (quarterly)\n",
    "- $\\sigma$: Scale of idiosyncratic closure cost\n",
    "- $\\beta_{NMC}$: Coefficients of the net monetary cost function (8 parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Setup: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-14T19:38:34.527709Z",
     "start_time": "2026-01-14T19:38:34.505042Z"
    }
   },
   "source": "# Core scientific computing\nimport numpy as np\nimport pandas as pd\nfrom scipy import stats\nfrom scipy.optimize import minimize\nfrom scipy.special import expit  # Logistic function\nimport scipy.io as sio\nfrom tabulate import tabulate\n\n# Visualization\nimport matplotlib.pyplot as plt\n\n# Utilities\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Set display options\npd.set_option('display.max_columns', 50)\npd.set_option('display.float_format', '{:.6f}'.format)\nnp.set_printoptions(precision=6, suppress=True)\n\n# Plotting style\nplt.rcParams['figure.figsize'] = (10, 6)\nplt.rcParams['font.size'] = 12\n\nprint(\"Libraries loaded successfully.\")",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries loaded successfully.\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 2. Data Overview\n",
    "\n",
    "## 2.1 Data Sources\n",
    "\n",
    "The data comes from the **Call Reports** (quarterly regulatory filings by U.S. banks) covering:\n",
    "- **Period**: 1985Q4 to 1992Q4 (the S&L Crisis era)\n",
    "- **Sample**: 22,269 bank-quarter observations\n",
    "- **Bank closures**: 714 failures (3.21%)\n",
    "\n",
    "## 2.2 Pre-computed Data Files\n",
    "\n",
    "This replication uses pre-computed files from the original MATLAB estimation:\n",
    "\n",
    "| File | Contents | Stage |\n",
    "|------|----------|-------|\n",
    "| `dataforlogit_KLW.txt` | B-spline design matrix (22,269 x 80) | First stage |\n",
    "| `logit_beta_KLW.txt` | Pre-computed logit coefficients (79) | First stage |\n",
    "| `ccpnext_param_sim5000_KLW.txt` | Forward simulations (5,000 draws) | Second stage |\n",
    "| `dataforparam_KLW.mat` | Merged GMM estimation data | Third stage |\n",
    "| `theta_KLW.mat` | Original structural estimates | Verification |\n",
    "\n",
    "**Note on Replication**: The first and second stages are NOT independently replicated here. We use pre-computed files because:\n",
    "1. First-stage logit requires MATLAB's CompEcon B-spline toolbox\n",
    "2. Second-stage simulation requires AR(4) transition parameter estimates from Stata"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-14T19:38:37.304201Z",
     "start_time": "2026-01-14T19:38:37.132426Z"
    }
   },
   "source": [
    "# Define paths\n",
    "DATA_PATH = './data/'\n",
    "OUTPUT_PATH = './output/'\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"LOADING PRE-COMPUTED DATA FILES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# ============================================================\n",
    "# Load the pre-computed logit design matrix\n",
    "# ============================================================\n",
    "print(\"\\n1. Loading logit design matrix (B-spline basis functions)...\")\n",
    "logit_data = np.loadtxt(DATA_PATH + 'dataforlogit_KLW.txt')\n",
    "print(f\"   Shape: {logit_data.shape}\")\n",
    "print(f\"   Columns 1-72: B-spline basis (6 vars x 4 lags x 3 basis)\")\n",
    "print(f\"   Columns 73-76: Unemployment (4 lags)\")\n",
    "print(f\"   Columns 77-78: House, Senate indices\")\n",
    "print(f\"   Column 79: yearq\")\n",
    "print(f\"   Column 80: failed (outcome)\")\n",
    "\n",
    "X_logit = logit_data[:, :78]  # First 78 columns are regressors\n",
    "y_logit = logit_data[:, 79]   # Column 80 is outcome (0-indexed: 79)\n",
    "\n",
    "print(f\"\\n   Number of failures: {int(y_logit.sum())} ({100*y_logit.mean():.2f}%)\")\n",
    "\n",
    "# ============================================================\n",
    "# Load pre-computed forward simulations\n",
    "# ============================================================\n",
    "print(\"\\n2. Loading forward simulation results (5,000 draws per obs)...\")\n",
    "ccp_next = np.loadtxt(OUTPUT_PATH + 'ccpnext_param_sim5000_KLW.txt')\n",
    "print(f\"   Shape: {ccp_next.shape}\")\n",
    "\n",
    "# ============================================================\n",
    "# Load original logit coefficients\n",
    "# ============================================================\n",
    "print(\"\\n3. Loading original logit coefficients (from Stata)...\")\n",
    "with open(OUTPUT_PATH + 'logit_beta_KLW.txt', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "orig_logit_beta = []\n",
    "for line in lines[3:]:\n",
    "    parts = line.strip().split('\\t')\n",
    "    if len(parts) >= 2:\n",
    "        try:\n",
    "            orig_logit_beta.append(float(parts[1]))\n",
    "        except:\n",
    "            pass\n",
    "orig_logit_beta = np.array(orig_logit_beta)\n",
    "print(f\"   Number of coefficients: {len(orig_logit_beta)}\")\n",
    "\n",
    "# ============================================================\n",
    "# Load GMM estimation data\n",
    "# ============================================================\n",
    "print(\"\\n4. Loading GMM estimation data...\")\n",
    "gmm_mat = sio.loadmat(OUTPUT_PATH + 'dataforparam_KLW.mat')\n",
    "print(f\"   Variables loaded: {len([k for k in gmm_mat.keys() if not k.startswith('__')])}\")\n",
    "\n",
    "# ============================================================\n",
    "# Load original structural estimates for comparison\n",
    "# ============================================================\n",
    "print(\"\\n5. Loading original structural estimates...\")\n",
    "theta_mat = sio.loadmat(OUTPUT_PATH + 'theta_KLW.mat')\n",
    "theta_original = theta_mat['theta_KLW'].squeeze()\n",
    "print(f\"   Original theta: {theta_original}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"DATA LOADING COMPLETE\")\n",
    "print(\"=\"*70)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "LOADING PRE-COMPUTED DATA FILES\n",
      "======================================================================\n",
      "\n",
      "1. Loading logit design matrix (B-spline basis functions)...\n",
      "   Shape: (22269, 80)\n",
      "   Columns 1-72: B-spline basis (6 vars x 4 lags x 3 basis)\n",
      "   Columns 73-76: Unemployment (4 lags)\n",
      "   Columns 77-78: House, Senate indices\n",
      "   Column 79: yearq\n",
      "   Column 80: failed (outcome)\n",
      "\n",
      "   Number of failures: 714 (3.21%)\n",
      "\n",
      "2. Loading forward simulation results (5,000 draws per obs)...\n",
      "   Shape: (22269, 15)\n",
      "\n",
      "3. Loading original logit coefficients (from Stata)...\n",
      "   Number of coefficients: 79\n",
      "\n",
      "4. Loading GMM estimation data...\n",
      "   Variables loaded: 34\n",
      "\n",
      "5. Loading original structural estimates...\n",
      "   Original theta: [      0.958234     639.844059 -507234.992222   93645.094123\n",
      "   -4320.306837  -54111.280274  -48971.264904 -183782.202034\n",
      "    -829.006435     210.188013]\n",
      "\n",
      "======================================================================\n",
      "DATA LOADING COMPLETE\n",
      "======================================================================\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-14T19:39:12.901676Z",
     "start_time": "2026-01-14T19:39:12.860452Z"
    }
   },
   "source": "# =============================================================================\n# Table 1: Summary Statistics (1985-1992)\n# Replicating Table 1 from Kang, Lowery & Wardlaw (RFS 2015), page 16\n# =============================================================================\n\nprint(\"=\"*75)\nprint(\"Table 1: Summary Statistics: 1985-1992\")\nprint(\"=\"*75)\n\n# Extract key variables from GMM data\nequity_a = gmm_mat['equity_a_all'][:, 0].squeeze()\nnpf_a = gmm_mat['npf_a_all'][:, 0].squeeze()\nlog_assets = gmm_mat['logasset_all'][:, 0].squeeze()\nroa = gmm_mat['roa_annual_all'][:, 0].squeeze()\nrealest = gmm_mat['realEst_own_a_all'][:, 0].squeeze()\nunemp = gmm_mat['unemp_all'][:, 0].squeeze()\nHouse = gmm_mat['House'].squeeze()\nSenate = gmm_mat['Senate'].squeeze()\nBclose = gmm_mat['Bclose'].squeeze()\nassets_M = np.exp(log_assets) / 1e6  # Convert to millions\n\n# Panel A: Quarterly Call Report data/macroeconomic and political conditions\nprint(\"\\nPanel A: Quarterly Call Report data/macroeconomic and political conditions\")\nprint(\"-\"*75)\n\ndef format_stat(val, decimals=3):\n    \"\"\"Format statistic with appropriate precision.\"\"\"\n    if abs(val) >= 100:\n        return f\"{val:.0f}\"\n    elif abs(val) >= 10:\n        return f\"{val:.1f}\"\n    else:\n        return f\"{val:.{decimals}f}\"\n\npanel_a_vars = [\n    ('Assets ($M)', assets_M),\n    ('Equity/assets', equity_a),\n    ('Nonperforming loans/assets', npf_a),\n    ('Real estate owned/assets', realest),\n    ('Net income/assets', roa),\n    ('State unemployment rate (%)', unemp),\n    ('House', House),\n    ('Senate', Senate),\n]\n\npanel_a_rows = []\nfor name, arr in panel_a_vars:\n    panel_a_rows.append([\n        name,\n        format_stat(arr.mean()),\n        format_stat(arr.std()),\n        format_stat(np.percentile(arr, 5)),\n        format_stat(np.median(arr)),\n        format_stat(np.percentile(arr, 95))\n    ])\n\nprint(tabulate(panel_a_rows,\n               headers=['', 'Mean', 'Sd', '5%', 'Median', '95%'],\n               tablefmt='simple',\n               colalign=('left', 'right', 'right', 'right', 'right', 'right')))\n\nprint(f\"\\nObservations: {len(equity_a):,}\")\nprint(f\"Unique banks: {len(np.unique(gmm_mat['BankID'])):,}\")\n\n# Panel B: FDIC failure and merger data\nprint(\"\\n\" + \"-\"*75)\nprint(\"Panel B: FDIC failure and merger data\")\nprint(\"-\"*75)\n\nn_failures = int(Bclose.sum())\nfailure_rate = 100 * Bclose.mean()\n\nprint(f\"\\nFailures: {n_failures}\")\nprint(f\"Failure rate: {failure_rate:.2f}%\")\n\nprint(\"\\n\" + \"=\"*75)\nprint(\"Note: This table corresponds to Table 1 in the paper (page 16).\")\nprint(\"=\"*75)",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========================================================================\n",
      "Table 1: Summary Statistics: 1985-1992\n",
      "===========================================================================\n",
      "\n",
      "Panel A: Quarterly Call Report data/macroeconomic and political conditions\n",
      "---------------------------------------------------------------------------\n",
      "                               Mean     Sd      5%    Median     95%\n",
      "---------------------------  ------  -----  ------  --------  ------\n",
      "Assets ($M)                   0.125  0.238   0.016     0.052    0.51\n",
      "Equity/assets                 0.054  0.039       0     0.057   0.106\n",
      "Nonperforming loans/assets    0.041  0.036   0.003     0.031   0.108\n",
      "Real estate owned/assets      0.026   0.03       0     0.017   0.083\n",
      "Net income/assets            -0.022  0.024  -0.065    -0.014  -0.001\n",
      "State unemployment rate (%)    6.96  1.694     4.5       6.7     9.6\n",
      "House                         3.148  2.903       0         3      10\n",
      "Senate                        1.423  0.757       0         2       2\n",
      "\n",
      "Observations: 22,269\n",
      "Unique banks: 4,661\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "Panel B: FDIC failure and merger data\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "Failures: 714\n",
      "Failure rate: 3.21%\n",
      "\n",
      "===========================================================================\n",
      "Note: This table corresponds to Table 1 in the paper (page 16).\n",
      "===========================================================================\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize key variables\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "# Capital ratio distribution\n",
    "axes[0, 0].hist(equity_a, bins=50, edgecolor='black', alpha=0.7)\n",
    "axes[0, 0].axvline(x=0.08, color='red', linestyle='--', linewidth=2, label='Regulatory min (8%)')\n",
    "axes[0, 0].set_xlabel('Equity / Assets')\n",
    "axes[0, 0].set_ylabel('Frequency')\n",
    "axes[0, 0].set_title('Capital Ratio Distribution')\n",
    "axes[0, 0].legend()\n",
    "\n",
    "# NPL distribution\n",
    "axes[0, 1].hist(npf_a, bins=50, edgecolor='black', alpha=0.7)\n",
    "axes[0, 1].set_xlabel('Non-Performing Loans / Assets')\n",
    "axes[0, 1].set_ylabel('Frequency')\n",
    "axes[0, 1].set_title('Asset Quality Distribution')\n",
    "\n",
    "# Compare failed vs surviving: equity\n",
    "failed_mask = Bclose == 1\n",
    "axes[1, 0].hist(equity_a[~failed_mask], bins=30, alpha=0.5, label='Surviving', density=True)\n",
    "axes[1, 0].hist(equity_a[failed_mask], bins=30, alpha=0.5, label='Failed', density=True)\n",
    "axes[1, 0].set_xlabel('Equity / Assets')\n",
    "axes[1, 0].set_ylabel('Density')\n",
    "axes[1, 0].set_title('Capital: Failed vs Surviving Banks')\n",
    "axes[1, 0].legend()\n",
    "\n",
    "# Compare failed vs surviving: NPL\n",
    "axes[1, 1].hist(npf_a[~failed_mask], bins=30, alpha=0.5, label='Surviving', density=True)\n",
    "axes[1, 1].hist(npf_a[failed_mask], bins=30, alpha=0.5, label='Failed', density=True)\n",
    "axes[1, 1].set_xlabel('Non-Performing Loans / Assets')\n",
    "axes[1, 1].set_ylabel('Density')\n",
    "axes[1, 1].set_title('Asset Quality: Failed vs Surviving Banks')\n",
    "axes[1, 1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 3. First Stage: CCP Estimation\n",
    "\n",
    "## 3.1 Flexible Logit Specification\n",
    "\n",
    "The first stage estimates conditional choice probabilities (CCPs) using a flexible logit model.\n",
    "\n",
    "### Why B-spline Basis Functions?\n",
    "\n",
    "We avoid imposing restrictive functional forms by using **B-spline basis functions**:\n",
    "- 6 state variables (equity, NPL, log_assets, real_estate, ROA, asset_growth)\n",
    "- 4 lags each (current + 3 lags)\n",
    "- 3 B-spline basis functions per variable-lag\n",
    "- Total: 72 basis + 4 unemployment lags + 2 political indices + 1 constant = **79 parameters**\n",
    "\n",
    "### Note on Replication\n",
    "\n",
    "**We use pre-computed logit coefficients from the original Stata estimation** because:\n",
    "1. The B-spline basis requires MATLAB's CompEcon toolbox (not available in Python)\n",
    "2. The high-dimensional logit (79 parameters) requires careful regularization\n",
    "\n",
    "The logit model is:\n",
    "$$P(\\text{close}_t = 1 | s_t) = \\Lambda(X_t \\beta) = \\frac{1}{1 + \\exp(-X_t \\beta)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"FIRST STAGE: CCP Estimation\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Add constant to design matrix\n",
    "X_logit_const = np.column_stack([X_logit, np.ones(len(X_logit))])\n",
    "print(f\"\\nDesign matrix with constant: {X_logit_const.shape}\")\n",
    "print(f\"Number of parameters: {X_logit_const.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Using Pre-computed Coefficients\n",
    "\n",
    "The original estimation was performed in **Stata** (see `logit_KLW.do`):\n",
    "```stata\n",
    "logit failed lnbasis_1 - lnbasis_72 unemp* house senate\n",
    "```\n",
    "\n",
    "We load and verify the pre-computed coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Using Pre-computed Logit Coefficients ---\")\n",
    "\n",
    "# Compute predictions using original betas\n",
    "P_hat = expit(X_logit_const @ orig_logit_beta)\n",
    "\n",
    "# Load original predictions for verification\n",
    "P_hat_file = np.loadtxt(OUTPUT_PATH + 'logit_predict_KLW.txt')\n",
    "\n",
    "print(f\"Predictions using original betas: mean={P_hat.mean():.6f}\")\n",
    "print(f\"Original prediction file:         mean={P_hat_file.mean():.6f}\")\n",
    "print(f\"Correlation: {np.corrcoef(P_hat, P_hat_file)[0,1]:.8f}\")\n",
    "print(f\"Max absolute difference: {np.abs(P_hat - P_hat_file).max():.10f}\")\n",
    "\n",
    "if np.corrcoef(P_hat, P_hat_file)[0,1] > 0.9999:\n",
    "    print(\"\\n>>> VERIFICATION PASSED: Predictions match original!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Verification and Diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use original predictions for subsequent analysis\n",
    "P_hat = P_hat_file.copy()\n",
    "\n",
    "print(\"Using ORIGINAL logit predictions for exact replication.\")\n",
    "print(f\"\\nPredicted closure probabilities:\")\n",
    "print(f\"  Min:  {P_hat.min():.8f}\")\n",
    "print(f\"  Max:  {P_hat.max():.8f}\")\n",
    "print(f\"  Mean: {P_hat.mean():.8f}\")\n",
    "print(f\"  Actual closure rate: {y_logit.mean():.8f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diagnostic plots\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Distribution of predicted probabilities\n",
    "axes[0].hist(P_hat[y_logit == 0], bins=50, alpha=0.5, label='Surviving', density=True)\n",
    "axes[0].hist(P_hat[y_logit == 1], bins=50, alpha=0.5, label='Failed', density=True)\n",
    "axes[0].set_xlabel('Predicted P(Close)')\n",
    "axes[0].set_ylabel('Density')\n",
    "axes[0].set_title('Distribution of Predicted Closure Probabilities')\n",
    "axes[0].legend()\n",
    "\n",
    "# Calibration plot\n",
    "bins = np.linspace(0, 1, 21)\n",
    "bin_indices = np.digitize(P_hat, bins)\n",
    "bin_means = []\n",
    "actual_rates = []\n",
    "for i in range(1, len(bins)):\n",
    "    mask = bin_indices == i\n",
    "    if mask.sum() > 0:\n",
    "        bin_means.append(P_hat[mask].mean())\n",
    "        actual_rates.append(y_logit[mask].mean())\n",
    "\n",
    "axes[1].scatter(bin_means, actual_rates, s=100, alpha=0.7)\n",
    "axes[1].plot([0, 1], [0, 1], 'r--', label='Perfect calibration')\n",
    "axes[1].set_xlabel('Mean Predicted Probability')\n",
    "axes[1].set_ylabel('Actual Closure Rate')\n",
    "axes[1].set_title('Calibration Plot')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 4. Second Stage: Forward Simulation\n",
    "\n",
    "## 4.1 State Transition Model\n",
    "\n",
    "The moment condition requires $\\mathbb{E}_t[\\ln P(\\text{close}_{t+1} | s_{t+1})]$, the expected log probability of closure next period.\n",
    "\n",
    "### AR(4) Transition Processes\n",
    "\n",
    "Each state variable follows an AR(4) process estimated from the data:\n",
    "$$x_{t+1} = \\alpha_0 + \\alpha_1 x_t + \\alpha_2 x_{t-1} + \\alpha_3 x_{t-2} + \\alpha_4 x_{t-3} + \\varepsilon_{t+1}$$\n",
    "\n",
    "## 4.2 Monte Carlo Integration\n",
    "\n",
    "For each observation, the MATLAB code (`ccpnext_param_KLW.m`):\n",
    "1. Draws 5,000 realizations from the empirical residual distribution (winsorized to [0.25, 99.75] percentiles)\n",
    "2. Computes next-period state for each draw\n",
    "3. Evaluates the logit CCP at the simulated state\n",
    "4. Averages $\\ln P_{t+1}$ and $MC_{t+1}$ across draws\n",
    "\n",
    "### Note on Replication\n",
    "\n",
    "**We use pre-computed forward simulation results** because:\n",
    "1. The procedure requires AR(4) transition coefficients estimated in Stata\n",
    "2. Reproducing the exact random number sequence requires MATLAB's RNG seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"SECOND STAGE: Forward Simulation Results\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nPre-computed simulation results: {ccp_next.shape}\")\n",
    "print(f\"Number of observations: {ccp_next.shape[0]:,}\")\n",
    "print(f\"Number of simulation draws per obs: 5,000\")\n",
    "print(f\"Total simulations: {ccp_next.shape[0] * 5000:,}\")\n",
    "\n",
    "# Extract key columns\n",
    "E_P_next = ccp_next[:, 2]      # E[P(close_{t+1})]\n",
    "E_ln_P_next = ccp_next[:, 3]   # E[ln P(close_{t+1})]\n",
    "E_MC_next_sim = ccp_next[:, 4] # E[MC_{t+1}]\n",
    "\n",
    "print(f\"\\n--- E[P_next] Statistics ---\")\n",
    "print(f\"  Range: [{E_P_next.min():.8f}, {E_P_next.max():.8f}]\")\n",
    "print(f\"  Mean:  {E_P_next.mean():.8f}\")\n",
    "\n",
    "print(f\"\\n--- E[ln P_next] Statistics ---\")\n",
    "print(f\"  Range: [{E_ln_P_next.min():.4f}, {E_ln_P_next.max():.4f}]\")\n",
    "print(f\"  Mean:  {E_ln_P_next.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify consistency with GMM data\n",
    "print(\"\\n--- Verification Against GMM Data ---\")\n",
    "\n",
    "E_ln_P_gmm = gmm_mat['Eln_prob_next'].squeeze()\n",
    "\n",
    "print(f\"From ccpnext file:   E[ln P] mean = {E_ln_P_next.mean():.6f}\")\n",
    "print(f\"From GMM .mat file:  E[ln P] mean = {E_ln_P_gmm.mean():.6f}\")\n",
    "print(f\"Correlation: {np.corrcoef(E_ln_P_next, E_ln_P_gmm)[0,1]:.8f}\")\n",
    "\n",
    "if np.corrcoef(E_ln_P_next, E_ln_P_gmm)[0,1] > 0.9999:\n",
    "    print(\"\\n>>> VERIFICATION PASSED: Forward simulations match!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 5. Third Stage: Structural GMM Estimation\n",
    "\n",
    "## 5.1 The Moment Condition\n",
    "\n",
    "From the CCP inversion and Euler equation:\n",
    "\n",
    "$$g(\\theta) = \\sigma \\cdot \\ln\\left(\\frac{1-P_t}{P_t}\\right) + \\beta\\sigma \\cdot \\mathbb{E}[\\ln P_{t+1}] - \\beta \\cdot \\left(-\\mathbb{E}[MC_{t+1}] + X_{t+1}\\beta_{NMC}\\right) + \\left(-MC_t + X_t \\beta_{NMC}\\right)$$\n",
    "\n",
    "### The Net Monetary Cost (NMC) Function\n",
    "\n",
    "$$NMC(s_t) = -MC(s_t) + X_t \\beta_{NMC}$$\n",
    "\n",
    "where $MC(s_t)$ is the pre-computed monetary cost from a Tobit model, and $X_t \\beta_{NMC}$ is a linear adjustment.\n",
    "\n",
    "**Note**: The pre-computed $MC$ already captures the direct cost component; $\\beta_{NMC}$ captures additional effects through the listed covariates.\n",
    "\n",
    "## 5.2 Continuously-Updated GMM\n",
    "\n",
    "**CRITICAL**: The original uses **continuously-updated GMM**, not standard two-step GMM.\n",
    "\n",
    "Standard GMM: $W = (Z'Z/N)^{-1}$ (fixed instruments)\n",
    "\n",
    "**Continuously-updated GMM**: $W = (G'G/N)^{-1}$ (moment contributions)\n",
    "\n",
    "From `param_obj_cont_KLW.m` (lines 66-70):\n",
    "```matlab\n",
    "G = [g1,g2,g3,g4,g5,g6,g7,g8,g9,g10,g11];\n",
    "W = (1/Nobs)*(G'*G);\n",
    "f_temp = W\\m';\n",
    "f = m*f_temp;\n",
    "```\n",
    "\n",
    "### Instruments (11 moments)\n",
    "\n",
    "1. Constant\n",
    "2. log(assets)\n",
    "3. log(assets)$^2$\n",
    "4. NPL ratio\n",
    "5. ROA\n",
    "6. House index\n",
    "7. Senate index\n",
    "8. Equity ratio\n",
    "9. Real estate ratio\n",
    "10. Asset growth\n",
    "11. State unemployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"THIRD STAGE: Structural GMM Estimation\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# ============================================================\n",
    "# Extract all data from GMM .mat file\n",
    "# ============================================================\n",
    "\n",
    "# CCPs\n",
    "Eprob_now = gmm_mat['Eprob_now'].squeeze()\n",
    "Eln_prob_next = gmm_mat['Eln_prob_next'].squeeze()\n",
    "\n",
    "# Monetary costs (from pre-estimated Tobit model)\n",
    "Emc_now = gmm_mat['Emc_now'].squeeze()\n",
    "Emc_next = gmm_mat['Emc_next'].squeeze()\n",
    "\n",
    "# Political indices\n",
    "House = gmm_mat['House'].squeeze()\n",
    "Senate = gmm_mat['Senate'].squeeze()\n",
    "House_next = gmm_mat['House_next'].squeeze()\n",
    "Senate_next = gmm_mat['Senate_next'].squeeze()\n",
    "\n",
    "# State variables\n",
    "logasset_all = gmm_mat['logasset_all']\n",
    "npf_a_all = gmm_mat['npf_a_all']\n",
    "roa_annual_all = gmm_mat['roa_annual_all']\n",
    "realEst_own_a_all = gmm_mat['realEst_own_a_all']\n",
    "equity_a_all = gmm_mat['equity_a_all']\n",
    "assGrowth_1y_all = gmm_mat['assGrowth_1y_all']\n",
    "unemp_all = gmm_mat['unemp_all']\n",
    "\n",
    "# Expected next-period variables\n",
    "Elogasset_next = gmm_mat['Elogasset_next'].squeeze()\n",
    "Elogasset_next2 = gmm_mat['Elogasset_next2'].squeeze()\n",
    "Enpf_a_next = gmm_mat['Enpf_a_next'].squeeze()\n",
    "Erealest_a_next = gmm_mat['Erealest_a_next'].squeeze()\n",
    "Eroa_next = gmm_mat['Eroa_next'].squeeze()\n",
    "\n",
    "Nobs = len(Eprob_now)\n",
    "ONES = np.ones(Nobs)\n",
    "\n",
    "print(f\"\\nSample size for GMM: {Nobs:,} observations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Handle extreme probabilities (as in original code)\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n--- Handling Extreme Probabilities ---\")\n",
    "print(f\"Max P before adjustment: {Eprob_now.max():.10f}\")\n",
    "\n",
    "# From param_obj_cont_KLW.m lines 27-30:\n",
    "# One observation has P very close to 1, causing log(1-P) issues\n",
    "sorted_idx = np.argsort(Eprob_now)\n",
    "idx_biggest = sorted_idx[-1]\n",
    "idx_2biggest = sorted_idx[-2]\n",
    "\n",
    "Eprob_now_adj = Eprob_now.copy()\n",
    "Eprob_now_adj[idx_biggest] = Eprob_now[idx_2biggest] + (1 - Eprob_now[idx_2biggest]) * 0.9\n",
    "\n",
    "print(f\"Max P after adjustment:  {Eprob_now_adj.max():.10f}\")\n",
    "print(f\"Adjustment applied to observation {idx_biggest}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Construct design matrices (exactly as in param_obj_KLW.m)\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n--- Constructing Design Matrices ---\")\n",
    "\n",
    "# X_now = [const, log_assets, log_assets^2, npf_a, roa, realest_a, House, Senate]\n",
    "Xnow = np.column_stack([\n",
    "    ONES,\n",
    "    logasset_all[:, 0],\n",
    "    logasset_all[:, 0]**2,\n",
    "    npf_a_all[:, 0],\n",
    "    roa_annual_all[:, 0],\n",
    "    realEst_own_a_all[:, 0],\n",
    "    House,\n",
    "    Senate\n",
    "])\n",
    "\n",
    "# X_next = [const, E[log_assets], E[log_assets^2], E[npf], E[roa], E[realest], House_next, Senate_next]\n",
    "Xnext = np.column_stack([\n",
    "    ONES,\n",
    "    Elogasset_next,\n",
    "    Elogasset_next2,\n",
    "    Enpf_a_next,\n",
    "    Eroa_next,\n",
    "    Erealest_a_next,\n",
    "    House_next,\n",
    "    Senate_next\n",
    "])\n",
    "\n",
    "# Instruments Z (11 columns)\n",
    "Z = np.column_stack([\n",
    "    ONES,\n",
    "    logasset_all[:, 0],\n",
    "    logasset_all[:, 0]**2,\n",
    "    npf_a_all[:, 0],\n",
    "    roa_annual_all[:, 0],\n",
    "    House,\n",
    "    Senate,\n",
    "    equity_a_all[:, 0],\n",
    "    realEst_own_a_all[:, 0],\n",
    "    assGrowth_1y_all[:, 0],\n",
    "    unemp_all[:, 0]\n",
    "])\n",
    "\n",
    "print(f\"X_now shape:  {Xnow.shape}\")\n",
    "print(f\"X_next shape: {Xnext.shape}\")\n",
    "print(f\"Z shape:      {Z.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# GMM Objective Function: CONTINUOUSLY-UPDATED GMM\n",
    "# Matches param_obj_cont_KLW.m exactly\n",
    "# ============================================================\n",
    "\n",
    "def gmm_objective_cont(THETA, return_details=False):\n",
    "    \"\"\"\n",
    "    Continuously-updated GMM objective function.\n",
    "    \n",
    "    CRITICAL: Uses W = G'G (moment contributions), NOT W = Z'Z (instruments)\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    THETA : array of length 10\n",
    "        [beta, sigma, beta_NMC[0:8]]\n",
    "    return_details : bool\n",
    "        If True, return (f, m, G) for debugging\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    f : float\n",
    "        GMM objective value (to be minimized)\n",
    "    \"\"\"\n",
    "    beta = THETA[0]       # Discount factor\n",
    "    sigma = THETA[1]      # Scale parameter\n",
    "    beta_NMC = THETA[2:10]  # NMC coefficients\n",
    "    \n",
    "    # Compute log-odds: log((1-P)/P)\n",
    "    log_odds = np.log(1 - Eprob_now_adj) - np.log(Eprob_now_adj)\n",
    "    \n",
    "    # Moment condition g1 (equation from CCP inversion)\n",
    "    g1 = (sigma * log_odds + \n",
    "          beta * sigma * Eln_prob_next - \n",
    "          beta * (-Emc_next + Xnext @ beta_NMC) + \n",
    "          (-Emc_now + Xnow @ beta_NMC))\n",
    "    \n",
    "    # Interact base moment with instruments\n",
    "    g2 = g1 * Z[:, 1]\n",
    "    g3 = g1 * Z[:, 2]\n",
    "    g4 = g1 * Z[:, 3]\n",
    "    g5 = g1 * Z[:, 4]\n",
    "    g6 = g1 * Z[:, 5]\n",
    "    g7 = g1 * Z[:, 6]\n",
    "    g8 = g1 * Z[:, 7]\n",
    "    g9 = g1 * Z[:, 8]\n",
    "    g10 = g1 * Z[:, 9]\n",
    "    g11 = g1 * Z[:, 10]\n",
    "    \n",
    "    # Sample moment vector\n",
    "    m = np.array([\n",
    "        g1.mean(), g2.mean(), g3.mean(), g4.mean(), g5.mean(),\n",
    "        g6.mean(), g7.mean(), g8.mean(), g9.mean(), g10.mean(), g11.mean()\n",
    "    ])\n",
    "    \n",
    "    # CONTINUOUSLY-UPDATED WEIGHTING: W = G'G (not Z'Z!)\n",
    "    G = np.column_stack([g1, g2, g3, g4, g5, g6, g7, g8, g9, g10, g11])\n",
    "    W = (G.T @ G) / Nobs\n",
    "    \n",
    "    # GMM objective: m' * W^{-1} * m\n",
    "    try:\n",
    "        f_temp = np.linalg.solve(W, m)\n",
    "        f = m @ f_temp\n",
    "    except np.linalg.LinAlgError:\n",
    "        f = 1e10\n",
    "    \n",
    "    if return_details:\n",
    "        return f, m, G\n",
    "    return f\n",
    "\n",
    "print(\"GMM objective function defined (continuously-updated weighting).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# Verify objective function at original estimates\n# ============================================================\n\nprint(\"Verification: Objective at Original Estimates\")\nprint(\"=\"*50)\n\nparam_names = ['beta', 'sigma', 'NMC:const', 'NMC:logA', 'NMC:logA2', \n               'NMC:npf', 'NMC:roa', 'NMC:realest', 'NMC:House', 'NMC:Senate']\n\n# Display original theta using tabulate\norig_table = [[name, f\"{val:.4f}\"] for name, val in zip(param_names, theta_original)]\nprint(\"\\nOriginal estimates:\")\nprint(tabulate(orig_table, headers=['Parameter', 'Value'], tablefmt='simple'))\n\nf_at_original = gmm_objective_cont(theta_original)\nprint(f\"\\nGMM objective at original: {f_at_original:.8f}\")\n\n# Check gradient (should be near zero at optimum)\neps = 1e-6\ngrad = np.zeros(10)\nfor i in range(10):\n    theta_plus = theta_original.copy()\n    theta_minus = theta_original.copy()\n    theta_plus[i] += eps\n    theta_minus[i] -= eps\n    grad[i] = (gmm_objective_cont(theta_plus) - gmm_objective_cont(theta_minus)) / (2 * eps)\n\nprint(f\"Gradient norm at original: {np.linalg.norm(grad):.8f}\")\n\nif f_at_original < 0.001 and np.linalg.norm(grad) < 0.001:\n    print(\"\\n>>> VERIFICATION PASSED: Original estimates are at a local minimum!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Grid-Search Refinement Procedure\n",
    "\n",
    "**Key Insight from the Original Code**: Standard gradient-based optimization converges to different local minima depending on starting values. The original MATLAB code uses an **iterative grid search refinement** procedure.\n",
    "\n",
    "From `fn_obj_cont_KLW.m` (lines 76-132) and `findmin_cont_KLW.m` (lines 26-60):\n",
    "\n",
    "1. Run gradient-based optimization (fmincon)\n",
    "2. For each parameter, search over a grid of $\\pm 100\\%$ of its current value\n",
    "3. Find the parameter values that minimize the objective for each parameter\n",
    "4. Compute objective at the grid-refined parameter vector\n",
    "5. If grid search finds a lower objective, use those parameters\n",
    "6. Repeat until convergence (up to 25 iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Grid-Search Refinement (from fn_obj_cont_KLW.m)\n",
    "# ============================================================\n",
    "\n",
    "def grid_search_refinement(THETA, num_range=100, portion=0.01, extend=1.0):\n",
    "    \"\"\"\n",
    "    Grid search refinement procedure from fn_obj_cont_KLW.m.\n",
    "    \n",
    "    For each parameter, searches over a grid from:\n",
    "        theta[i] - theta[i]*portion*num_range  to  theta[i] + theta[i]*portion*num_range*extend\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    THETA : array of length 10\n",
    "        Current parameter estimates\n",
    "    num_range : int\n",
    "        Number of grid points on each side (default 100)\n",
    "    portion : float\n",
    "        Step size as fraction of parameter (default 0.01 = 1%)\n",
    "    extend : float\n",
    "        Extension factor for positive side (default 1.0)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    THETA_new : array\n",
    "        Refined parameter estimates\n",
    "    f_new : float\n",
    "        Objective at refined estimates\n",
    "    improved : bool\n",
    "        Whether refinement improved the objective\n",
    "    \"\"\"\n",
    "    f_old = gmm_objective_cont(THETA)\n",
    "    \n",
    "    # For each parameter, find the grid value that minimizes objective (holding others fixed)\n",
    "    THETA_new = np.zeros_like(THETA)\n",
    "    \n",
    "    for i_param in range(len(THETA)):\n",
    "        # Create grid for this parameter\n",
    "        theta_i = THETA[i_param]\n",
    "        if abs(theta_i) < 1e-10:  # Handle near-zero parameters\n",
    "            theta_range = np.linspace(-1, 1, 2*num_range + 1)\n",
    "        else:\n",
    "            theta_range = np.linspace(\n",
    "                theta_i - abs(theta_i) * portion * num_range,\n",
    "                theta_i + abs(theta_i) * portion * num_range * extend,\n",
    "                2 * num_range + 1\n",
    "            )\n",
    "        \n",
    "        # Evaluate objective at each grid point\n",
    "        f_range = np.zeros(len(theta_range))\n",
    "        for k, theta_k in enumerate(theta_range):\n",
    "            THETA_temp = THETA.copy()\n",
    "            THETA_temp[i_param] = theta_k\n",
    "            f_range[k] = gmm_objective_cont(THETA_temp)\n",
    "        \n",
    "        # Find minimizing grid point\n",
    "        best_idx = np.argmin(f_range)\n",
    "        THETA_new[i_param] = theta_range[best_idx]\n",
    "    \n",
    "    f_new = gmm_objective_cont(THETA_new)\n",
    "    \n",
    "    return THETA_new, f_new, f_new < f_old\n",
    "\n",
    "print(\"Grid search refinement function defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Full Optimization with Grid Refinement (from findmin_cont_KLW.m)\n",
    "# ============================================================\n",
    "\n",
    "def gmm_optimize_with_grid_refinement(x0, max_iterations=25, tol=1e-8, verbose=True):\n",
    "    \"\"\"\n",
    "    GMM optimization with iterative grid search refinement.\n",
    "    Matches the procedure in findmin_cont_KLW.m.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    x0 : array\n",
    "        Starting values\n",
    "    max_iterations : int\n",
    "        Maximum number of refinement iterations\n",
    "    tol : float\n",
    "        Convergence tolerance\n",
    "    verbose : bool\n",
    "        Print progress\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    theta_best : array\n",
    "        Best parameter estimates found\n",
    "    f_best : float\n",
    "        Objective at best estimates\n",
    "    history : list\n",
    "        History of objective values\n",
    "    \"\"\"\n",
    "    # Bounds\n",
    "    bounds = [\n",
    "        (0.001, 0.999),  # beta\n",
    "        (0.001, None),   # sigma\n",
    "    ] + [(None, None)] * 8\n",
    "    \n",
    "    theta_current = x0.copy()\n",
    "    f_current = gmm_objective_cont(theta_current)\n",
    "    history = [f_current]\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"\\nStarting optimization with grid refinement\")\n",
    "        print(f\"Initial objective: {f_current:.8f}\")\n",
    "        print(\"-\" * 60)\n",
    "    \n",
    "    for iteration in range(max_iterations):\n",
    "        # Step 1: Gradient-based optimization\n",
    "        result = minimize(\n",
    "            gmm_objective_cont,\n",
    "            theta_current,\n",
    "            method='L-BFGS-B',\n",
    "            bounds=bounds,\n",
    "            options={'maxiter': 500, 'ftol': 1e-12}\n",
    "        )\n",
    "        theta_grad = result.x\n",
    "        f_grad = result.fun\n",
    "        \n",
    "        # Step 2: Grid search refinement\n",
    "        theta_grid, f_grid, improved = grid_search_refinement(theta_grad)\n",
    "        \n",
    "        # Choose better result\n",
    "        if f_grid < f_grad:\n",
    "            theta_new = theta_grid\n",
    "            f_new = f_grid\n",
    "            method_used = \"grid\"\n",
    "        else:\n",
    "            theta_new = theta_grad\n",
    "            f_new = f_grad\n",
    "            method_used = \"gradient\"\n",
    "        \n",
    "        history.append(f_new)\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"Iter {iteration+1:2d}: f={f_new:.8f} (from {method_used}), improvement={f_current - f_new:.2e}\")\n",
    "        \n",
    "        # Check convergence\n",
    "        if abs(f_current - f_new) < tol:\n",
    "            if verbose:\n",
    "                print(f\"\\nConverged after {iteration+1} iterations.\")\n",
    "            break\n",
    "        \n",
    "        theta_current = theta_new\n",
    "        f_current = f_new\n",
    "    \n",
    "    return theta_current, f_current, history\n",
    "\n",
    "print(\"Full optimization procedure defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 Estimation Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Run optimization from initial values\n",
    "# ============================================================\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"GMM ESTIMATION WITH GRID REFINEMENT\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Starting values (from GMM1st_KLW.mat - first-stage GMM estimates)\n",
    "x_initial = np.array([\n",
    "    9.54192957e-01,   # beta\n",
    "    5.77371682e+02,   # sigma\n",
    "    -4.68922494e+05,  # NMC_const\n",
    "    8.56032237e+04,   # NMC_logA\n",
    "    -3.91390922e+03,  # NMC_logA2\n",
    "    -3.38245568e+04,  # NMC_npf\n",
    "    -5.48256731e+04,  # NMC_roa\n",
    "    -1.46755533e+05,  # NMC_realest\n",
    "    -4.19949688e+02,  # NMC_House\n",
    "    1.13845592e+01    # NMC_Senate\n",
    "])\n",
    "\n",
    "print(f\"\\nStarting from first-stage GMM estimates\")\n",
    "print(f\"Initial objective: {gmm_objective_cont(x_initial):.8f}\")\n",
    "\n",
    "# Run optimization with grid refinement\n",
    "theta_estimated, f_estimated, history = gmm_optimize_with_grid_refinement(\n",
    "    x_initial, max_iterations=15, verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Also run from original estimates to verify\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"VERIFICATION: Starting from Original Estimates\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "theta_from_orig, f_from_orig, history_orig = gmm_optimize_with_grid_refinement(\n",
    "    theta_original, max_iterations=5, verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# Compare results\n# ============================================================\n\nprint(\"Table: Replication Comparison\")\nprint(\"=\"*60)\n\n# Use the result with lower objective\nif f_estimated < f_from_orig:\n    theta_final = theta_estimated\n    f_final = f_estimated\n    source = \"initial values\"\nelse:\n    theta_final = theta_from_orig\n    f_final = f_from_orig\n    source = \"original\"\n\nprint(f\"\\nUsing estimates from {source} (lower objective)\")\n\n# Create comparison table using tabulate\ncomparison_data = []\nfor i, name in enumerate(param_names):\n    orig = theta_original[i]\n    est = theta_final[i]\n    pct_diff = 100 * (est - orig) / abs(orig) if orig != 0 else 0\n    comparison_data.append([name, f\"{orig:.4f}\", f\"{est:.4f}\", f\"{pct_diff:.2f}%\"])\n\nprint(\"\\n\" + tabulate(comparison_data, \n                      headers=['Parameter', 'Original', 'Replicated', '% Diff'],\n                      tablefmt='simple',\n                      colalign=('left', 'right', 'right', 'right')))\n\nprint(f\"\\nGMM Objective:\")\nprint(f\"  Original:   {gmm_objective_cont(theta_original):.8f}\")\nprint(f\"  Replicated: {f_final:.8f}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot convergence\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax.plot(history, 'b-o', label='From initial values')\n",
    "ax.axhline(y=gmm_objective_cont(theta_original), color='r', linestyle='--', \n",
    "           label=f'Original objective ({gmm_objective_cont(theta_original):.6f})')\n",
    "ax.set_xlabel('Iteration')\n",
    "ax.set_ylabel('GMM Objective')\n",
    "ax.set_title('Convergence of GMM Estimation with Grid Refinement')\n",
    "ax.legend()\n",
    "ax.set_yscale('log')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 6. Inference and Results\n",
    "\n",
    "## 6.1 Standard Error Computation\n",
    "\n",
    "For continuously-updated GMM, the asymptotic variance has the form:\n",
    "\n",
    "$$\\text{Avar}(\\hat{\\theta}) = \\frac{1}{N} (\\Gamma' W^{-1} \\Gamma)^{-1}$$\n",
    "\n",
    "where $\\Gamma = \\partial m / \\partial \\theta$ is the Jacobian of moments with respect to parameters.\n",
    "\n",
    "## 6.2 Pre-Estimation Variance Adjustments\n",
    "\n",
    "**Important**: The original code (`Avar_param_obj_KLW.m`) includes adjustments for pre-estimation error from:\n",
    "1. First-stage logit CCP estimation\n",
    "2. Tobit cost function estimation\n",
    "\n",
    "Following Newey-McFadden (1994), the total variance is:\n",
    "\n",
    "$$\\text{Avar} = \\text{Avar}_{\\text{base}} + \\text{Avar}_{\\text{logit\\_adj}} + \\text{Avar}_{\\text{cost\\_adj}}$$\n",
    "\n",
    "**Note**: The adjustments require the full covariance matrices from pre-estimation stages. We compute the base variance here and note that full standard errors would be slightly larger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# Table 7: Structural Parameters - Nonmonetary Costs\n# Replicating Table 7, Column \"Model I (85-92)\" from KLW (RFS 2015), page 27\n# =============================================================================\n\nprint(\"=\"*70)\nprint(\"Table 7: Structural Parameters: Nonmonetary Costs\")\nprint(\"Model I (85-92) - Parsimonious specification, 1985-1992 sample\")\nprint(\"=\"*70)\n\ndef compute_gmm_se(theta, eps=1e-5):\n    \"\"\"\n    Compute standard errors for continuously-updated GMM.\n    \n    Uses numerical derivatives for the Jacobian.\n    \n    NOTE: This computes the BASE variance only. Full variance\n    requires pre-estimation adjustments per Avar_param_obj_KLW.m.\n    \"\"\"\n    n_params = len(theta)\n    n_moments = 11\n    \n    def compute_moments(th):\n        beta, sigma = th[0], th[1]\n        beta_NMC = th[2:10]\n        \n        log_odds = np.log(1 - Eprob_now_adj) - np.log(Eprob_now_adj)\n        g1 = (sigma * log_odds + \n              beta * sigma * Eln_prob_next - \n              beta * (-Emc_next + Xnext @ beta_NMC) + \n              (-Emc_now + Xnow @ beta_NMC))\n        \n        m = np.array([\n            g1.mean(),\n            (g1 * Z[:, 1]).mean(),\n            (g1 * Z[:, 2]).mean(),\n            (g1 * Z[:, 3]).mean(),\n            (g1 * Z[:, 4]).mean(),\n            (g1 * Z[:, 5]).mean(),\n            (g1 * Z[:, 6]).mean(),\n            (g1 * Z[:, 7]).mean(),\n            (g1 * Z[:, 8]).mean(),\n            (g1 * Z[:, 9]).mean(),\n            (g1 * Z[:, 10]).mean()\n        ])\n        return m\n    \n    # Numerical Jacobian: Gamma = dm/dtheta\n    Gamma = np.zeros((n_moments, n_params))\n    for j in range(n_params):\n        theta_plus = theta.copy()\n        theta_minus = theta.copy()\n        theta_plus[j] += eps\n        theta_minus[j] -= eps\n        Gamma[:, j] = (compute_moments(theta_plus) - compute_moments(theta_minus)) / (2 * eps)\n    \n    # Compute moment contributions at theta\n    beta, sigma = theta[0], theta[1]\n    beta_NMC = theta[2:10]\n    log_odds = np.log(1 - Eprob_now_adj) - np.log(Eprob_now_adj)\n    g1 = (sigma * log_odds + \n          beta * sigma * Eln_prob_next - \n          beta * (-Emc_next + Xnext @ beta_NMC) + \n          (-Emc_now + Xnow @ beta_NMC))\n    \n    G_mat = np.column_stack([\n        g1, g1*Z[:,1], g1*Z[:,2], g1*Z[:,3], g1*Z[:,4],\n        g1*Z[:,5], g1*Z[:,6], g1*Z[:,7], g1*Z[:,8], g1*Z[:,9], g1*Z[:,10]\n    ])\n    \n    # Weighting matrix and its inverse\n    W = (G_mat.T @ G_mat) / Nobs\n    W_inv = np.linalg.inv(W)\n    \n    # Variance: (Gamma' W^{-1} Gamma)^{-1} / N\n    bread = Gamma.T @ W_inv @ Gamma\n    V = np.linalg.inv(bread) / Nobs\n    \n    se = np.sqrt(np.diag(V))\n    return se, V\n\n# Compute standard errors at final estimates\nse, V = compute_gmm_se(theta_final)\nt_stats = theta_final / se\n\n# Helper for significance stars\ndef get_stars(t):\n    if abs(t) > 2.58:\n        return '***'\n    elif abs(t) > 1.96:\n        return '**'\n    elif abs(t) > 1.65:\n        return '*'\n    return ''\n\n# Parameter names matching Table 7 in paper (page 27)\ntable7_params = [\n    ('Intercept', 2),          # NMC constant\n    ('log(Assets)', 3),        # NMC log assets\n    ('(log(Assets))^2', 4),    # NMC log assets squared\n    ('NP Loans/Assets', 5),    # NMC NPL ratio\n    ('Net Income/Assets', 6),  # NMC ROA\n    ('RE Owned/Assets', 7),    # NMC real estate\n    ('House', 8),              # NMC House\n    ('Senate', 9),             # NMC Senate\n    ('beta (quarterly discount factor)', 0),  # beta\n    ('sigma', 1),              # sigma\n]\n\n# Build table rows\ntable_rows = []\nfor name, idx in table7_params:\n    est = theta_final[idx]\n    se_val = se[idx]\n    stars = get_stars(t_stats[idx])\n    table_rows.append([name, f\"{est:.4f}{stars}\", f\"({se_val:.4f})\"])\n\nprint(tabulate(table_rows,\n               headers=['', 'Model I (85-92)', ''],\n               tablefmt='simple',\n               colalign=('left', 'right', 'left')))\n\n# J-test\nf_obj = gmm_objective_cont(theta_final)\nn_moments = 11\nn_params = 10\ndf = n_moments - n_params\nj_stat = Nobs * f_obj\nj_pval = 1 - stats.chi2.cdf(j_stat, df)\n\nprint(f\"\\nJ-test p-value                       {j_pval:.4f}\")\nprint(f\"Observations                         {Nobs:,}\")\n\nprint(\"\\n\" + \"-\"*70)\nprint(\"Notes: Standard errors in parentheses. *** p<0.01, ** p<0.05, * p<0.10\")\nprint(\"This replicates Model I (85-92) from Table 7 in the paper (page 27).\")\nprint(\"Table 7 also contains Models I(a), II, III, IV, and V (08-12).\")\nprint(\"-\"*70)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 7. Economic Interpretation\n",
    "\n",
    "## 7.1 Parameter Interpretation\n",
    "\n",
    "### Discount Factor ($\\beta \\approx 0.958$)\n",
    "\n",
    "The quarterly discount factor implies:\n",
    "- Annual discount factor: $\\beta^4 \\approx 0.843$\n",
    "- Implied annual discount rate: $r \\approx 15.7\\%$\n",
    "\n",
    "**Economic Interpretation**: This is substantially higher than typical market discount rates (5-10%). Possible explanations:\n",
    "1. **Regulatory time pressure**: Political incentives to resolve problems quickly\n",
    "2. **Agency costs**: Regulators may have shorter effective horizons than socially optimal\n",
    "3. **Option value**: Waiting has opportunity cost when bank conditions deteriorate\n",
    "\n",
    "### Scale Parameter ($\\sigma \\approx 640$)\n",
    "\n",
    "The scale parameter captures heterogeneity in unobserved closure costs. A larger $\\sigma$:\n",
    "- Makes closure decisions **less deterministic** given observables\n",
    "- Reflects idiosyncratic factors (local political pressure, examiner discretion, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(\"Economic Interpretation\")\nprint(\"=\"*50)\n\nbeta_est = theta_final[0]\nsigma_est = theta_final[1]\n\n# Discount factor interpretation\nprint(\"\\n1. DISCOUNT FACTOR\")\ndiscount_data = [\n    ['Quarterly ', f\"{beta_est:.4f}\"],\n    ['Annual ', f\"{beta_est**4:.4f}\"],\n    ['Implied annual rate', f\"{100*(1 - beta_est**4):.1f}%\"]\n]\nprint(tabulate(discount_data, tablefmt='simple'))\nprint(\"\\n   Interpretation: Regulators discount future costs more heavily\")\nprint(\"   than market rates, reflecting political pressures or agency costs.\")\n\nprint(\"\\n2. SCALE PARAMETER\")\nprint(f\"    = {sigma_est:.2f}\")\nprint(\"\\n   Interpretation: Substantial unobserved heterogeneity exists in\")\nprint(\"   closure costs, including examiner discretion and local factors.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2 Net Monetary Cost Function\n",
    "\n",
    "The NMC function is:\n",
    "$$NMC(s_t) = -MC(s_t) + X_t \\beta_{NMC}$$\n",
    "\n",
    "where $MC(s_t)$ is the pre-computed monetary cost from the Tobit model, and $X_t \\beta_{NMC}$ captures additional effects.\n",
    "\n",
    "### Interpreting the NMC Coefficients\n",
    "\n",
    "| Coefficient | Estimate | Interpretation |\n",
    "|-------------|----------|----------------|\n",
    "| `NMC:const` | $< 0$ | Base adjustment is negative |\n",
    "| `NMC:logA` | $> 0$ | Larger banks have higher adjusted NMC (more costly to keep open) |\n",
    "| `NMC:logA2` | $< 0$ | Diminishing returns to size |\n",
    "| `NMC:npf` | $< 0$ | Higher NPLs reduce adjusted NMC (NPL effect already in MC) |\n",
    "| `NMC:roa` | $< 0$ | Higher profitability reduces adjusted NMC |\n",
    "| `NMC:realest` | $< 0$ | Real estate effect (already in MC) |\n",
    "| `NMC:House` | $< 0$ | Political index reduces closure costs |\n",
    "| `NMC:Senate` | varies | Political index effect (often insignificant) |\n",
    "\n",
    "**Important Caveat**: The NMC coefficients adjust a pre-computed $MC$ variable. Their signs reflect **residual effects** after the Tobit model, not the total effect of each variable on closure costs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(\"Table: Net Monetary Cost (NMC) Coefficients\")\nprint(\"=\"*60)\nprint(\"\\nThese coefficients adjust the pre-computed monetary cost MC.\")\nprint(\"Signs reflect RESIDUAL effects after the Tobit cost model.\\n\")\n\nnmc_data = [\n    ('Constant', theta_final[2], 'Base adjustment'),\n    ('Log(assets)', theta_final[3], 'Larger banks  higher NMC'),\n    ('Log(assets)', theta_final[4], 'Diminishing size effect'),\n    ('NPL ratio', theta_final[5], 'NPL effect (residual after MC)'),\n    ('ROA', theta_final[6], 'Profitability reduces NMC'),\n    ('Real estate', theta_final[7], 'Real estate effect (residual)'),\n    ('House index', theta_final[8], 'Political index effect'),\n    ('Senate index', theta_final[9], 'Political index effect'),\n]\n\nnmc_table = [[name, f\"{est:.2f}\", interp] for name, est, interp in nmc_data]\n\nprint(tabulate(nmc_table,\n               headers=['Variable', 'Estimate', 'Interpretation'],\n               tablefmt='simple'))"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final visualization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Plot 1: Predicted P(close) vs equity\n",
    "axes[0].scatter(equity_a_all[:, 0], Eprob_now_adj, alpha=0.1, s=1)\n",
    "axes[0].set_xlabel('Equity / Assets')\n",
    "axes[0].set_ylabel('P(Close)')\n",
    "axes[0].set_title('Closure Probability vs Capital Ratio')\n",
    "axes[0].axvline(x=0.08, color='red', linestyle='--', label='Regulatory min (8%)')\n",
    "axes[0].legend()\n",
    "\n",
    "# Plot 2: Predicted P(close) vs NPL\n",
    "axes[1].scatter(npf_a_all[:, 0], Eprob_now_adj, alpha=0.1, s=1)\n",
    "axes[1].set_xlabel('Non-Performing Loans / Assets')\n",
    "axes[1].set_ylabel('P(Close)')\n",
    "axes[1].set_title('Closure Probability vs Asset Quality')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
